{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Github README Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "data_path = \"./dataset/data/esol_iupac.csv\"\n",
    "raw_data = pd.read_csv(data_path)\n",
    "\n",
    "def query2IUPAC(text):\n",
    "  try:\n",
    "    '''This function queries the one given molecule name and returns a SMILES string from the record'''\n",
    "    #query the PubChem database\n",
    "    r = requests.get('https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/smiles/' + text + '/property/IUPACName/JSON')\n",
    "    data = r.json()\n",
    "    smi = data[\"PropertyTable\"][\"Properties\"][0][\"IUPACName\"]\n",
    "    return smi\n",
    "  except:\n",
    "    return None\n",
    "\n",
    "# raw_data[\"IUPAC\"] = raw_data[\"SMILES\"].map(lambda sml: query2IUPAC(sml))\n",
    "raw_data = raw_data[[\"IUPAC\", \"measured log(solubility:mol/L)\"]]\n",
    "raw_data = raw_data.dropna()\n",
    "raw_data[50:65]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### README example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bolift\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "asktell = bolift.AskTellFewShotTopk(\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "asktell.tell(\"3-chloroaniline\", -1.37)\n",
    "asktell.tell(\"nitromethane\", 0.26)\n",
    "asktell.tell(\"1-bromobutane\", -2.43)\n",
    "asktell.tell(\"3-chlorophenol\", -0.7)\n",
    "\n",
    "yhat = asktell.predict(\"penta-1,4-diene\t\")\n",
    "print(yhat.mean(), yhat.std())\n",
    "\n",
    "pool_list = [\n",
    "  \"1,5-dimethylnaphthalene\",\n",
    "  \"2-aminophenol\",\n",
    "  \"1hexa-1,5-diene\",\n",
    "  \"1,1,2,3,4,4-hexachlorobuta-1,3-diene\"\n",
    "]\n",
    "pool=bolift.Pool(pool_list)\n",
    "print(asktell.ask(pool))\n",
    "\n",
    "asktell.tell(\"phenol\", -0.5)\n",
    "yhat = asktell.predict(\"penta-1,4-diene\")\n",
    "print(yhat.mean(), yhat.std())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bolift\n",
    "from bolift.llm_model import GaussDist, DiscreteDist\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "import itertools\n",
    "import os\n",
    "import openai\n",
    "import glob\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")\n",
    "# @retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def run_ablation_experiment(asktell, train_data, test_data, system_message=\"\"):\n",
    "    if isinstance(asktell, bolift.AskTellGPR):\n",
    "        for i in range(len(train_data)-1):\n",
    "            asktell.tell(train_data.iloc[i, 0], float(train_data.iloc[i, 1]), train=False)\n",
    "        asktell.tell(train_data.iloc[i+1, 0], float(train_data.iloc[i+1, 1]), train=True)\n",
    "    else:\n",
    "        for i in range(len(train_data)):\n",
    "            asktell.tell(train_data.iloc[i, 0], float(train_data.iloc[i, 1]))\n",
    "    x    = []\n",
    "    y    = []\n",
    "    yhat = []\n",
    "    for j in range(len(test_data)):\n",
    "        x.append(test_data.iloc[j, 0])\n",
    "        y.append(float(test_data.iloc[j, 1]))\n",
    "        yhat.append(asktell.predict(test_data.iloc[j, 0]))#, system_message=system_message))\n",
    "\n",
    "    x_filter = [xi for xi, yhi in zip(x, yhat)]# if len(yhi.values) > 0]\n",
    "    y_filter = [yi for yi, yhi in zip(y, yhat)]# if len(yhi.values) > 0]\n",
    "    yhat_filter = [yhi for yi, yhi in zip(y, yhat)]# if len(yhi.values) > 0]\n",
    "    return x_filter, y_filter, yhat_filter\n",
    "\n",
    "def save_csv(filename, x, y, yhat, data, model, T, k, N, model_class, tokens):\n",
    "    if not os.path.exists(filename):\n",
    "        f = open(filename, \"w\")\n",
    "        f.write(\"y;yhat;yprobs;data;model;Temperature;k_selected;N_train;model_class;n_tokens;x\\n\")\n",
    "    else:\n",
    "        f = open(filename, \"a\")\n",
    "    for xi, yi, yhi in zip(x, y, yhat):\n",
    "        if isinstance(yhi, DiscreteDist):\n",
    "            if len(yhi.values) > 0:\n",
    "                for v,p in zip(yhi.values, yhi.probs):\n",
    "                    f.write(f\"{yi};{v};{p:.4f};{data};{model};{T};{k};{N};{model_class};{tokens};{xi}\\n\")\n",
    "        if isinstance(yhi, GaussDist):\n",
    "            f.write(f\"{yi};{yhi.mean()};{yhi.std():.4f};{data};{model};{T};{k};{N};{model_class};{tokens};{xi}\\n\")\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataset(data: str, N: int, split=0.8):\n",
    "    match data:\n",
    "        case \"in-house\":\n",
    "            data_path = \"./dataset/data/71023_BO_ready_pool.csv\"\n",
    "            raw_data = pd.read_csv(data_path)\n",
    "\n",
    "            raw_data['Catalyst'] = raw_data['Prompt'].str.extract(r'(\\b[A-Z][a-z]?:[A-Z][a-z]?:[A-Z][a-z]?\\b)')\n",
    "            unique_cat = raw_data['Catalyst'].unique()\n",
    "            c = {c: 0.2+m*(5/len(unique_cat)) for m, c in enumerate(unique_cat)}\n",
    "            raw_data['dummy_Completion'] = raw_data['Catalyst'].apply(lambda x: np.random.normal(c[x], 0.05))\n",
    "\n",
    "            x_name = \"Prompt\"\n",
    "            y_name = \"dummy_Completion\"\n",
    "        case \"ocm\":\n",
    "            data_path = \"./dataset/data/12708_ocm_dataset.csv\"\n",
    "            raw_data = pd.read_csv(data_path, sep=\";\")\n",
    "            raw_data = raw_data.sample(frac=1).reset_index(drop=True)\n",
    "            x_name = \"prompt\"\n",
    "            y_name = \"completion\"\n",
    "        case \"biasfree_ocm\":\n",
    "            data_path = \"./dataset/data/bias_free_ocmdataset_p_comp.csv\"\n",
    "            raw_data = pd.read_csv(data_path, sep=\",\")\n",
    "            raw_data = raw_data.sample(frac=1).reset_index(drop=True)\n",
    "            x_name = \"prompt\"\n",
    "            y_name = \"completion\"\n",
    "        case \"sol\":\n",
    "            data_path = \"./dataset/data/esol_iupac.csv\"\n",
    "            raw_data = pd.read_csv(data_path)\n",
    "            raw_data = raw_data.dropna()\n",
    "            raw_data = raw_data[[\"IUPAC\", \"measured log(solubility:mol/L)\"]]\n",
    "            x_name = \"IUPAC\"\n",
    "            y_name = \"measured log(solubility:mol/L)\"\n",
    "        case _:\n",
    "            raise ValueError(\"Unknown data\")\n",
    "        \n",
    "    n_data = raw_data.shape[0]\n",
    "    indexes = np.random.choice(n_data, int(n_data), replace=False)\n",
    "    train = np.random.choice(n_data, int(n_data * split), replace=False)\n",
    "    test = np.setdiff1d(np.arange(n_data), train)\n",
    "    test = np.random.choice(test, min(200, len(test)), replace=False) # limiting too large test set to avoid expense with OpenAI requests\n",
    "\n",
    "    if N > len(train):\n",
    "        raise ValueError(f\"N must be less than the training set size. Trainin set size: {len(train)}\")\n",
    "    train_data = raw_data.iloc[train, :].reset_index(drop=True)[:N]\n",
    "    test_data = raw_data.iloc[test, :].reset_index(drop=True)\n",
    "    # print(f\"Dataset size:  \\t{n_data}\")\n",
    "    # print(f\"Training size: \\t{len(train_data)}\")\n",
    "    # print(f\"Test size:     \\t{len(test_data)}\")\n",
    "\n",
    "    return raw_data, train_data, test_data, indexes, x_name, y_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def get_asktell(model: str, kwargs: dict = {}, pool: bolift.Pool = None, knn: int = 1):\n",
    "    match model:\n",
    "        case \"gpt-3.5-turbo-instruct\":\n",
    "            kwargs['model']=\"gpt-3.5-turbo-instruct\"\n",
    "            return bolift.AskTellFewShotTopk(**kwargs)\n",
    "        case \"gpt-3.5-turbo-0125\":\n",
    "            kwargs['model']=\"gpt-3.5-turbo-0125\"\n",
    "            return bolift.AskTellFewShotTopk(**kwargs)\n",
    "        case \"gpt-4\":\n",
    "            kwargs['model']=\"gpt-4\"\n",
    "            return bolift.AskTellFewShotTopk(**kwargs)\n",
    "        case \"gpt-4o\":\n",
    "            kwargs['model']=\"gpt-4o\"\n",
    "            return bolift.AskTellFewShotTopk(**kwargs)\n",
    "        case \"gpt-4-0125-preview\":\n",
    "            kwargs['model']=\"gpt-4-0125-preview\"\n",
    "            return bolift.AskTellFewShotTopk(**kwargs)\n",
    "        case \"davinci\":\n",
    "            kwargs['model']=\"davinci-002\"\n",
    "            return bolift.AskTellFewShotTopk(**kwargs)\n",
    "        case \"gpr\":\n",
    "            kwargs['selector_k'] = 0\n",
    "            kwargs['pool'] = pool if pool else None\n",
    "            kwargs['n_components'] = 32\n",
    "            return bolift.AskTellGPR(**kwargs)\n",
    "        case \"knn\":\n",
    "            del kwargs['selector_k']\n",
    "            kwargs['knn'] = knn\n",
    "            return bolift.AskTellNearestNeighbor(**kwargs)\n",
    "        case \"krr\":\n",
    "            kwargs['alpha'] = 0.5\n",
    "            return bolift.AskTellRidgeKernelRegression(**kwargs)\n",
    "        case _:\n",
    "            raise ValueError(\"Unknown model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(exp, dataset, system_message=\"\", *args, **kwargs):\n",
    "    T_list = exp['T_list']\n",
    "    k_list = exp['k_list']\n",
    "    N_list = exp['N_list']\n",
    "    models_list = exp['models_list']\n",
    "    out_csv_file = exp['out_csv_file']\n",
    "    model_class=\"topk\"\n",
    "    for T, k, N, model in itertools.product(T_list, k_list, N_list, models_list):\n",
    "        print(f\"Running {dataset} {model_class} ablation with T={T}, k={k}, N={N}, model={model}\", end=\" \")\n",
    "        raw_data, train_data, test_data, indexes, x_name, y_name = get_dataset(dataset, N, split=0.8)\n",
    "        kwargs['temperature'] = T\n",
    "        kwargs['selector_k'] = k\n",
    "        pool=None\n",
    "        if isinstance(model, bolift.AskTellGPR):\n",
    "            pool = bolift.Pool(raw_data[x_name][indexes].tolist())\n",
    "        asktell = get_asktell(model, kwargs=kwargs, pool=pool) #, knn=5)\n",
    "        x, y, yhat =  run_ablation_experiment(asktell, train_data, test_data, system_message=system_message)\n",
    "        save_csv(out_csv_file, x, y, yhat, dataset, model, T, k, N, model_class, asktell.tokens_used)\n",
    "        print(\" --> done\")\n",
    "\n",
    "def save_backup(out_csv_file):\n",
    "    if os.path.exists(f\"{out_csv_file}.csv\"):\n",
    "        i = 1\n",
    "        while os.path.exists(f\"{out_csv_file}{i}.csv\"):\n",
    "            i += 1\n",
    "        os.rename(f\"{out_csv_file}.csv\", f\"{out_csv_file}{i}.csv\")\n",
    "\n",
    "def merge_exps(out_csv_file):\n",
    "    save_backup(out_csv_file)\n",
    "    all_files = glob.glob(\"regression-results_exp*.csv\")\n",
    "    exps = []\n",
    "\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0, sep=\";\")\n",
    "        exps.append(df)\n",
    "\n",
    "    frame = pd.concat(exps, axis=0, ignore_index=True)\n",
    "    frame.to_csv(f\"{out_csv_file}.csv\", index=False, sep=\";\")\n",
    "\n",
    "    for filename in all_files:\n",
    "        os.remove(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config experiment\n",
    "\n",
    "These values and datasets should be loaded accordingly with the experiments that are being done.\n",
    "The union of all values considered in our experiments is available below.\n",
    "    \n",
    "```python\n",
    "T_list = [0.01, 0.1, 0.7, 1.0]\n",
    "k_list = [1, 2, 3, 4, 5]\n",
    "N_list = [1, 2, 5, 10, 50, 100, 250, 500, 700, 1000]\n",
    "models_list = [\"gpt-3.5-turbo-instruct\", \"gpt-3.5-turbo-0125\", \"gpt-4-0125-preview\", \"gpt-4o\" \"davinci-002\", \"KNN\", \"RNN\", \"GPR\", \"FineTunning\"]\n",
    "out_csv_file = \"regression_results.csv\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = {\n",
    "    \"exp_1\" : {\n",
    "        \"T_list\" : [0.05],\n",
    "        \"k_list\" : [1, 2, 5, 10],\n",
    "        \"N_list\" : [1000],\n",
    "        \"models_list\" : [\"gpt-3.5-turbo-0125\", \"gpt-4-0125-preview\", \"gpt-4o\"],\n",
    "        \"out_csv_file\" : \"regression-results1.csv\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in-house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=\"in-house\"\n",
    "kwargs = dict(\n",
    "    prefix=\"\",\n",
    "    prompt_template=PromptTemplate(\n",
    "        input_variables=[\"x\", \"y\", \"y_name\"],\n",
    "        template=\"Q: What is the {y_name} of {x}?@@@\\nA: {y}###\",\n",
    "    ),\n",
    "    suffix=\"What is the {y_name} of {x}?@@@\\nA:\",\n",
    "    x_formatter=lambda x: f\"experimental procedure: {x}\",\n",
    "    y_name=\"CO STY\",\n",
    "    y_formatter=lambda y: f\"{y:.2f}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=\"ocm\"\n",
    "# dataset=\"biasfree_ocm\"\n",
    "kwargs = dict(\n",
    "    # prefix=\"You are a bot who knows chemistry and catalysts. \" \\\n",
    "    #         \"Below, you'll see examples of experimental procedures to synthesize catalysts and the measured C2 yield in a oxidative methane coupling reaction. \" \\\n",
    "    #         \"The following question should be answered with a number and finished with ###\\n\",\n",
    "    prefix=\"\",\n",
    "    prompt_template=PromptTemplate(\n",
    "        input_variables=[\"x\", \"y\", \"y_name\"],   \n",
    "        template=\"Q: What is the {y_name} of {x}?@@@\\nA: {y}###\",\n",
    "    ),\n",
    "    suffix=\"What is the {y_name} of {x}?@@@\\nA:\",\n",
    "    x_formatter=lambda x: f\"experimental procedure: {x}\",\n",
    "    y_name=\"C2 yield\",\n",
    "    y_formatter=lambda y: f\"{y:.2f}\",\n",
    ")\n",
    "\n",
    "inv_system_message_path = \"./prompts/inv_prompt_1.txt\"\n",
    "system_message_path = \"./prompts/prompt_1.txt\"\n",
    "\n",
    "exps = {\n",
    "    # \"exp_1\" : { # Experiment 1 -> Varying k\n",
    "    #     \"T_list\" : [0.05],\n",
    "    #     \"k_list\" : [1, 2, 5, 10],\n",
    "    #     \"N_list\" : [1000],\n",
    "    #     \"models_list\" : [\"gpt-3.5-turbo-0125\"],\n",
    "    #     \"out_csv_file\" : \"regression-results_exp1.csv\",\n",
    "    # },\n",
    "    # \"exp_2\": { # Experiment 2 -> Varying T\n",
    "    #     \"T_list\" : [0.01, 0.1, 0.5, 0.7, 1.0, 1.5],\n",
    "    #     \"k_list\" : [5],\n",
    "    #     \"N_list\" : [1000],\n",
    "    #     \"models_list\" : [\"gpt-3.5-turbo-0125\"],\n",
    "    #     \"out_csv_file\" : \"regression-results_exp2.csv\",\n",
    "    # },\n",
    "    # \"exp_3\": { # Experiment 3 -> Varying N\n",
    "    #     \"T_list\" : [0.7],\n",
    "    #     \"k_list\" : [5],\n",
    "    #     \"N_list\" : [1, 5, 10, 25, 50, 100, 250, 500, 1000],\n",
    "    #     \"models_list\" : [\"gpt-3.5-turbo-0125\"],\n",
    "    #     \"out_csv_file\" : \"regression-results_exp3.csv\",\n",
    "    # },\n",
    "    \"exp_4\": { # Experiment 4 -> Varying the model\n",
    "        \"T_list\" : [0.7],\n",
    "        \"k_list\" : [5],\n",
    "        \"N_list\" : [1000],\n",
    "        # \"models_list\" : [\"gpt-4o\", \"gpt-3.5-turbo-0125\", \"gpt-4-0125-preview\", \"gpr\"],\n",
    "        \"models_list\" : [\"gpt-3.5-turbo-0125\", \"gpt-3.5-turbo-instruct\", \"gpr\"],\n",
    "        \"out_csv_file\" : \"regression-results_exp4.csv\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solubility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=\"sol\"\n",
    "kwargs = dict(\n",
    "    prefix=\"\",\n",
    "    prompt_template=PromptTemplate(\n",
    "        input_variables=[\"x\", \"y\", \"y_name\"],\n",
    "        template=\"Q: What is the {y_name} of {x}?@@@\\nA: {y}###\",\n",
    "    ),\n",
    "    suffix=\"What is the {y_name} of {x}?@@@\\nA:\",\n",
    "    x_formatter=lambda x: f\"iupac name {x}\",\n",
    "    y_name=\"measured log solubility in mols per litre\",\n",
    "    y_formatter=lambda y: f\"{y:.2f}\",\n",
    ")\n",
    "\n",
    "\n",
    "# inv_system_message_path = \"./prompts/inv_prompt_1.txt\"\n",
    "system_message_path = \"./prompts/prompt_sol.txt\"\n",
    "\n",
    "exps = {\n",
    "    # \"exp_1\" : { # Experiment 1 -> Varying k\n",
    "    #     \"T_list\" : [0.05],\n",
    "    #     \"k_list\" : [1, 2, 5, 10],\n",
    "    #     \"N_list\" : [700],\n",
    "    #     \"models_list\" : [\"gpt-3.5-turbo-0125\"],\n",
    "    #     \"out_csv_file\" : \"regression-results_exp1.csv\",\n",
    "    # },\n",
    "    # \"exp_2\": { # Experiment 2 -> Varying T\n",
    "    #     \"T_list\" : [0.01, 0.1, 0.5, 1.0],\n",
    "    #     \"k_list\" : [5],\n",
    "    #     \"N_list\" : [700],\n",
    "    #     \"models_list\" : [\"gpt-3.5-turbo-0125\"],\n",
    "    #     \"out_csv_file\" : \"regression-results_exp2.csv\",\n",
    "    # },\n",
    "    # \"exp_3\": { # Experiment 3 -> Varying N\n",
    "    #     \"T_list\" : [0.7],\n",
    "    #     \"k_list\" : [5],\n",
    "    #     \"N_list\" : [1, 5, 10, 25, 50, 100, 250, 500, 700],\n",
    "    #     \"models_list\" : [\"gpt-3.5-turbo-0125\"],\n",
    "    #     \"out_csv_file\" : \"regression-results_exp3.csv\",\n",
    "    # },\n",
    "    \"exp_4\": { # Experiment 4 -> Varying the model\n",
    "        \"T_list\" : [0.7],\n",
    "        \"k_list\" : [5],\n",
    "        \"N_list\" : [700],\n",
    "        # \"models_list\" : [\"gpt-3.5-turbo-instruct\", \"davinci-002\", \"gpt-4-0125-preview\"],\n",
    "        \"models_list\" : [\"knn\", \"krr\"],\n",
    "        \"out_csv_file\" : \"regression-results_exp4_sol.csv\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment 1\n",
      "Running sol topk ablation with T=0.7, k=5, N=700, model=knn  --> done\n",
      "Running sol topk ablation with T=0.7, k=5, N=700, model=krr "
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "AskTellFewShot.__init__() got an unexpected keyword argument 'knn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m exps:\n\u001b[1;32m      8\u001b[0m     exp \u001b[38;5;241m=\u001b[39m exps[e]\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m merge_exps(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msol-regression-models_test\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(exp, dataset, system_message, *args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, bolift\u001b[38;5;241m.\u001b[39mAskTellGPR):\n\u001b[1;32m     15\u001b[0m     pool \u001b[38;5;241m=\u001b[39m bolift\u001b[38;5;241m.\u001b[39mPool(raw_data[x_name][indexes]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m---> 16\u001b[0m asktell \u001b[38;5;241m=\u001b[39m \u001b[43mget_asktell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#, knn=5)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m x, y, yhat \u001b[38;5;241m=\u001b[39m  run_ablation_experiment(asktell, train_data, test_data, system_message\u001b[38;5;241m=\u001b[39msystem_message)\n\u001b[1;32m     18\u001b[0m save_csv(out_csv_file, x, y, yhat, dataset, model, T, k, N, model_class, asktell\u001b[38;5;241m.\u001b[39mtokens_used)\n",
      "Cell \u001b[0;32mIn[5], line 32\u001b[0m, in \u001b[0;36mget_asktell\u001b[0;34m(model, kwargs, pool, knn)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkrr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     31\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbolift\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAskTellRidgeKernelRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01m_\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/bolift/lib/python3.10/site-packages/bolift/asktellRidgeRegression.py:8\u001b[0m, in \u001b[0;36mAskTellRidgeKernelRegression.__init__\u001b[0;34m(self, alpha, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m=\u001b[39m alpha\n",
      "File \u001b[0;32m~/miniconda3/envs/bolift/lib/python3.10/site-packages/bolift/asktellGPR.py:27\u001b[0m, in \u001b[0;36mAskTellGPR.__init__\u001b[0;34m(self, n_components, pool, cache_path, n_neighbors, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cache_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# Forcing exemple_selector to not build context\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_regressor()\n",
      "\u001b[0;31mTypeError\u001b[0m: AskTellFewShot.__init__() got an unexpected keyword argument 'knn'"
     ]
    }
   ],
   "source": [
    "if os.path.exists(system_message_path):\n",
    "    with open(system_message_path, \"r\") as f:\n",
    "        system_message = f.read()\n",
    "\n",
    "for i in range(2):\n",
    "    print(f\"Running experiment {i+1}\")\n",
    "    for e in exps:\n",
    "        exp = exps[e]\n",
    "        run_experiment(exp, dataset, system_message, **kwargs)\n",
    "\n",
    "    merge_exps(\"sol-regression-models_test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sol-regression-models.csv\", sep=\";\")\n",
    "df = df[df.model == \"gpt-4o\"]\n",
    "\n",
    "# plot y by yhat\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.scatterplot(data=df, x=\"y\", y=\"yhat\", hue=\"model\", style=\"model\")\n",
    "plt.plot([0, 20], [0, 20], color=\"black\", linestyle=\"--\")\n",
    "plt.xlabel(\"True value\")\n",
    "plt.ylabel(\"Predicted value\")\n",
    "plt.legend().remove()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test of the last regression experiment\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lim=(min(y)-1,max(y)+1)\n",
    "# lim=(-20,40)\n",
    "plt.plot(lim, lim)\n",
    "plt.xlim(lim)\n",
    "plt.ylim(lim)\n",
    "# plt.scatter(X_test[:,0], [yhi.mean() for yhi in yhat], color=\"red\", alpha=0.2)\n",
    "# plt.scatter(X_test[:,0], y, color=\"blue\", alpha=0.2)\n",
    "# plt.scatter(X_train[:,0],train_data['completion'].to_list(), color=\"green\", alpha=0.2)\n",
    "plt.scatter(y, [yhi.mean() for yhi in yhat], color=\"red\", alpha=0.2)\n",
    "plt.scatter(train_data['completion'].to_list(),train_data['completion'].to_list())\n",
    "# plt.errorbar(y, \n",
    "#             [yhi.mean() for yhi in yhat], \n",
    "#             yerr=[yhi.std() for yhi in yhat],\n",
    "#             fmt='.', color='gray', alpha=0.4)\n",
    "plt.text(lim[0] + 0.1*(max(y)-min(y)), lim[1] - 1*0.1*(max(y)-min(y)), f\"correlation = {np.corrcoef(y, [yhi.mean() for yhi in yhat])[0,1]:.3f}\")\n",
    "plt.text(lim[0] + 0.1*(max(y)-min(y)), lim[1] - 2*0.1*(max(y)-min(y)), f\"MAE = {mean_absolute_error(y, [yhi.mean() for yhi in yhat]):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "import uncertainty_toolbox as uct\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as font_manager\n",
    "urllib.request.urlretrieve('https://github.com/google/fonts/raw/main/ofl/ibmplexmono/IBMPlexMono-Regular.ttf', 'IBMPlexMono-Regular.ttf')\n",
    "fe = font_manager.FontEntry(\n",
    "    fname='IBMPlexMono-Regular.ttf',\n",
    "    name='plexmono')\n",
    "font_manager.fontManager.ttflist.append(fe)\n",
    "plt.rcParams.update({'axes.facecolor':'#f5f4e9',\n",
    "            'grid.color' : '#AAAAAA',\n",
    "            'axes.edgecolor':'#333333',\n",
    "            'figure.facecolor':'#FFFFFF',\n",
    "            'axes.grid': False,\n",
    "            'axes.prop_cycle':   plt.cycler('color', plt.cm.Dark2.colors),\n",
    "            'font.family': fe.name,\n",
    "            'figure.figsize': (3.5,3.5 / 1.2),\n",
    "            'ytick.left': True,\n",
    "            'xtick.bottom': True\n",
    "           })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sol-regression-models.csv\", sep=';')\n",
    "# df = pd.read_csv(\"ocm-regression-results1.csv\", sep=';')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['data'] == 'ocm')].groupby(['Temperature', 'data', 'k_selected', 'model_class', \"N_train\", \"model\"]).size().reset_index().sort_values(by=[\"model_class\", \"Temperature\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def mse(y, pred):\n",
    "  # return np.mean((y-pred)**2)\n",
    "  return mean_squared_error(y, pred)\n",
    "\n",
    "def mae(y, pred):\n",
    "  return mean_absolute_error(y, pred)\n",
    "\n",
    "def r2(y, pred):\n",
    "  return r2_score(y, pred)\n",
    "\n",
    "def corr(y, pred):\n",
    "  return np.corrcoef(y, pred)[0,1]\n",
    "\n",
    "def acc(y, pred, threshold):\n",
    "  acc = sum((abs(pred - y)<threshold))/len(pred)\n",
    "  return acc\n",
    "\n",
    "def log_likelihood(y, pred, ystd, eps=0):\n",
    "  y = np.array(y)\n",
    "  pred = np.array(pred)\n",
    "  ystd = np.array(ystd)\n",
    "  yvar = ystd**2 + eps\n",
    "  neg_ll = 0.5 * (np.log(yvar) + ((y - pred)**2 / yvar))\n",
    "  return np.sum(neg_ll)/len(y)\n",
    "\n",
    "def select_df(df, data, k, T, model, model_class, N):\n",
    "  config = {'k': k,\n",
    "            'T': T,\n",
    "            'data': data,\n",
    "            'model': model,\n",
    "            'model_class': model_class,\n",
    "            'N': N,\n",
    "            }\n",
    "\n",
    "  q = f\"\"\n",
    "  if T != 'any':\n",
    "    q += f\"Temperature=={T} and \"\n",
    "  if k != 'any':  \n",
    "    q+= f\"k_selected=={k} and \"\n",
    "  if model != 'any': \n",
    "    q+= f\"model=='{model}' and \"\n",
    "  q+= f\"model_class=='{model_class}' and \"\n",
    "  if N != 'any':\n",
    "    q+= f\"N_train=={N} and \"\n",
    "  q += f\"data=='{data}'\"\n",
    "  sel = df.query(q)\n",
    "  if sel.empty:\n",
    "    raise ValueError(f\"Dataframe is empty for the configuration {config}\")\n",
    "  return sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_parities(df, data_property, data_range, nrows, ncols, data=None, k=None, T=None, model=None, model_class=None, N=None, axis_name=None, calibration=None, recal_ind=1, out_name=None, GPR=False):\n",
    "  config = {'k': k,\n",
    "            'T': T,\n",
    "            'data': data,\n",
    "            'model': model,\n",
    "            'model_class': model_class,\n",
    "            'N': N,\n",
    "            }\n",
    "\n",
    "  if sum([1 for i in config.values() if i is None]) > 1:\n",
    "    raise ValueError(\"Only the property being varied in data_range can me passed as None.\")\n",
    "\n",
    "  if nrows*ncols < len(data_range):\n",
    "    raise ValueError('''There's not enough space to plat all data in data_range.\n",
    "    Decrease the size of data_range or increase ncols or nrows.''')\n",
    "\n",
    "  fig, axs = plt.subplots(nrows=nrows, ncols=ncols, sharey=False, figsize=(12, 4), dpi=600)\n",
    "  for i, p in enumerate(data_range):\n",
    "    config[data_property] = p\n",
    "    y=[]\n",
    "    yhat=[]\n",
    "    yprob=[]\n",
    "    ax = axs if ncols*nrows == 1 else axs.flatten()[i]\n",
    "\n",
    "    df_sel = select_df(df, **config)\n",
    "\n",
    "    for prompt in df_sel['x'].unique():\n",
    "        y.append(df_sel[df_sel['x']==prompt]['y'].unique()[0])\n",
    "        # max_p = np.argmax(df_sel[df_sel['y']==d]['yprobs'].values)\n",
    "        yhat.append(df_sel[df_sel['x']==prompt]['yhat'].values)\n",
    "        yprob.append(df_sel[df_sel['x']==prompt]['yprobs'].values)\n",
    "    yprobs = [yhi.std() for yhi in yhat]\n",
    "    if GPR:\n",
    "        ymeans = np.array([yhi.mean() for yhi in yhat])\n",
    "        ystds = np.array([ypi.mean() for ypi in yprob])\n",
    "    else:\n",
    "        ymeans = np.array([\n",
    "                  np.sum(yhi*ypi) if len(yhi)>1 else yhi.mean()\n",
    "                  for yhi,ypi in zip(yhat, yprob)\n",
    "                ])\n",
    "        ystds = np.array([\n",
    "                  np.sqrt(np.sum((yhi-ymi)**2*ypi)) if np.sum((yhi-ymi)**2*ypi)>1 else 0.1 #ypi.mean()\n",
    "                  for yhi,ypi,ymi in zip(yhat, yprob, ymeans)\n",
    "                ])\n",
    "\n",
    "    if calibration:\n",
    "        if calibration == \"scaling_factor\":\n",
    "          std_scaling = uct.recalibration.optimize_recalibration_ratio(ymeans[:recal_ind], ystds[:recal_ind], np.array(y[:recal_ind]),\n",
    "                                                                        criterion=\"miscal\")\n",
    "          ystds = ystds * std_scaling\n",
    "        elif calibration == \"isotonic\":\n",
    "          exp_props, obs_props= uct.metrics_calibration.get_proportion_lists_vectorized(ymeans[:recal_ind], ystds[:recal_ind], np.array(y[:recal_ind]))\n",
    "          recal_model = uct.recalibration.iso_recal(exp_props, obs_props)\n",
    "          recal_bounds = uct.metrics_calibration.get_prediction_interval(ymeans, ystds, 0.95, recal_model)\n",
    "          ystds=np.array([ymeans - recal_bounds.lower,\n",
    "                 recal_bounds.upper - ymeans])\n",
    "\n",
    "    ax.plot(y,y)\n",
    "    ax.errorbar(y, \n",
    "                ymeans, \n",
    "                yerr=ystds,\n",
    "                fmt='.', color='gray', alpha=0.3)\n",
    "    ax.scatter(\n",
    "        y, ymeans, s=6, alpha=1, color=f\"C{i}\"\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f\"{data_property}={p}\")\n",
    "\n",
    "    lim = (min(y), max(y))\n",
    "    \n",
    "    if model_class in [\"KRR\", \"KNN\"]:\n",
    "       metrics = {\n",
    "          \"accuracy\": uct.metrics.get_all_accuracy_metrics(ymeans, np.array(y), verbose=False)\n",
    "                  }\n",
    "    else:\n",
    "        metrics = uct.metrics.get_all_metrics(ymeans, ystds, np.array(y), verbose=False)\n",
    "    ax.text(lim[0] + 0.1*(max(y)-min(y)), lim[1] - 1*0.1*(max(y)-min(y)), f\"$(\\\\uparrow$)correlation = {metrics['accuracy']['corr']:.3f}\")\n",
    "    if model_class not in [\"KRR\", \"KNN\"]:\n",
    "      ax.text(lim[0] + 0.1*(max(y)-min(y)), lim[1] - 2*0.1*(max(y)-min(y)), f\"$(\\\\downarrow$)neg-ll = {metrics['scoring_rule']['nll']:.3f}\")\n",
    "    ax.text(lim[0] + 0.1*(max(y)-min(y)), lim[1] - 3*0.1*(max(y)-min(y)), f\"$(\\\\downarrow$)MAE = {metrics['accuracy']['mae']:.3f}\")\n",
    "\n",
    "    ax.set_ylim(lim[0],lim[1])\n",
    "    ax.set_xlim(lim[0],lim[1])\n",
    "\n",
    "    ax.set_xlabel(f\"measured {axis_name}\")\n",
    "    if (i%ncols==0):\n",
    "      ax.set_ylabel(f\"predicted {axis_name}\")\n",
    "\n",
    "  # plt.tight_layout()\n",
    "  plt.show()\n",
    "  # if (out_name):\n",
    "  #   plt.savefig(f\"figs/{out_name}\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ablation(df, data_property, data_range, nrows, ncols, data=None, k=None, T=None, model=None, model_class=None, N=None, out_name=None, GPR=False):\n",
    "  config = {'k': k,\n",
    "            'T': T,\n",
    "            'data': data,\n",
    "            'model': model,\n",
    "            'model_class': model_class,\n",
    "            'N': N,\n",
    "            }\n",
    "\n",
    "  MAE_list = []\n",
    "  RMSE_list = []\n",
    "  r_list = []\n",
    "  nll_list = []\n",
    "  prop_list = []\n",
    "  for i, p in enumerate(data_range):\n",
    "    config[data_property] = p\n",
    "    y=[]\n",
    "    yhat=[]\n",
    "    yprobs=[]\n",
    "    yprob=[]\t\n",
    "\n",
    "    df_sel = select_df(df, **config)\n",
    "\n",
    "    for prompt in df_sel['x'].unique():\n",
    "        y.append(df_sel[df_sel['x']==prompt]['y'].unique()[0])\n",
    "        # max_p = np.argmax(df_sel[df_sel['y']==d]['yprobs'].values)\n",
    "        yhat.append(df_sel[df_sel['x']==prompt]['yhat'].values)\n",
    "        yprob.append(df_sel[df_sel['x']==prompt]['yprobs'].values)\n",
    "    yprobs = [yhi.std() for yhi in yhat]\n",
    "    if GPR:\n",
    "        ymeans = np.array([yhi.mean() for yhi in yhat])\n",
    "        ystds = np.array([ypi.mean() for ypi in yprob])\n",
    "    else:\n",
    "        ymeans = np.array([\n",
    "                  np.sum(yhi*ypi) if len(yhi)>1 else yhi.mean()\n",
    "                  for yhi,ypi in zip(yhat, yprob)\n",
    "                ])\n",
    "        ystds = np.array([\n",
    "                  np.sqrt(np.sum((yhi-ymi)**2*ypi)) if yhi.std()>1 else ypi.mean()\n",
    "                  for yhi,ypi,ymi in zip(yhat, yprob, ymeans)\n",
    "                ])\n",
    "\n",
    "    metrics = uct.metrics.get_all_metrics(ymeans, ystds, np.array(y), verbose=False)\n",
    "    r_list.append(metrics['accuracy']['corr'])\n",
    "    RMSE_list.append(metrics['accuracy']['rmse'])\n",
    "    MAE_list.append(metrics['accuracy']['mae'])\n",
    "    nll_list.append(metrics['scoring_rule']['nll'])\n",
    "    prop_list.append(p)\n",
    "    print(f\"{model_class}(N:{config['N']}/k:{config['k']}/T:{config['T']}) => RMSE: | MAE: {MAE_list[-1]} | r: {r_list[-1]} | nll: {nll_list[-1]}\")\n",
    "\n",
    "  fig, axs = plt.subplots(nrows=nrows, ncols=ncols, sharey=False, figsize=(4*ncols, 4*nrows), dpi=300)\n",
    "  \n",
    "  axs[0].plot(prop_list, MAE_list)\n",
    "  axs[0].set_xlabel(data_property)\n",
    "  axs[0].set_ylabel(\"$\\\\rightarrow$MAE\")\n",
    "  \n",
    "  axs[1].plot(prop_list, r_list)\n",
    "  axs[1].set_xlabel(data_property)\n",
    "  axs[1].set_ylabel(\"$\\\\leftarrow$correlation\")\n",
    "\n",
    "  axs[2].plot(prop_list, nll_list)\n",
    "  axs[2].set_xlabel(data_property)\n",
    "  axs[2].set_yscale('log')\n",
    "  axs[2].set_ylabel(\"$\\\\rightarrow$negative log-likelihood\")\n",
    "\n",
    "  plt.tight_layout()\n",
    "  # plt.show()\n",
    "  if (out_name):\n",
    "    plt.savefig(f\"figs/{out_name}\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_ablation_data(df, data_property, data_range, data=None, k=None, T=None, model=None, model_class=None, N=None, GPR=False):\n",
    "  config = {'k': k,\n",
    "          'T': T,\n",
    "          'data': data,\n",
    "          'model': model,\n",
    "          'model_class': model_class,\n",
    "          'N': N,\n",
    "          }\n",
    "   \n",
    "  MAE_list = []\n",
    "  RMSE_list = []\n",
    "  r_list = []\n",
    "  nll_list = []\n",
    "  prop_list = []\n",
    "  for i, p in enumerate(data_range):\n",
    "    config[data_property] = p\n",
    "    y=[]\n",
    "    yhat=[]\n",
    "    yprobs=[]\n",
    "    yprob=[]\n",
    "\n",
    "    df_sel = select_df(df, **config)\n",
    "\n",
    "    for prompt in df_sel['x'].unique():\n",
    "        y.append(df_sel[df_sel['x']==prompt]['y'].unique()[0])\n",
    "        # max_p = np.argmax(df_sel[df_sel['y']==d]['yprobs'].values)\n",
    "        yhat.append(df_sel[df_sel['x']==prompt]['yhat'].values)\n",
    "        yprob.append(df_sel[df_sel['x']==prompt]['yprobs'].values)\n",
    "    yprobs = [yhi.std() for yhi in yhat]\n",
    "    if GPR:\n",
    "        ymeans = np.array([yhi.mean() for yhi in yhat])\n",
    "        ystds = np.array([ypi.mean() for ypi in yprob])\n",
    "    else:\n",
    "        ymeans = np.array([\n",
    "                  np.sum(yhi*ypi) if len(yhi)>1 else yhi.mean()\n",
    "                  for yhi,ypi in zip(yhat, yprob)\n",
    "                ])\n",
    "        ystds = np.array([\n",
    "                  np.sqrt(np.sum((yhi-ymi)**2*ypi)) if np.sum((yhi-ymi)**2*ypi)>0 else 10\n",
    "                  for yhi,ypi,ymi in zip(yhat, yprob, ymeans)\n",
    "                ])\n",
    "\n",
    "    if model_class in [\"KRR\", \"KNN\"]:\n",
    "       metrics = {\n",
    "          \"accuracy\": uct.metrics.get_all_accuracy_metrics(ymeans, np.array(y), verbose=False)\n",
    "                  }\n",
    "    else:\n",
    "      metrics = uct.metrics.get_all_metrics(ymeans, ystds, np.array(y), verbose=False)\n",
    "      nll_list.append(metrics['scoring_rule']['nll'])\n",
    "    r_list.append(metrics['accuracy']['corr'])\n",
    "    RMSE_list.append(metrics['accuracy']['rmse'])\n",
    "    MAE_list.append(metrics['accuracy']['mae'])\n",
    "    prop_list.append(p)\n",
    "    with open(\"Table.tex\", \"a\") as t:\n",
    "      t.write(f\"{config['data']}&{model_class}&{model}&{config['T']}&{config['k']}&{config['N']}&{RMSE_list[-1]}&{MAE_list[-1]}&{r_list[-1]}&{nll_list[-1] if nll_list else '-'}&\\\\\\\\\\n\")\n",
    "    # print(f\"{model_class}(N:{config['N']}/k:{config['k']}/T:{config['T']}) => RMSE: | MAE: {MAE_list[-1]} | r: {r_list[-1]} | nll: {nll_list[-1]}\")\n",
    "   \n",
    "  return prop_list, MAE_list, r_list, nll_list\n",
    "\n",
    "def create_sub_ablation(axs, df, lims, data_property, data_range, color='C0', data=None, k=None, T=None, model=None, model_class=None, N=None, label=False, GPR=False):\n",
    "  config = {'k': k,\n",
    "            'T': T,\n",
    "            'data': data,\n",
    "            'model': model,\n",
    "            'model_class': model_class,\n",
    "            'N': N,\n",
    "            }\n",
    "\n",
    "  prop_list, MAE_list, r_list, nll_list = get_sub_ablation_data(df, data_property, data_range, **config, GPR=GPR)\n",
    "\n",
    "  for ax in axs:\n",
    "    ax.label_outer()\n",
    "\n",
    "  if label:\n",
    "    if model_class==\"GPR-BOT\":\n",
    "      axs[0].plot(prop_list, MAE_list, label=\"GPR\", color=color)\n",
    "    else:\n",
    "      axs[0].plot(prop_list, MAE_list, label=model_class, color=color)\n",
    "  else:\n",
    "    axs[0].plot(prop_list, MAE_list, color=color)\n",
    "  axs[0].set_ylabel(\"MAE\\n$\\leftarrow$\")\n",
    "  axs[0].set_ylim(lims[0])\n",
    "  axs[0].set_label(model_class)\n",
    "  \n",
    "  axs[1].plot(prop_list, r_list, color=color)\n",
    "  axs[1].set_xlabel(data_property)\n",
    "  axs[1].set_ylabel(\"r\\n$\\\\rightarrow$\")\n",
    "  axs[1].set_ylim(lims[1])\n",
    "  axs[1].set_label(model_class)\n",
    "\n",
    "  if False: #model_class not in [\"KRR\", \"KNN\"]:\n",
    "    axs[2].plot(prop_list, nll_list, color=color)\n",
    "    axs[2].set_xlabel(data_property)\n",
    "    axs[2].set_yscale('log')\n",
    "    axs[2].set_ylabel(\"neg-ll\\n$\\leftarrow$\")\n",
    "    # axs[1].set_label(model_class)\n",
    "\n",
    "  for ax in axs:\n",
    "    ax.label_outer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub_shadow(axs, df, lims, data_property, data_range, color='C0', data=None, k=None, T=None, model=None, model_class=None, N=None, label=False, GPR=False):\n",
    "\n",
    "    all_MAE = []\n",
    "    all_r = []\n",
    "    config = {'k': k,\n",
    "            'T': T,\n",
    "            'data': data,\n",
    "            'model': model,\n",
    "            'model_class': model_class,\n",
    "            'N': N,\n",
    "            }\n",
    "\n",
    "    for i in range(1, 6):  # Loop through the 5 CSV files\n",
    "        df = pd.read_csv(f\"{data}-regression-results{i}.csv\", sep=';')\n",
    "        df_sel = select_df(df, **config)\n",
    "        \n",
    "        prop_list, MAE_list, r_list, nll_list = get_sub_ablation_data(df_sel, data_property, data_range, data=data, k=k, T=T, model=model, model_class=model_class, N=N)\n",
    "\n",
    "        all_MAE.append(MAE_list)\n",
    "        all_r.append(r_list)\n",
    "\n",
    "    all_MAE = np.array(all_MAE)\n",
    "    all_r = np.array(all_r)\n",
    "\n",
    "    # Compute average MAE and r\n",
    "    avg_MAE = np.mean(all_MAE, axis=0)\n",
    "    avg_r = np.mean(all_r, axis=0)\n",
    "\n",
    "    # Compute min and max for uncertainty region\n",
    "    min_MAE = np.min(all_MAE, axis=0)\n",
    "    max_MAE = np.max(all_MAE, axis=0)\n",
    "    min_r = np.min(all_r, axis=0)\n",
    "    max_r = np.max(all_r, axis=0)\n",
    "\n",
    "    # Plot average curve with uncertainty region\n",
    "    axs[0].fill_between(prop_list, min_MAE, max_MAE, color=color, alpha=0.3)\n",
    "    axs[0].plot(prop_list, avg_MAE, color=color)\n",
    "    axs[0].set_ylabel(\"MAE\\n$\\leftarrow$\")\n",
    "    axs[0].set_ylim(lims[0])\n",
    "    axs[0].legend()\n",
    "\n",
    "    axs[1].fill_between(prop_list, min_r, max_r, color=color, alpha=0.3)\n",
    "    axs[1].plot(prop_list, avg_r, color=color)\n",
    "    axs[1].set_ylabel(\"r\\n$\\\\rightarrow$\")\n",
    "    axs[1].set_ylim(lims[1])\n",
    "    axs[1].legend()\n",
    "\n",
    "    axs[1].set_xlabel(data_property)\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.label_outer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_parity_data():\n",
    "   pass\n",
    "   \n",
    "\n",
    "def create_sub_parity(ax, df_sel, axis_name, model_class, lim=[-1,1], color='gray', GPR=False, title=None, calibration=None, recal_ind=0):\n",
    "    y=[]\n",
    "    yhat=[]\n",
    "    yprob=[]\n",
    "    for prompt in df_sel['x'].unique():\n",
    "        y.append(df_sel[df_sel['x']==prompt]['y'].unique()[0])\n",
    "        # max_p = np.argmax(df_sel[df_sel['y']==d]['yprobs'].values)\n",
    "        yhat.append(df_sel[df_sel['x']==prompt]['yhat'].values)\n",
    "        yprob.append(df_sel[df_sel['x']==prompt]['yprobs'].values)\n",
    "    yprobs = [yhi.std() for yhi in yhat]\n",
    "    if GPR:\n",
    "        ymeans = np.array([yhi.mean() for yhi in yhat])\n",
    "        ystds = np.array([ypi.mean() for ypi in yprob])\n",
    "    else:\n",
    "        ymeans = np.array([\n",
    "                  np.sum(yhi*ypi) if len(yhi)>1 else yhi.mean()\n",
    "                  for yhi,ypi in zip(yhat, yprob)\n",
    "                ])\n",
    "        ystds = np.array([\n",
    "                  np.sqrt(np.sum((yhi-ymi)**2*ypi)) if len(yhi)>1 else ypi.mean()\n",
    "                  for yhi,ypi,ymi in zip(yhat, yprob, ymeans)\n",
    "                ])\n",
    "        # hack to fix uncertainties in finetuned model. 3.559 is the training set (N=1000) std\n",
    "        ystds = np.array([ysi if ysi!=10 else 3.559 for ysi in ystds]) \n",
    "  \n",
    "    if calibration:\n",
    "        if calibration == \"scaling_factor\":\n",
    "          std_scaling = uct.recalibration.optimize_recalibration_ratio(ymeans[:recal_ind], ystds[:recal_ind], np.array(y[:recal_ind]),\n",
    "                                                                        criterion=\"miscal\")\n",
    "          ystds = ystds * std_scaling\n",
    "        elif calibration == \"isotonic\":\n",
    "          exp_props, obs_props= uct.metrics_calibration.get_proportion_lists_vectorized(ymeans[:recal_ind], ystds[:recal_ind], np.array(y[:recal_ind]))\n",
    "          recal_model = uct.recalibration.iso_recal(exp_props, obs_props)\n",
    "          recal_bounds = uct.metrics_calibration.get_prediction_interval(ymeans, ystds, 0.95, recal_model)\n",
    "          ystds=np.array([ymeans - recal_bounds.lower,\n",
    "                 recal_bounds.upper - ymeans])\n",
    "\n",
    "    if model_class in [\"KRR\", \"KNN\"] or calibration==\"isotonic\":\n",
    "       metrics = {\n",
    "          \"accuracy\": uct.metrics.get_all_accuracy_metrics(ymeans, np.array(y), verbose=False)\n",
    "                  }\n",
    "    else:\n",
    "      metrics = uct.metrics.get_all_metrics(ymeans, ystds, np.array(y), verbose=False)\n",
    "      ax.text(lim[0] + 0.1*(max(y)-min(y)), lim[1] - 2*0.1*(max(y)-min(y)), f\"$(\\\\downarrow$)neg-ll = {metrics['scoring_rule']['nll']:.3f}\")\n",
    "    ax.text(lim[0] + 0.1*(max(y)-min(y)), lim[1] - 1*0.1*(max(y)-min(y)), f\"$(\\\\uparrow$)correlation = {metrics['accuracy']['corr']:.3f}\")\n",
    "    ax.text(lim[0] + 0.1*(max(y)-min(y)), lim[1] - 3*0.1*(max(y)-min(y)), f\"$(\\\\downarrow$)MAE = {metrics['accuracy']['mae']:.3f}\")\n",
    "\n",
    "    # with open(\"Table.tex\", \"a\") as t:\n",
    "    #   t.write(f\"{config['data']}&{model_class}&{model}&{config['T']}&{config['k']}&{config['N']}&{RMSE_list[-1]}&{MAE_list[-1]}&{r_list[-1]}&{nll_list[-1] if nll_list else '-'}&\\\\\\\\\\n\")\n",
    "    # print(f\"{model_class}(N:{config['N']}/k:{config['k']}/T:{config['T']}) => RMSE: | MAE: {MAE_list[-1]} | r: {r_list[-1]} | nll: {nll_list[-1]}\")\n",
    "    print(metrics['accuracy']['rmse'])\n",
    "\n",
    "    ax.set_xlabel(f\"measured {axis_name}\")\n",
    "    ax.set_ylabel(f\"predicted {axis_name}\")\n",
    "    ax.set_ylim(lim[0],lim[1])\n",
    "    ax.set_xlim(lim[0],lim[1])\n",
    "    ax.set_xticks(np.arange(lim[0],lim[1]+0.1,4.0))\n",
    "\n",
    "    if title:\n",
    "      ax.set_title(title)\n",
    "\n",
    "    ax.plot(y,y)\n",
    "    ax.plot(lim,lim)\n",
    "    if model_class not in [\"KRR\", \"KNN\"]:\n",
    "      ax.errorbar(y, \n",
    "                  ymeans, \n",
    "                  yerr=ystds,\n",
    "                  fmt='.', color='gray', alpha=0.2)\n",
    "    ax.scatter(\n",
    "        y, ymeans, s=6, alpha=1, color=color\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = \"ocm\"\n",
    "max_N=1000\n",
    "\n",
    "fig = plt.figure(figsize=(16,6), constrained_layout=True)\n",
    "subfigs = fig.subfigures(1,3, wspace=0.1, hspace=0.1)\n",
    "\n",
    "lims = [(0,5),(0,1),(-1,1)]\n",
    "\n",
    "sub00 = subfigs[0].subplots(2,1, sharex=True, sharey=False)\n",
    "df1 = pd.read_csv(f\"{data}-regression-results1.csv\", sep=';')\n",
    "d01 = select_df(df1, data=data, k=5, T=0.7, model='gpt-3.5-turbo-0125', model_class='topk', N='any')\n",
    "create_sub_ablation(sub00, d01, lims, 'N', sorted(d01['N_train'].unique()), data=data, color='C1', k=5, T=0.7, model='gpt-3.5-turbo-0125', model_class='topk', N=None, label=False)\n",
    "df2 = pd.read_csv(f\"{data}-regression-results2.csv\", sep=';')\n",
    "d02 = select_df(df2, data=data, k=5, T=0.7, model='gpt-3.5-turbo-0125', model_class='topk', N='any')\n",
    "create_sub_ablation(sub00, d02, lims, 'N', sorted(d02['N_train'].unique()), data=data, color='C2', k=5, T=0.7, model='gpt-3.5-turbo-0125', model_class='topk', N=None, label=False)\n",
    "df3 = pd.read_csv(f\"{data}-regression-results3.csv\", sep=';')\n",
    "d03 = select_df(df3, data=data, k=5, T=0.7, model='gpt-3.5-turbo-0125', model_class='topk', N='any')\n",
    "create_sub_ablation(sub00, d03, lims, 'N', sorted(d03['N_train'].unique()), data=data, color='C3', k=5, T=0.7, model='gpt-3.5-turbo-0125', model_class='topk', N=None, label=False)\n",
    "df4 = pd.read_csv(f\"{data}-regression-results4.csv\", sep=';')\n",
    "d04 = select_df(df4, data=data, k=5, T=0.7, model='gpt-3.5-turbo-0125', model_class='topk', N='any')\n",
    "create_sub_ablation(sub00, d04, lims, 'N', sorted(d04['N_train'].unique()), data=data, color='C4', k=5, T=0.7, model='gpt-3.5-turbo-0125', model_class='topk', N=None, label=False)\n",
    "df5 = pd.read_csv(f\"{data}-regression-results5.csv\", sep=';')\n",
    "d05 = select_df(df5, data=data, k=5, T=0.7, model='gpt-3.5-turbo-0125', model_class='topk', N='any')\n",
    "create_sub_ablation(sub00, d05, lims, 'N', sorted(d05['N_train'].unique()), data=data, color='C5', k=5, T=0.7, model='gpt-3.5-turbo-0125', model_class='topk', N=None, label=False)\n",
    "\n",
    "\n",
    "sub02 = subfigs[1].subplots(2,1, sharex=True, sharey=False)\n",
    "df1 = pd.read_csv(f\"{data}-regression-results1.csv\", sep=';')\n",
    "d01 = select_df(df1, data=data, k='any', T=0.05, model='gpt-3.5-turbo-0125', model_class='topk', N=10)\n",
    "create_sub_ablation(sub02, d01, lims, 'k', sorted(d01['k_selected'].unique()), data=data, color='C1', k='any', T=0.05, model='gpt-3.5-turbo-0125', model_class='topk', N=10, label=False)\n",
    "df2 = pd.read_csv(f\"{data}-regression-results2.csv\", sep=';')\n",
    "d02 = select_df(df2, data=data, k='any', T=0.05, model='gpt-3.5-turbo-0125', model_class='topk', N=10)\n",
    "create_sub_ablation(sub02, d02, lims, 'k', sorted(d02['k_selected'].unique()), data=data, color='C2', k='any', T=0.05, model='gpt-3.5-turbo-0125', model_class='topk', N=10, label=False)\n",
    "df3 = pd.read_csv(f\"{data}-regression-results3.csv\", sep=';')\n",
    "d03 = select_df(df3, data=data, k='any', T=0.05, model='gpt-3.5-turbo-0125', model_class='topk', N=10)\n",
    "create_sub_ablation(sub02, d03, lims, 'k', sorted(d03['k_selected'].unique()), data=data, color='C3', k='any', T=0.05, model='gpt-3.5-turbo-0125', model_class='topk', N=10, label=False)\n",
    "df4 = pd.read_csv(f\"{data}-regression-results4.csv\", sep=';')\n",
    "d04 = select_df(df4, data=data, k='any', T=0.05, model='gpt-3.5-turbo-0125', model_class='topk', N=10)\n",
    "create_sub_ablation(sub02, d04, lims, 'k', sorted(d04['k_selected'].unique()), data=data, color='C4', k='any', T=0.05, model='gpt-3.5-turbo-0125', model_class='topk', N=10, label=False)\n",
    "df5 = pd.read_csv(f\"{data}-regression-results5.csv\", sep=';')\n",
    "d05 = select_df(df5, data=data, k='any', T=0.05, model='gpt-3.5-turbo-0125', model_class='topk', N=10)\n",
    "create_sub_ablation(sub02, d05, lims, 'k', sorted(d05['k_selected'].unique()), data=data, color='C5', k='any', T=0.05, model='gpt-3.5-turbo-0125', model_class='topk', N=10, label=False)\n",
    "\n",
    "sub03 = subfigs[2].subplots(2,1, sharex=True, sharey=False)\n",
    "df1 = pd.read_csv(f\"{data}-regression-results1.csv\", sep=';')\n",
    "d01 = select_df(df1, data=data, k=5, T='any', model='gpt-3.5-turbo-0125', model_class='topk', N=max_N)\n",
    "create_sub_ablation(sub03, d01, lims, 'T', sorted(d01['Temperature'].unique()), data=data, color='C1', k=5, T='any', model='gpt-3.5-turbo-0125', model_class='topk', N=max_N, label=False)\n",
    "df2 = pd.read_csv(f\"{data}-regression-results2.csv\", sep=';')\n",
    "d02 = select_df(df2, data=data, k=5, T='any', model='gpt-3.5-turbo-0125', model_class='topk', N=max_N)\n",
    "create_sub_ablation(sub03, d02, lims, 'T', sorted(d02['Temperature'].unique()), data=data, color='C2', k=5, T='any', model='gpt-3.5-turbo-0125', model_class='topk', N=max_N, label=False)\n",
    "df3 = pd.read_csv(f\"{data}-regression-results3.csv\", sep=';')\n",
    "d03 = select_df(df3, data=data, k=5, T='any', model='gpt-3.5-turbo-0125', model_class='topk', N=max_N)\n",
    "create_sub_ablation(sub03, d03, lims, 'T', sorted(d03['Temperature'].unique()), data=data, color='C3', k=5, T='any', model='gpt-3.5-turbo-0125', model_class='topk', N=max_N, label=False)\n",
    "df4 = pd.read_csv(f\"{data}-regression-results4.csv\", sep=';')\n",
    "d04 = select_df(df4, data=data, k=5, T='any', model='gpt-3.5-turbo-0125', model_class='topk', N=max_N)\n",
    "create_sub_ablation(sub03, d04, lims, 'T', sorted(d04['Temperature'].unique()), data=data, color='C4', k=5, T='any', model='gpt-3.5-turbo-0125', model_class='topk', N=max_N, label=False)\n",
    "df5 = pd.read_csv(f\"{data}-regression-results5.csv\", sep=';')\n",
    "d05 = select_df(df5, data=data, k=5, T='any', model='gpt-3.5-turbo-0125', model_class='topk', N=max_N)\n",
    "create_sub_ablation(sub03, d05, lims, 'T', sorted(d05['Temperature'].unique()), data=data, color='C5', k=5, T='any', model='gpt-3.5-turbo-0125', model_class='topk', N=max_N, label=False)\n",
    "\n",
    "\n",
    "# fig.legend(loc='upper center', bbox_to_anchor=(0.5 ,0),\n",
    "#           fancybox=True, shadow=True, ncol=6)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f\"figs/metrics\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = \"ocm\"\n",
    "max_N = 1000\n",
    "\n",
    "fig = plt.figure(figsize=(16,6), constrained_layout=True)\n",
    "subfigs = fig.subfigures(1,3, wspace=0.1, hspace=0.1)\n",
    "\n",
    "lims = [(0,5),(0,1),(-1,1)]\n",
    "\n",
    "sub00 = subfigs[0].subplots(2,1, sharex=True, sharey=False)\n",
    "df1 = pd.read_csv(f\"{data}-regression-results1.csv\", sep=';')\n",
    "d01 = select_df(df1, data=data, k=5, T=0.7, model='gpt-3.5-turbo-0125', model_class='topk', N='any')\n",
    "create_sub_shadow(sub00, d01, lims, 'N', sorted(d01['N_train'].unique()), data=data, color='C1', k=5, T=0.7, model='gpt-3.5-turbo-0125', model_class='topk', N='any', label=False)\n",
    "\n",
    "sub02 = subfigs[1].subplots(2,1, sharex=True, sharey=False)\n",
    "df1 = pd.read_csv(f\"{data}-regression-results1.csv\", sep=';')\n",
    "d01 = select_df(df1, data=data, k='any', T=0.05, model='gpt-3.5-turbo-0125', model_class='topk', N=10)\n",
    "create_sub_shadow(sub02, d01, lims, 'k', sorted(d01['k_selected'].unique()), data=data, color='C1', k='any', T=0.05, model='gpt-3.5-turbo-0125', model_class='topk', N=10, label=False)\n",
    "\n",
    "sub03 = subfigs[2].subplots(2,1, sharex=True, sharey=False)\n",
    "df1 = pd.read_csv(f\"{data}-regression-results1.csv\", sep=';')\n",
    "d01 = select_df(df1, data=data, k=5, T='any', model='gpt-3.5-turbo-0125', model_class='topk', N=max_N)\n",
    "create_sub_shadow(sub03, d01, lims, 'T', sorted(d01['Temperature'].unique()), data=data, color='C1', k=5, T='any', model='gpt-3.5-turbo-0125', model_class='topk', N=max_N, label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(16,8), constrained_layout=True)\n",
    "for ax in axs.flat:\n",
    "    ax.set_aspect(1)\n",
    "\n",
    "d00 = select_df(df, data=\"iupac-sol\", k=5, T=0.7, model='text-davinci-003', model_class='topk', N=700)\n",
    "lim_sol = (min(d00['y']), max(d00['y']))\n",
    "lim_sol = (-12,4)\n",
    "text_anchor = sum(lim_sol)/len(lim_sol)\n",
    "create_sub_parity(axs[0,0], d00, 'LogS solubility', lim=lim_sol, model_class=\"topk\", color=f'C0', calibration=\"scaling_factor\", recal_ind=300)\n",
    "\n",
    "d01 = select_df(df, data=\"iupac-sol\", k=5, T=0.7, model='gpt-4', model_class='topk', N=700)\n",
    "create_sub_parity(axs[0,1], d01, 'LogS solubility', lim=lim_sol, model_class=\"topk\", color=f'C1', calibration=\"scaling_factor\", recal_ind=300)\n",
    "\n",
    "d02 = select_df(df, data=\"iupac-sol\", k=0, T=0.05, model='any', model_class='finetune', N=700)\n",
    "create_sub_parity(axs[0,2], d02, 'LogS solubility', lim=lim_sol, model_class=\"finetune\", color=f'C2', calibration=\"scaling_factor\", recal_ind=300)\n",
    "\n",
    "d03 = select_df(df, data=\"iupac-sol\", k=32, T=0.05, model='text-ada-001', model_class='GPR-BOT', N=700)\n",
    "create_sub_parity(axs[0,3], d03, 'LogS solubility', lim=lim_sol, model_class=\"GPR\", color=f'C3', GPR=True, calibration=\"scaling_factor\", recal_ind=300)\n",
    "\n",
    "\n",
    "d10 = select_df(df, data=\"C2\", k=5, T=0.7, model='text-davinci-003', model_class='topk', N=1000)\n",
    "lim_c2 = (min(d10['y']), max(d10['y']))\n",
    "lim_c2 = (-2, 25)\n",
    "create_sub_parity(axs[1,0], d10, 'C2 yield', lim=lim_c2, model_class=\"topk\", color=f'C4', calibration=\"scaling_factor\", recal_ind=300)\n",
    "\n",
    "d11 = select_df(df, data=\"C2\", k=5, T=0.7, model='gpt-4', model_class='topk', N=1000)\n",
    "create_sub_parity(axs[1,1], d11, 'C2 yield', lim=lim_c2, model_class=\"topk\", color=f'C5', calibration=\"scaling_factor\", recal_ind=300)\n",
    "\n",
    "d12 = select_df(df, data=\"C2\", k=0, T=0.05, model='any', model_class='finetune', N=1000)\n",
    "create_sub_parity(axs[1,2], d12, 'C2 yield', lim=lim_c2, model_class=\"finetune\", color=f'C6', calibration=\"scaling_factor\", recal_ind=300)\n",
    "\n",
    "d13 = select_df(df, data=\"C2\", k=32, T=0.05, model='text-ada-001', model_class='GPR-BOT', N=1000)\n",
    "create_sub_parity(axs[1,3], d13, 'C2 yield', lim=lim_c2, model_class=\"GPR\", color=f'C7', GPR=True, calibration=\"scaling_factor\", recal_ind=300)\n",
    "\n",
    "anchor_x = (lim_sol[1]+lim_sol[0])/2\n",
    "anchor_y = lim_sol[1] + 1\n",
    "bbox_props = dict(boxstyle=\"square\", fc='#f5f4e9', ec=\"gray\", lw=1)\n",
    "axs[0,0].text(anchor_x, anchor_y, \"davinci\", ha=\"center\", va=\"bottom\", rotation=0,\n",
    "            size=15, bbox=bbox_props)\n",
    "axs[0,1].text(anchor_x, anchor_y, \"GPT-4\", ha=\"center\", va=\"bottom\", rotation=0,\n",
    "            size=15, bbox=bbox_props)\n",
    "axs[0,2].text(anchor_x, anchor_y, \"Finetune\", ha=\"center\", va=\"bottom\", rotation=0,\n",
    "            size=15, bbox=bbox_props)\n",
    "axs[0,3].text(anchor_x, anchor_y, \"GPR\", ha=\"center\", va=\"bottom\", rotation=0,\n",
    "            size=15, bbox=bbox_props)\n",
    "\n",
    "axs[0,0].text(lim_sol[0]-5, (lim_sol[1]+lim_sol[0])/2, \"Solubility\", ha=\"right\", va=\"center\", rotation=0,\n",
    "            size=15, bbox=bbox_props)\n",
    "axs[1,0].text(lim_c2[0]-7, (lim_c2[1]+lim_c2[0])/2, \"C2 yield\", ha=\"right\", va=\"center\", rotation=0,\n",
    "            size=15, bbox=bbox_props)\n",
    "\n",
    "plt.savefig(f\"figs/parities\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#figsize=(6.4,4.8)\n",
    "fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(16,8), constrained_layout=True)\n",
    "for ax in axs.flat:\n",
    "    ax.set_aspect(1)\n",
    "\n",
    "# plot axs[0,0]\n",
    "d00 = select_df(df, data=\"iupac-sol\", k=5, T=0.7, model='text-davinci-003', model_class='topk', N=700)\n",
    "lim_sol = (min(d00['y']), max(d00['y']))\n",
    "lim_sol = (-12,4)\n",
    "text_anchor = sum(lim_sol)/len(lim_sol)\n",
    "create_sub_parity(axs[0], d00, 'LogS solubility', lim=lim_sol, model_class=\"topk\", color=f'C0', calibration=\"scaling_factor\", recal_ind=300)\n",
    "# plot axs[0,1]\n",
    "d01 = select_df(df, data=\"iupac-sol\", k=5, T=0.7, model='gpt-4', model_class='topk', N=700)\n",
    "create_sub_parity(axs[1], d01, 'LogS solubility', lim=lim_sol, model_class=\"topk\", color=f'C1', calibration=\"scaling_factor\", recal_ind=300)\n",
    "# plot axs[0,2]\n",
    "d02 = select_df(df, data=\"iupac-sol\", k=0, T=0.05, model='any', model_class='finetune', N=700)\n",
    "create_sub_parity(axs[2], d02, 'LogS solubility', lim=lim_sol, model_class=\"finetune\", color=f'C2', calibration=\"scaling_factor\", recal_ind=300)\n",
    "# plot axs[0,3]\n",
    "d03 = select_df(df, data=\"iupac-sol\", k=32, T=0.05, model='text-ada-001', model_class='GPR-BOT', N=700)\n",
    "create_sub_parity(axs[3], d03, 'LogS solubility', lim=lim_sol, model_class=\"GPR\", color=f'C3', GPR=True, calibration=\"scaling_factor\", recal_ind=300)\n",
    "\n",
    "anchor_x = (lim_sol[1]+lim_sol[0])/2\n",
    "anchor_y = lim_sol[1] + 1\n",
    "bbox_props = dict(boxstyle=\"square\", fc='#f5f4e9', ec=\"gray\", lw=1)\n",
    "axs[0].text(anchor_x, anchor_y, \"davinci\", ha=\"center\", va=\"bottom\", rotation=0,\n",
    "            size=15, bbox=bbox_props)\n",
    "axs[1].text(anchor_x, anchor_y, \"GPT-4\", ha=\"center\", va=\"bottom\", rotation=0,\n",
    "            size=15, bbox=bbox_props)\n",
    "axs[2].text(anchor_x, anchor_y, \"Finetune\", ha=\"center\", va=\"bottom\", rotation=0,\n",
    "            size=15, bbox=bbox_props)\n",
    "axs[3].text(anchor_x, anchor_y, \"GPR\", ha=\"center\", va=\"bottom\", rotation=0,\n",
    "            size=15, bbox=bbox_props)\n",
    "\n",
    "axs[0].text(lim_sol[0]-5, (lim_sol[1]+lim_sol[0])/2, \"Solubility\", ha=\"right\", va=\"center\", rotation=0,\n",
    "            size=15, bbox=bbox_props)\n",
    "\n",
    "plt.savefig(f\"figs/parities-sol\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(16,8), constrained_layout=True)\n",
    "for ax in axs.flat:\n",
    "    ax.set_aspect(1)\n",
    "\n",
    "d10 = select_df(df, data=\"C2\", k=5, T=0.7, model='text-davinci-003', model_class='topk', N=1000)\n",
    "lim_c2 = (min(d10['y']), max(d10['y']))\n",
    "lim_c2 = (-2, 25)\n",
    "create_sub_parity(axs[0], d10, 'C2 yield', lim=lim_c2, model_class=\"topk\", color=f'C4', calibration=\"scaling_factor\", recal_ind=300)\n",
    "d11 = select_df(df, data=\"C2\", k=5, T=0.7, model='gpt-4', model_class='topk', N=1000)\n",
    "create_sub_parity(axs[1], d11, 'C2 yield', lim=lim_c2, model_class=\"topk\", color=f'C5', calibration=\"scaling_factor\", recal_ind=300)\n",
    "d12 = select_df(df, data=\"C2\", k=0, T=0.05, model='any', model_class='finetune', N=1000)\n",
    "create_sub_parity(axs[2], d12, 'C2 yield', lim=lim_c2, model_class=\"finetune\", color=f'C6', calibration=\"scaling_factor\", recal_ind=300)\n",
    "d13 = select_df(df, data=\"C2\", k=32, T=0.05, model='text-ada-001', model_class='GPR-BOT', N=1000)\n",
    "create_sub_parity(axs[3], d13, 'C2 yield', lim=lim_c2, model_class=\"GPR\", color=f'C7', GPR=True, calibration=\"scaling_factor\", recal_ind=300)\n",
    "\n",
    "\n",
    "anchor_x = (lim_c2[1]+lim_c2[0])/2\n",
    "anchor_y = lim_c2[1] + 1\n",
    "bbox_props = dict(boxstyle=\"square\", fc='#f5f4e9', ec=\"gray\", lw=1)\n",
    "axs[0].text(anchor_x, anchor_y, \"davinci\", ha=\"center\", va=\"bottom\", rotation=0,\n",
    "            size=15, bbox=bbox_props)\n",
    "axs[1].text(anchor_x, anchor_y, \"GPT-4\", ha=\"center\", va=\"bottom\", rotation=0,\n",
    "            size=15, bbox=bbox_props)\n",
    "axs[2].text(anchor_x, anchor_y, \"Finetune\", ha=\"center\", va=\"bottom\", rotation=0,\n",
    "            size=15, bbox=bbox_props)\n",
    "axs[3].text(anchor_x, anchor_y, \"GPR\", ha=\"center\", va=\"bottom\", rotation=0,\n",
    "            size=15, bbox=bbox_props)\n",
    "\n",
    "axs[0].text(lim_c2[0]-7, (lim_c2[1]+lim_c2[0])/2, \"C2 yield\", ha=\"right\", va=\"center\", rotation=0,\n",
    "            size=15, bbox=bbox_props)\n",
    "\n",
    "plt.savefig(f\"figs/parities-C2\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12,8), constrained_layout=True)\n",
    "for ax in axs.flat:\n",
    "    ax.set_aspect(1)\n",
    "\n",
    "d00 = select_df(df, data=\"C2\", k=5, T=0.7, model='text-curie-001', model_class='topk', N=1000)\n",
    "lim_c2 = (min(d00['y']), max(d00['y']))\n",
    "lim_c2 = (-2, 25)\n",
    "text_anchor = sum(lim_c2)/len(lim_c2)\n",
    "create_sub_parity(axs[0,0], d00, 'C2 yield', lim=lim_c2, model_class=\"topk\", color=f'C0', title=\"curie\")\n",
    "d01 = select_df(df, data=\"C2\", k=5, T=0.7, model='text-davinci-003', model_class='topk', N=1000)\n",
    "create_sub_parity(axs[0,1], d01, 'C2 yield', lim=lim_c2, model_class=\"topk\", color=f'C1', title=\"davinci\")\n",
    "d02 = select_df(df, data=\"C2\", k=5, T=0.7, model='gpt-4', model_class='topk', N=1000)\n",
    "create_sub_parity(axs[0,2], d02, 'C2 yield', lim=lim_c2, model_class=\"topk\", color=f'C2', title=\"GPT-4\")\n",
    "\n",
    "d10 = select_df(df, data=\"C2\", k=1, T=0.05, model='text-ada-001', model_class='KNN', N=1000)\n",
    "create_sub_parity(axs[1,0], d10, 'C2 yield', lim=lim_c2, model_class=\"KNN\", color=f'C4', title=\"KNN\")\n",
    "d11 = select_df(df, data=\"C2\", k=0, T=0.05, model='text-ada-001', model_class='KRR', N=1000)\n",
    "create_sub_parity(axs[1,1], d11, 'C2 yield', lim=lim_c2, model_class=\"KRR\", color=f'C5', title=\"KRR\")\n",
    "d12 = select_df(df, data=\"C2\", k=0, T=0.05, model='any', model_class='finetune', N=1000)\n",
    "create_sub_parity(axs[1,2], d12, 'C2 yield', lim=lim_c2, model_class=\"finetune\", color=f'C6', title=\"finetune\")\n",
    "\n",
    "plt.savefig(f\"figs/par_models\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_data = df[(df['data'] == 'ocm')]\n",
    "c2_data.groupby(['Temperature', 'data', 'k_selected', 'model_class', \"N_train\", \"model\"]).size().reset_index().sort_values(by=[\"model_class\", \"Temperature\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parities(c2_data, \n",
    "              'N', \n",
    "              [1,25,200,1000],#sorted(c2_data[(c2_data['model_class']==\"multi\") & (c2_data['model']==\"text-curie-001\")]['N_train'].unique()), \n",
    "              nrows=1, ncols=4,\n",
    "              data='C2',\n",
    "              k=5,\n",
    "              T=0.05,\n",
    "              model='text-curie-001',\n",
    "              model_class='multi',\n",
    "              N=None,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_C2_multi_N_curie.png\")\n",
    "\n",
    "plot_parities(c2_data, \n",
    "              'k', \n",
    "              [0,1,5], #sorted(c2_data[(c2_data['model_class']==\"multi\") & (c2_data['model']==\"text-curie-001\")]['k_selected'].unique()), \n",
    "              nrows=1, ncols=3,\n",
    "              data='C2',\n",
    "              k=None,\n",
    "              T=0.05,\n",
    "              model='text-curie-001',\n",
    "              model_class='multi',\n",
    "              N=1000,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_C2_multi_k_curie.png\")\n",
    "\n",
    "plot_parities(c2_data, \n",
    "              'T', \n",
    "              [0.05, 0.5, 0.7, 1.0], #sorted(c2_data[(c2_data['model_class']==\"multi\") & (c2_data['model']==\"text-curie-001\")]['Temperature'].unique()), \n",
    "              nrows=1, ncols=4,\n",
    "              data='C2',\n",
    "              k=5,\n",
    "              T=None,\n",
    "              model='text-curie-001',\n",
    "              model_class='multi',\n",
    "              N=1000,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_C2_multi_T_curie.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_ablation(c2_data, \n",
    "#               'N', \n",
    "#               sorted(c2_data[(c2_data['model_class']==\"multi\") & (c2_data['model']==\"text-curie-001\")]['N_train'].unique()), \n",
    "#               nrows=1, ncols=3,\n",
    "#               data='C2',\n",
    "#               k=5,\n",
    "#               T=0.05,\n",
    "#               model='text-curie-001',\n",
    "#               model_class='multi',\n",
    "#               N=None,\n",
    "#               out_name=\"ablation_C2_multi_N_curie.png\")\n",
    "\n",
    "# plot_ablation(c2_data, \n",
    "#               'k', \n",
    "#               sorted(c2_data[(c2_data['model_class']==\"multi\") & (c2_data['model']==\"text-curie-001\")]['k_selected'].unique()), \n",
    "#               nrows=1, ncols=3,\n",
    "#               data='C2',\n",
    "#               k=None,\n",
    "#               T=0.05,\n",
    "#               model='text-curie-001',\n",
    "#               model_class='multi',\n",
    "#               N=1000,\n",
    "#               out_name=\"ablation_C2_multi_k_curie.png\")\n",
    "\n",
    "# plot_ablation(c2_data, \n",
    "#               'T', \n",
    "#               sorted(c2_data[(c2_data['model_class']==\"multi\") & (c2_data['model']==\"text-curie-001\")]['Temperature'].unique()), \n",
    "#               nrows=1, ncols=3,\n",
    "#               data='C2',\n",
    "#               k=5,\n",
    "#               T=None,\n",
    "#               model='text-curie-001',\n",
    "#               model_class='multi',\n",
    "#               N=1000,\n",
    "#               out_name=\"ablation_C2_multi_T_curie.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multi-davinci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parities(c2_data, \n",
    "              'N', \n",
    "              sorted(c2_data[(c2_data['model_class']==\"multi\") & (c2_data['model']==\"text-davinci-003\")]['N_train'].unique()), \n",
    "              nrows=1, ncols=1,\n",
    "              data='C2', \n",
    "              k=5, \n",
    "              T=0.05, \n",
    "              model='text-davinci-001',\n",
    "              model_class='multi', \n",
    "              N=None,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_C2_multi_N_davinci.png\")\n",
    "\n",
    "plot_parities(c2_data, \n",
    "              'T', \n",
    "              [0.05, 0.5, 0.7, 1.0], \n",
    "              nrows=1, ncols=4,\n",
    "              data='C2', \n",
    "              k=5, \n",
    "              T=None, \n",
    "              model='text-davinci-003',\n",
    "              model_class='multi', \n",
    "              N=1000,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_C2_multi_T_davinci.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_ablation(c2_data, \n",
    "#               'N', \n",
    "#               sorted(c2_data[(c2_data['model_class']==\"multi\") & (c2_data['model']==\"text-davinci-003\")]['N_train'].unique()), \n",
    "#               nrows=1, ncols=3,\n",
    "#               data='C2',\n",
    "#               k=5,\n",
    "#               T=0.05,\n",
    "#               model='text-davinci-003',\n",
    "#               model_class='multi',\n",
    "#               N=None,\n",
    "#               out_name=\"ablation_C2_multi_N_davinci.png\")\n",
    "\n",
    "# plot_ablation(c2_data, \n",
    "#               'T', \n",
    "#               sorted(c2_data[(c2_data['model_class']==\"multi\") & (c2_data['model']==\"text-davinci-003\")]['Temperature'].unique()), \n",
    "#               nrows=1, ncols=3,\n",
    "#               data='C2',\n",
    "#               k=5,\n",
    "#               T=None,\n",
    "#               model='text-davinci-003',\n",
    "#               model_class='multi',\n",
    "#               N=1000,\n",
    "#               out_name=\"ablation_C2_multi_T_davinci.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parities(df, \n",
    "              'model', \n",
    "              [\"gpt-3.5-turbo-0125\", \"gpt-4-0125-preview\", \"gpt-4o\"], #sorted(c2_data[(c2_data['model_class']==\"topk\") & (c2_data['model']==\"text-curie-001\")]['N_train'].unique()), \n",
    "              nrows=1, ncols=3,\n",
    "              data='ocm', \n",
    "              k=5, \n",
    "              T=0.7, \n",
    "              model=None, \n",
    "              model_class='topk', \n",
    "              N=1000,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_C2_topk_N_curie.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parities(df, \n",
    "              'N', \n",
    "              [1,50,250,1000], #sorted(c2_data[(c2_data['model_class']==\"topk\") & (c2_data['model']==\"text-curie-001\")]['N_train'].unique()), \n",
    "              nrows=1, ncols=4,\n",
    "              data='ocm', \n",
    "              k=5, \n",
    "              T=0.7, \n",
    "              model='gpt-3.5-turbo-0125', \n",
    "              model_class='topk', \n",
    "              N=None,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_C2_topk_N_curie.png\")\n",
    "\n",
    "plot_parities(df, \n",
    "              'k', \n",
    "              [1,2,5,10], #sorted(c2_data[(c2_data['model_class']==\"topk\") & (c2_data['model']==\"text-curie-001\")]['k_selected'].unique()), \n",
    "              nrows=1, ncols=4,\n",
    "              data='ocm', \n",
    "              k=None, \n",
    "              T=0.05, \n",
    "              model='gpt-3.5-turbo-0125', \n",
    "              model_class='topk', \n",
    "              N=10,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_C2_topk_k_curie.png\")\n",
    "\n",
    "plot_parities(df, \n",
    "              'T', \n",
    "              [0.01,0.1,0.5,1.0], #sorted(c2_data[(c2_data['model_class']==\"topk\") & (c2_data['model']==\"text-curie-001\")]['k_selected'].unique()), \n",
    "              nrows=1, ncols=4,\n",
    "              data='ocm', \n",
    "              k=5, \n",
    "              T=None, \n",
    "              model='gpt-3.5-turbo-0125', \n",
    "              model_class='topk', \n",
    "              N=1000,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_C2_topk_T_curie.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### topk-davinci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parities(c2_data, \n",
    "              'T', \n",
    "              sorted(c2_data[(c2_data['model_class']==\"topk\") & (c2_data['model']==\"text-davinci-003\")]['Temperature'].unique()), \n",
    "              nrows=1, ncols=4,\n",
    "              data='C2',\n",
    "              k=5,\n",
    "              T=None,\n",
    "              model='text-davinci-003',\n",
    "              model_class='topk',\n",
    "              N=1000,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_C2_multi_T_curie.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_ablation(c2_data, \n",
    "#               'N', \n",
    "#               sorted(c2_data[(c2_data['model_class']==\"topk\") & (c2_data['model']==\"text-davinci-003\")]['N_train'].unique()), \n",
    "#               nrows=1, ncols=3,\n",
    "#               data='C2',\n",
    "#               k=5,\n",
    "#               T=0.05,\n",
    "#               model='text-davinci-003',\n",
    "#               model_class='topk',\n",
    "#               N=None,\n",
    "#               out_name=\"ablation_C2_topk_N_davinci.png\")\n",
    "\n",
    "# plot_ablation(c2_data, \n",
    "#               'T', \n",
    "#               sorted(c2_data[(c2_data['model_class']==\"topk\") & (c2_data['model']==\"text-davinci-003\")]['Temperature'].unique()), \n",
    "#               nrows=1, ncols=3,\n",
    "#               data='C2',\n",
    "#               k=5,\n",
    "#               T=None,\n",
    "#               model='text-davinci-003',\n",
    "#               model_class='topk',\n",
    "#               N=1000,\n",
    "#               out_name=\"ablation_C2_multi_T_davinci.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parities(c2_data, \n",
    "              'N', \n",
    "              [1,10,250,500], #sorted(c2_data[(c2_data['model_class']==\"GPR-BOT\") & (c2_data['model']==\"text-ada-001\")]['N_train'].unique()), \n",
    "              nrows=1, ncols=4,\n",
    "              data='C2', \n",
    "              k=32, \n",
    "              T=0.05, \n",
    "              model='text-ada-001', \n",
    "              model_class='GPR-BOT', \n",
    "              N=None,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_C2_GPR_N.png\",\n",
    "              GPR=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_ablation(c2_data, \n",
    "#               'N', \n",
    "#               sorted(c2_data[(c2_data['model_class']==\"GPR-BOT\") & (c2_data['model']==\"text-ada-001\")]['N_train'].unique()), \n",
    "#               nrows=1, ncols=3,\n",
    "#               data='C2',\n",
    "#               k=32,\n",
    "#               T=0.05,\n",
    "#               model='text-ada-001',\n",
    "#               model_class='GPR-BOT',\n",
    "#               N=None,\n",
    "#               out_name=\"ablation_C2_GPR_N_ada.png\",\n",
    "#               GPR=True)\n",
    "\n",
    "# plot_ablation(c2_data, \n",
    "#               'k',\n",
    "#               sorted(c2_data[(c2_data['model_class']==\"GPR-BOT\") & (c2_data['model']==\"text-ada-001\")]['k_selected'].unique()), \n",
    "#               nrows=1, ncols=3,\n",
    "#               data='C2',\n",
    "#               k=None,\n",
    "#               T=0.05,\n",
    "#               model='text-ada-001',\n",
    "#               model_class='GPR-BOT',\n",
    "#               N=500,\n",
    "#               out_name=\"ablation_C2_GPR_N_ada.png\",\n",
    "#               GPR=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parities(c2_data, \n",
    "              'N', \n",
    "              [5,10,25,50,100,250,500,1000], #sorted(c2_data[(c2_data['model_class']==\"GPR-BOT\") & (c2_data['model']==\"text-ada-001\")]['N_train'].unique()), \n",
    "              nrows=2, ncols=4,\n",
    "              data='C2', \n",
    "              k=1, \n",
    "              T=0.05, \n",
    "              model='text-ada-001', \n",
    "              model_class='KNN', \n",
    "              N=None,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_C2_KNN_N.png\",\n",
    "              GPR=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parities(c2_data, \n",
    "              'N', \n",
    "              [50,100,250,1000], #sorted(c2_data[(c2_data['model_class']==\"finetune\")]['N_train'].unique()), \n",
    "              nrows=1, ncols=4,\n",
    "              data='C2', \n",
    "              k=0, \n",
    "              T=0.05, \n",
    "              model='any', \n",
    "              model_class='finetune', \n",
    "              N=None,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_C2_FT_N.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_ablation(df, \n",
    "#               'N', \n",
    "#               sorted(c2_data[(c2_data['model_class']==\"finetune\")]['N_train'].unique()), \n",
    "#               nrows=1, ncols=3,\n",
    "#               data='C2',\n",
    "#               k=0,\n",
    "#               T=0.05,\n",
    "#               model='any',\n",
    "#               model_class='finetune',\n",
    "#               N=None,\n",
    "#               out_name=\"ablation_C2_FT_N_ada.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### curie X davinci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models = df[\n",
    "    (df['model_class']==\"topk\") &\n",
    "    ((df['model']==\"text-curie-001\") | (df['model']==\"text-davinci-003\") | (df['model']==\"gpt-4\")) &\n",
    "    (df['k_selected']==5) &\n",
    "    (df['Temperature']==0.7)\n",
    "]\n",
    "df_models\n",
    "plot_parities(df_models, \n",
    "              'model', \n",
    "              [\n",
    "                \"text-curie-001\",\n",
    "                \"text-davinci-003\",\n",
    "                \"gpt-4\"\n",
    "              ], #sorted(c2_data[c2_data['model_class']==\"multi\"]['model'].unique()), \n",
    "              nrows=1, ncols=3,\n",
    "              data='C2', \n",
    "              k=5,\n",
    "              T=0.7,\n",
    "              model=None,\n",
    "              model_class='topk', \n",
    "              N=1000,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_C2_topk_N_curieXdavinci.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iupac sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iupac_sol_data = df[(df['data'] == 'sol')]\n",
    "iupac_sol_data.groupby(['Temperature', 'data','k_selected', 'model_class', \"N_train\", \"model\"]).size().reset_index().sort_values(by=[\"model_class\", \"Temperature\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parities(iupac_sol_data, \n",
    "              'N', \n",
    "              [1,10,250,700], #sorted(iupac_sol_data[iupac_sol_data['model_class']==\"multi\"]['N_train'].unique()), \n",
    "              nrows=1, ncols=4,\n",
    "              data='sol', \n",
    "              k=5, \n",
    "              T=0.05, \n",
    "              model='gpt-3.5-turbo-0125', \n",
    "              model_class='multi', \n",
    "              N=None,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"LogS solubility\",\n",
    "              out_name=\"par_sol_multi_N_curie.png\")\n",
    "\n",
    "plot_parities(iupac_sol_data, \n",
    "              'k', \n",
    "              [1,5,10], #sorted(iupac_sol_data[iupac_sol_data['model_class']==\"multi\"]['N_train'].unique()), \n",
    "              nrows=1, ncols=3,\n",
    "              data='sol', \n",
    "              k=None,\n",
    "              T=0.05, \n",
    "              model='gpt-3.5-turbo-0125',\n",
    "              model_class='multi', \n",
    "              N=700,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"LogS solubility\",\n",
    "              out_name=\"par_sol_multi_k_curie.png\")\n",
    "\n",
    "plot_parities(iupac_sol_data, \n",
    "              'T', \n",
    "              [0.05, 0.5, 0.7, 1.0], #sorted(iupac_sol_data[iupac_sol_data['model_class']==\"multi\"]['Temperature'].unique()), \n",
    "              nrows=1, ncols=4,\n",
    "              data='sol',\n",
    "              k=5,\n",
    "              T=None,\n",
    "              model='gpt-3.5-turbo-0125',\n",
    "              model_class='multi', \n",
    "              N=700,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"LogS solubility\",\n",
    "              out_name=\"par_sol_multi_T_curie.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ablation(iupac_sol_data, \n",
    "              'N', \n",
    "              sorted(iupac_sol_data[iupac_sol_data['model_class']==\"multi\"]['N_train'].unique()), \n",
    "              nrows=1, ncols=3,\n",
    "              data='iupac-sol',\n",
    "              k=5,\n",
    "              T=0.05,\n",
    "              model='text-curie-001',\n",
    "              model_class='multi',\n",
    "              N=None,\n",
    "              out_name=\"ablation_sol_multi_N_curie.png\")\n",
    "\n",
    "plot_ablation(iupac_sol_data, \n",
    "              'k', \n",
    "              sorted(iupac_sol_data[iupac_sol_data['model_class']==\"multi\"]['k_selected'].unique()), \n",
    "              nrows=1, ncols=3,\n",
    "              data='iupac-sol',\n",
    "              k=None,\n",
    "              T=0.05,\n",
    "              model='text-curie-001',\n",
    "              model_class='multi',\n",
    "              N=700,\n",
    "              out_name=\"ablation_sol_multi_k_curie.png\")\n",
    "\n",
    "plot_ablation(iupac_sol_data, \n",
    "              'T', \n",
    "              sorted(iupac_sol_data[iupac_sol_data['model_class']==\"multi\"]['Temperature'].unique()), \n",
    "              nrows=1, ncols=3,\n",
    "              data='iupac-sol',\n",
    "              k=5,\n",
    "              T=None,\n",
    "              model='text-curie-001',\n",
    "              model_class='multi',\n",
    "              N=700,\n",
    "              out_name=\"ablation_sol_multi_T_curie.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parities(iupac_sol_data, \n",
    "              'N', \n",
    "              [1,10,250,700], #sorted(iupac_sol_data[iupac_sol_data['model_class']==\"topk\"]['N_train'].unique()), \n",
    "              nrows=1, ncols=4,\n",
    "              data='sol', \n",
    "              k=5, \n",
    "              T=0.7, \n",
    "              model='gpt-3.5-turbo-0125', \n",
    "              model_class='topk',\n",
    "              N=None,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"LogS solubility\",\n",
    "              out_name=\"par_sol_topk_N_curie.png\")\n",
    "\n",
    "plot_parities(iupac_sol_data, \n",
    "              'k', \n",
    "              [1,5,10], #sorted(iupac_sol_data[iupac_sol_data['model_class']==\"multi\"]['N_train'].unique()), \n",
    "              nrows=1, ncols=3,\n",
    "              data='sol', \n",
    "              k=None,\n",
    "              T=0.05, \n",
    "              model='gpt-3.5-turbo-0125', \n",
    "              model_class='topk', \n",
    "              N=700,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"LogS solubility\",\n",
    "              out_name=\"par_sol_topk_k_curie.png\")\n",
    "\n",
    "plot_parities(iupac_sol_data, \n",
    "              'T', \n",
    "              [0.05, 0.5, 0.7, 1.0], #sorted(iupac_sol_data[iupac_sol_data['model_class']==\"multi\"]['N_train'].unique()), \n",
    "              nrows=1, ncols=4,\n",
    "              data='sol', \n",
    "              k=5,\n",
    "              T=None, \n",
    "              model='gpt-3.5-turbo-0125', \n",
    "              model_class='topk', \n",
    "              N=700,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"LogS solubility\",\n",
    "              out_name=\"par_sol_topk_T_curie.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ablation(iupac_sol_data, \n",
    "              'N', \n",
    "              sorted(iupac_sol_data[iupac_sol_data['model_class']==\"topk\"]['N_train'].unique()), \n",
    "              nrows=1, ncols=3,\n",
    "              data='iupac-sol',\n",
    "              k=5,\n",
    "              T=0.05,\n",
    "              model='text-curie-001',\n",
    "              model_class='topk',\n",
    "              N=None,\n",
    "              out_name=\"ablation_sol_topk_N_curie.png\")\n",
    "\n",
    "plot_ablation(iupac_sol_data, \n",
    "              'k', \n",
    "              [1,5,10], #sorted(iupac_sol_data[iupac_sol_data['model_class']==\"topk\"]['k_selected'].unique()), \n",
    "              nrows=1, ncols=3,\n",
    "              data='iupac-sol',\n",
    "              k=None,\n",
    "              T=0.05,\n",
    "              model='text-curie-001',\n",
    "              model_class='topk',\n",
    "              N=700,\n",
    "              out_name=\"ablation_sol_topk_k_curie.png\")\n",
    "\n",
    "plot_ablation(iupac_sol_data, \n",
    "              'T', \n",
    "              sorted(iupac_sol_data[iupac_sol_data['model_class']==\"topk\"]['Temperature'].unique()), \n",
    "              nrows=1, ncols=3,\n",
    "              data='iupac-sol',\n",
    "              k=5,\n",
    "              T=None,\n",
    "              model='text-curie-001',\n",
    "              model_class='topk',\n",
    "              N=700,\n",
    "              out_name=\"ablation_sol_topk_T_curie.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parities(iupac_sol_data, \n",
    "              'N', \n",
    "              [1,10,250,700], #sorted(iupac_sol_data[(iupac_sol_data['model_class']==\"GPR-BOT\") & (iupac_sol_data['model']==\"text-ada-001\")]['N_train'].unique()), \n",
    "              nrows=1, ncols=4,\n",
    "              data='iupac-sol', \n",
    "              k=32, \n",
    "              T=0.05, \n",
    "              model='text-ada-001', \n",
    "              model_class='GPR-BOT', \n",
    "              N=None,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"LoS solubility\",\n",
    "              out_name=\"par_sol_GPR_N.png\",\n",
    "              GPR=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ablation(df, \n",
    "              'N', \n",
    "              sorted(iupac_sol_data[(iupac_sol_data['model_class']==\"GPR-BOT\") & (iupac_sol_data['model']==\"text-ada-001\")]['N_train'].unique()), \n",
    "              nrows=1, ncols=3,\n",
    "              data='iupac-sol',\n",
    "              k=32,\n",
    "              T=0.05,\n",
    "              model='text-ada-001',\n",
    "              model_class='GPR-BOT',\n",
    "              N=None,\n",
    "              out_name=\"ablation_sol_GPR_N_ada.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parities(iupac_sol_data, \n",
    "              'N', \n",
    "              [5,10,25,50,100,250,500,700], #sorted(c2_data[(c2_data['model_class']==\"GPR-BOT\") & (c2_data['model']==\"text-ada-001\")]['N_train'].unique()), \n",
    "              nrows=2, ncols=4,\n",
    "              data='iupac-sol', \n",
    "              k=1, \n",
    "              T=0.05, \n",
    "              model='text-ada-001', \n",
    "              model_class='KNN', \n",
    "              N=None,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_sol_KNN_N.png\",\n",
    "              GPR=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parities(iupac_sol_data, \n",
    "              'N', \n",
    "              [50, 250, 700],#sorted(iupac_sol_data[iupac_sol_data['model_class']==\"finetune\"]['N_train'].unique()), \n",
    "              nrows=1, ncols=3,\n",
    "              data='iupac-sol', \n",
    "              k=0, \n",
    "              T=0.05, \n",
    "              model='any', \n",
    "              N=None,\n",
    "              axis_name=\"LogS solubility\",\n",
    "              out_name=\"par_sol_FT_N.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ablation(iupac_sol_data, \n",
    "              'N', \n",
    "              sorted(iupac_sol_data[iupac_sol_data['model_class']==\"finetune\"]['N_train'].unique()), \n",
    "              nrows=1, ncols=3,\n",
    "              data='iupac-sol',\n",
    "              k=0,\n",
    "              T=0.05,\n",
    "              model='any',\n",
    "              model_class='finetune',\n",
    "              N=None,\n",
    "              out_name=\"ablation_sol_FT_N_ada.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alloy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alloy_data = df[(df['data'] == 'alloy')]\n",
    "alloy_data.groupby(['Temperature', 'k_selected', 'model_class', \"N_train\", \"model\"]).size().reset_index().sort_values(by=[\"model_class\", \"Temperature\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrated MMR vs Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(14,12), constrained_layout=True)\n",
    "for ax in axs.flat:\n",
    "    ax.set_aspect(1)\n",
    "\n",
    "d00 = select_df(df, data=\"C2\", k=5, T=0.7, model='text-curie-001', model_class='topk_NN', N=1000)\n",
    "lim_c2 = (min(d00['y']), max(d00['y']))\n",
    "lim_c2 = (-2, 25)\n",
    "text_anchor = sum(lim_c2)/len(lim_c2)\n",
    "create_sub_parity(axs[0], d00, 'C2 yield', lim=lim_c2, model_class=\"topk_NN\", color=f'C4', title=\"topk_cos_sim|N=1000|T=.7|k=5|curie\",calibration='scaling_factor',recal_ind=300)\n",
    "\n",
    "d00 = select_df(df, data=\"C2\", k=5, T=0.7, model='text-curie-001', model_class='multi_NN', N=1000)\n",
    "lim_c2 = (min(d00['y']), max(d00['y']))\n",
    "lim_c2 = (-2, 25)\n",
    "text_anchor = sum(lim_c2)/len(lim_c2)\n",
    "create_sub_parity(axs[1], d00, 'C2 yield', lim=lim_c2, model_class=\"multi_NN\", color=f'C4', title=\"multi_cos_sim|N=1000|T=.7|k=5|curie\",calibration='scaling_factor',recal_ind=300)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_sub_parity(ax, df_sel, axis_name=\"topk\",model_class=\"topk\", lim=[-1,1], color='gray', GPR=False, Type_cali =False,rec_split=100,model='curie-001'):\n",
    "   \n",
    "    def process_data(df, unique_vals):\n",
    "        y, yhat, yprob = [], [], []\n",
    "        for prompt in unique_vals:\n",
    "            y.append(df[df['x'] == prompt]['y'].unique()[0])\n",
    "            yhat.append(df[df['x'] == prompt]['yhat'].values)\n",
    "            yprob.append(df[df['x'] == prompt]['yprobs'].values)\n",
    "        return y, yhat, yprob\n",
    "\n",
    "    def calculate_means_and_stds(yhat, yprob):\n",
    "        means = np.array([np.sum(yhi * ypi) if len(yhi) > 1 else ypi.mean() for yhi, ypi in zip(yhat, yprob)])\n",
    "        means = np.where(means == 0, 0.0001, means)\n",
    "        stds = np.array([np.sqrt(np.sum((yhi - ymi)**2 * ypi)) if len(yhi) > 1 else ypi.mean() for yhi, ypi, ymi in zip(yhat, yprob, means)])\n",
    "        return means, stds\n",
    "\n",
    "    unique_vals = df_sel['x'].unique()\n",
    "    y, yhat, yprob = process_data(df_sel, unique_vals[:rec_split])\n",
    "    y_rec, yhat_rec, yprob_rec = process_data(df_sel, unique_vals[rec_split:])\n",
    "\n",
    "    ymeans, ystds = calculate_means_and_stds(yhat, yprob)\n",
    "    ymeans_rec, ystds_rec = calculate_means_and_stds(yhat_rec, yprob_rec)\n",
    "    \n",
    "    if Type_cali == \"cali\":\n",
    "\n",
    "        if GPR:\n",
    "            yprobs = np.array([ypi.mean() for ypi in yprob])\n",
    "\n",
    "            yhats=np.array(np.concatenate(yhat))\n",
    "\n",
    "            ma = uct.miscalibration_area(yhats,yprobs, np.array(y), recal_model=None)\n",
    "            \n",
    "            x, y1 = uct.get_proportion_lists_vectorized(yhats,yprobs, np.array(y))\n",
    "            \n",
    "            ax.plot(x,x, linestyle= '--')\n",
    "            ax.plot(x, y1)\n",
    "            ax.fill_between(x, x, y1, color='teal', alpha=0.3)\n",
    "            \n",
    "            ax.set_title(' {} | {} | {}'.format(model,axis_name, model_class))\n",
    "           \n",
    "            ax.set_ylim(lim[0],lim[1])\n",
    "            ax.set_xlim(lim[0],lim[1])\n",
    "            ax.set_ylabel(\"Observed Proportion in Interval\")\n",
    "            \n",
    "            # ax.(lim[0] + 0.1*(max(yhat)-min(yhat)), lim[1] - 1*0.1*(max(yhat)-min(y)), f\"(\\u2193)Miscalibration area = {ma:.3f}\")\n",
    "\n",
    "            ax.annotate(f\"(\\u2193)Miscalibration area = {ma:.3f}\",\n",
    "                xy=(0.02, 0.98), xycoords='axes fraction',\n",
    "                horizontalalignment='left', verticalalignment='top')\n",
    "\n",
    "        else:\n",
    "            ma = uct.miscalibration_area(ymeans,ystds, np.array(y), recal_model=None)\n",
    "            \n",
    "            x, y1 = uct.get_proportion_lists_vectorized(ymeans,ystds, np.array(y))\n",
    "            \n",
    "            ax.plot(x,x, linestyle= '--')\n",
    "            ax.plot(x, y1)\n",
    "            ax.fill_between(x, x, y1, color='teal', alpha=0.3)\n",
    "            \n",
    "            ax.set_title(' {} | {} | {}'.format(model,axis_name, model_class))\n",
    "            # ax.set_xlabel(f\"measured {axis_name}\")\n",
    "            # ax.set_ylabel(\"Obsererved Proportion in Interval\")\n",
    "            ax.set_ylabel(\"Observed Proportion in Interval\")\n",
    "            ax.set_ylim(lim[0],lim[1])\n",
    "            ax.set_xlim(lim[0],lim[1])\n",
    "            \n",
    "            # ax.(lim[0] + 0.1*(max(yhat)-min(yhat)), lim[1] - 1*0.1*(max(yhat)-min(y)), f\"(\\u2193)Miscalibration area = {ma:.3f}\")\n",
    "\n",
    "            ax.annotate(f\"(\\u2193)Miscalibration area = {ma:.3f}\",\n",
    "                xy=(0.02, 0.98), xycoords='axes fraction',\n",
    "                horizontalalignment='left', verticalalignment='top')\n",
    "            \n",
    "\n",
    "    elif Type_cali == \"recali\":\n",
    "\n",
    "        if GPR:\n",
    "\n",
    "            yprobs = np.array([ypi.mean() for ypi in yprob])\n",
    "            yyprobs = np.array([ypi.mean() for ypi in yprob_rec])\n",
    "\n",
    "            yhats=np.array(np.concatenate(yhat))\n",
    "            yyhats=np.array(np.concatenate(yhat_rec))\n",
    "\n",
    "\n",
    "            exp_props,obs_props= uct.metrics_calibration.get_proportion_lists_vectorized(yyhats[:100], yyprobs[:100], np.array(y_rec[:100]))\n",
    "\n",
    "            \n",
    "            recal_model = uct.recalibration.iso_recal(exp_props, obs_props)\n",
    "\n",
    "            ma = uct.miscalibration_area(yhats, yprobs, np.array(y), recal_model=recal_model)\n",
    "            \n",
    "            x, y1 = uct.metrics_calibration.get_proportion_lists_vectorized(yhats, yprobs, np.array(y), recal_model=recal_model)\n",
    "            \n",
    "            ax.plot(x,x, linestyle= '--')\n",
    "            ax.plot(x, y1)\n",
    "            ax.fill_between(x, x, y1, color='teal', alpha=0.3)\n",
    "            \n",
    "            ax.set_title('Isotonic')\n",
    "            ax.set_ylim(lim[0],lim[1])\n",
    "            ax.set_xlim(lim[0],lim[1])\n",
    "            \n",
    "            # ax.(lim[0] + 0.1*(max(yhat)-min(yhat)), lim[1] - 1*0.1*(max(yhat)-min(y)), f\"(\\u2193)Miscalibration area = {ma:.3f}\")\n",
    "\n",
    "            ax.annotate(f\"(\\u2193)Miscalibration area = {ma:.3f}\",\n",
    "                xy=(0.02, 0.98), xycoords='axes fraction',\n",
    "                horizontalalignment='left', verticalalignment='top')\n",
    "\n",
    "        else:\n",
    "        \n",
    "            exp_props,obs_props= uct.metrics_calibration.get_proportion_lists_vectorized(ymeans_rec[:100], ystds_rec[:100], np.array(y_rec[:100]))\n",
    "\n",
    "\n",
    "            recal_model = uct.recalibration.iso_recal(exp_props, obs_props)\n",
    "\n",
    "            ma = uct.miscalibration_area(ymeans, ystds, np.array(y), recal_model=recal_model)\n",
    "            \n",
    "            x, y1 = uct.metrics_calibration.get_proportion_lists_vectorized(ymeans,ystds, np.array(y), recal_model=recal_model)\n",
    "            \n",
    "            ax.plot(x,x, linestyle= '--')\n",
    "            ax.plot(x, y1)\n",
    "            ax.fill_between(x, x, y1, color='teal', alpha=0.3)\n",
    "            \n",
    "            ax.set_title('Isotonic')\n",
    "            \n",
    "            ax.set_ylabel(\"Observed Proportion in Interval\")\n",
    "            ax.set_ylim(lim[0],lim[1])\n",
    "            ax.set_xlim(lim[0],lim[1])\n",
    "            \n",
    "            # ax.(lim[0] + 0.1*(max(yhat)-min(yhat)), lim[1] - 1*0.1*(max(yhat)-min(y)), f\"(\\u2193)Miscalibration area = {ma:.3f}\")\n",
    "\n",
    "            ax.annotate(f\"(\\u2193)Miscalibration area = {ma:.3f}\",\n",
    "                xy=(0.02, 0.98), xycoords='axes fraction',\n",
    "                horizontalalignment='left', verticalalignment='top')\n",
    "\n",
    "    elif Type_cali == \"recali_scale\":\n",
    "\n",
    "\n",
    "        if GPR:\n",
    "            \n",
    "            yhats=np.concatenate(yhat)\n",
    "            yyhats=np.concatenate(yhat_rec)\n",
    "\n",
    "            yprobs = np.array([ypi.mean() for ypi in yprob])\n",
    "            yyprobs = np.array([ypi.mean() for ypi in yprob_rec])\n",
    "\n",
    "            std_scaling = uct.recalibration.optimize_recalibration_ratio(yyhats[:100], yyprobs[:100], np.array(y_rec[:100]), criterion=\"miscal\")\n",
    "\n",
    "\n",
    "            ystds = yprobs * std_scaling\n",
    "            print(std_scaling,model)\n",
    "\n",
    "            ma = uct.miscalibration_area(yhats, ystds, np.array(y), recal_model=None)\n",
    "    \n",
    "            \n",
    "            x, y1 = uct.metrics_calibration.get_proportion_lists_vectorized(yhats, ystds, np.array(y), recal_model=None)\n",
    "            \n",
    "            ax.plot(x,x, linestyle= '--')\n",
    "            ax.plot(x, y1)\n",
    "            ax.fill_between(x, x, y1, color='teal', alpha=0.3)\n",
    "            \n",
    "            ax.set_title('Scaling')\n",
    "            ax.set_xlabel(\"Predicted Proportion in Interval\")\n",
    "            ax.set_ylabel(\"Observed Proportion in Interval\")\n",
    "            ax.set_ylim(lim[0],lim[1])\n",
    "            ax.set_xlim(lim[0],lim[1])\n",
    "            \n",
    "\n",
    "            ax.annotate(f\"(\\u2193)Miscalibration area = {ma:.3f}\",\n",
    "                xy=(0.02, 0.98), xycoords='axes fraction',\n",
    "                horizontalalignment='left', verticalalignment='top')\n",
    "\n",
    "        else:\n",
    "\n",
    "            std_scaling = uct.recalibration.optimize_recalibration_ratio(ymeans_rec[:100], ystds_rec[:100], np.array(y_rec[:100]),\n",
    "                                                                        criterion=\"miscal\")\n",
    "            print(std_scaling)\n",
    "            ystds = ystds * std_scaling\n",
    "\n",
    "\n",
    "            ma = uct.miscalibration_area(ymeans, ystds, np.array(y), recal_model=None)\n",
    "            \n",
    "            x, y1 = uct.metrics_calibration.get_proportion_lists_vectorized(ymeans, np.array(ystds), np.array(y), recal_model=None)\n",
    "            \n",
    "            ax.plot(x,x, linestyle= '--')\n",
    "            ax.plot(x, y1)\n",
    "            ax.fill_between(x, x, y1, color='teal', alpha=0.3)\n",
    "            \n",
    "            ax.set_title('Scaling')\n",
    "            ax.set_xlabel(\"Predicted Proportion in Interval\")\n",
    "            ax.set_ylabel(\"Observed Proportion in Interval\")\n",
    "            ax.set_ylim(lim[0],lim[1])\n",
    "            ax.set_xlim(lim[0],lim[1])\n",
    "            \n",
    "            # ax.(lim[0] + 0.1*(max(yhat)-min(yhat)), lim[1] - 1*0.1*(max(yhat)-min(y)), f\"(\\u2193)Miscalibration area = {ma:.3f}\")\n",
    "\n",
    "            ax.annotate(f\"(\\u2193)Miscalibration area = {ma:.3f}\",\n",
    "                xy=(0.02, 0.98), xycoords='axes fraction',\n",
    "                horizontalalignment='left', verticalalignment='top')\n",
    "\n",
    "    else:\n",
    "\n",
    "        ax.set_xlabel(f\"measured {axis_name}\")\n",
    "        ax.set_ylabel(f\"predicted {axis_name}\")\n",
    "        ax.set_ylim(lim[0], lim[1])\n",
    "        ax.set_xlim(lim[0], lim[1])\n",
    "\n",
    "        corr_val = corr(y, [yhi.mean() for yhi in yhat])\n",
    "        ax.text(lim[0] + 0.1 * (max(y) - min(y)), lim[1] - 1 * 0.1 * (max(y) - min(y)), f\"(\\u2191)correlation = {corr_val:.3f}\")\n",
    "        \n",
    "        if GPR:\n",
    "            ax.text(lim[0] + 0.1*(max(y)-min(y)), lim[1] - 2*0.1*(max(y)-min(y)), f\"(\\u2193)neg-ll = {log_likelihood(y, [yhi.mean() for yhi in yhat], yprobs, eps=1e-6):.3f}\")\n",
    "        else:\n",
    "            ax.text(lim[0] + 0.1*(max(y)-min(y)), lim[1] - 2*0.1*(max(y)-min(y)), f\"(\\u2193)neg-ll = {log_likelihood(y, [yhi.mean() for yhi in yhat], [yhi.std() if len(yhi)>1 else max(yprobs) for yhi in yhat], eps=1e-6):.3f}\")\n",
    "        ax.text(lim[0] + 0.1*(max(y)-min(y)), lim[1] - 3*0.1*(max(y)-min(y)), f\"(\\u2193)MAE = {mae(y, [yhi.mean() for yhi in yhat]):.3f}\")\n",
    "        \n",
    "        ax.plot(y,y)\n",
    "        ax.plot(lim,lim)\n",
    "        \n",
    "        if GPR:\n",
    "            ax.errorbar(y, \n",
    "                        [yhi.mean() for yhi in yhat], \n",
    "                        yerr=[abs(recal_bounds.lower),abs(recal_bounds.upper)],\n",
    "                        fmt='.', color='gray', alpha=0.3)\n",
    "        else:  \n",
    "            ax.errorbar(y, \n",
    "                        [yhi.mean() for yhi in yhat], \n",
    "                        yerr=[yhi.std() if len(yhi)>1 else max(yprobs) for yhi in yhat],\n",
    "                        fmt='.', color='gray', alpha=0.3)\n",
    "        ax.scatter(\n",
    "            y, [yhi.mean() for yhi in yhat], s=6, alpha=1, color=color\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import uncertainty_toolbox as uct\n",
    "\n",
    "#figsize=(6.4,4.8)\n",
    "fig, axs = plt.subplots(nrows=3, ncols=7, figsize=(30,12), constrained_layout=True)\n",
    "for ax in axs.flat:\n",
    "    ax.set_aspect(1)\n",
    "\n",
    "\n",
    "# plot axs[0,0]\n",
    "d00 = select_df(df, data=\"C2\", k=5, T=.7, model='text-curie-001', model_class='topk', N=1000)\n",
    "lim_c2 = (min(d00['y']), max(d00['y']))\n",
    "lim_c2 = (0, 1)\n",
    "text_anchor = sum(lim_c2)/len(lim_c2)\n",
    "create_sub_parity(axs[0,0], d00, axis_name='C2',model_class='topk', lim=lim_c2, color=f'C0',Type_cali=\"cali\",rec_split=100)\n",
    "# # plot axs[0,1]\n",
    "d01 = select_df(df, data=\"C2\", k=5, T=.7, model='text-curie-001', model_class='multi', N=1000)\n",
    "create_sub_parity(axs[0,1], d01, axis_name='C2',model_class='multi', lim=lim_c2, color=f'C1', Type_cali=\"cali\",rec_split=100)\n",
    "# # plot axs[0,2]\n",
    "d02 = select_df(df, data=\"C2\", k=5, T=0.7, model='text-davinci-003', model_class='topk', N=1000)\n",
    "create_sub_parity(axs[0,2], d02, axis_name='C2',model_class='topk', lim=lim_c2, color=f'C2', Type_cali=\"cali\", rec_split=100,model='text-davinci-003')\n",
    "\n",
    "\n",
    "\n",
    "# # plot axs[1,0]\n",
    "d10 = select_df(df, data=\"C2\", k=5, T=0.7, model='text-curie-001', model_class='topk', N=1000)\n",
    "lim_c2 = (min(d10['y']), max(d10['y']))\n",
    "lim_c2 = (0, 1)\n",
    "create_sub_parity(axs[1,0], d10, axis_name='C2 yield',model_class='topk', lim=lim_c2, color=f'C4', Type_cali=\"recali\",rec_split=100) # calibration plot\n",
    "# # # plot axs[1,1]\n",
    "d11 = select_df(df, data=\"C2\", k=5, T=.7, model='text-curie-001', model_class='multi', N=1000)\n",
    "lim = (min(d11['y']), max(d11['y']))\n",
    "create_sub_parity(axs[1,1], d11, axis_name='C2 yield',model_class='multi', lim=lim_c2, color=f'C5', Type_cali=\"recali\",rec_split=100)\n",
    "# # plot axs[1,2]\n",
    "d12 = select_df(df, data=\"C2\", k=5, T=0.7, model='text-davinci-003', model_class='topk', N=1000)\n",
    "lim = (min(d12['y']), max(d12['y']))\n",
    "create_sub_parity(axs[1,2], d12, axis_name='C2 yield',model_class='topk', lim=lim_c2, color=f'C6',Type_cali=\"recali\",rec_split=100)\n",
    "\n",
    "\n",
    "\n",
    "# # plot axs[2,0]\n",
    "d20 = select_df(df, data=\"C2\", k=5, T=0.7, model='text-curie-001', model_class='topk', N=1000)\n",
    "lim = (min(d20['y']), max(d20['y']))\n",
    "create_sub_parity(axs[2,0], d20, 'C2 yield',model_class='topk', lim=lim_c2, color=f'C6',Type_cali=\"recali_scale\",rec_split=100)\n",
    "\n",
    "# # plot axs[2,1]\n",
    "d21 = select_df(df, data=\"C2\", k=5, T=0.7, model='text-curie-001', model_class='multi', N=1000)\n",
    "lim = (min(d21['y']), max(d21['y']))\n",
    "create_sub_parity(axs[2,1], d21, 'C2 yield',model_class='multi', lim=lim_c2, color=f'C6',Type_cali=\"recali_scale\",GPR=False,rec_split=100)\n",
    "\n",
    "# # # plot axs[2,2]\n",
    "d22 = select_df(df, data=\"C2\", k=5, T=0.7, model='text-davinci-003', model_class='topk', N=1000)\n",
    "lim = (min(d22['y']), max(d22['y']))\n",
    "create_sub_parity(axs[2,2], d22, 'C2 yield', lim=lim_c2, color=f'C6',Type_cali=\"recali_scale\",rec_split=100)\n",
    "\n",
    "\n",
    "# # plot axs[0,3]\n",
    "d03 = select_df(df, data=\"C2\", k=5, T=0.7, model='gpt-4', model_class='topk', N=1000)\n",
    "lim_c2 = (min(d03['y']), max(d03['y']))\n",
    "lim_c2 = (0, 1)\n",
    "text_anchor = sum(lim_c2)/len(lim_c2)\n",
    "lim = (min(d03['y']), max(d03['y']))\n",
    "create_sub_parity(axs[0,3], d03, 'C2 yield',model='gpt-4', model_class='topk', lim=lim_c2, color=f'C6',Type_cali=\"cali\",rec_split=100)\n",
    "\n",
    "# # plot axs[1,3]\n",
    "d33 = select_df(df, data=\"C2\", k=5, T=0.7, model='gpt-4', model_class='topk', N=1000)\n",
    "lim = (min(d33['y']), max(d33['y']))\n",
    "create_sub_parity(axs[1,3], d33, 'C2 yield', lim=lim_c2, color=f'C6',Type_cali=\"recali\",rec_split=100)\n",
    "\n",
    "# # # plot axs[2,3]\n",
    "d33 = select_df(df, data=\"C2\", k=5, T=0.7, model='gpt-4', model_class='topk', N=1000)\n",
    "lim = (min(d33['y']), max(d33['y']))\n",
    "create_sub_parity(axs[2,3], d33, 'C2 yield', lim=lim_c2, color=f'C6',Type_cali=\"recali_scale\",rec_split=100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # plot axs[0,4]\n",
    "d04 = select_df(df, data=\"C2\", k=0, T=0, model='GPR', model_class='GPR_mat', N=1000)\n",
    "lim_c2 = (min(d04['y']), max(d04['y']))\n",
    "lim_c2 = (0, 1)\n",
    "text_anchor = sum(lim_c2)/len(lim_c2)\n",
    "lim = (min(d04['y']), max(d04['y']))\n",
    "create_sub_parity(axs[0,4], d04, 'C2 yield',model='GPR',GPR=True,model_class='GPR_mat', lim=lim_c2, color=f'C6',Type_cali=\"cali\",rec_split=100)\n",
    "\n",
    "# # plot axs[1,4]\n",
    "d14 = select_df(df, data=\"C2\", k=0, T=0, model='GPR', model_class='GPR_mat', N=1000)\n",
    "lim = (min(d14['y']), max(d14['y']))\n",
    "create_sub_parity(axs[1,4], d14, 'C2 yield', lim=lim_c2, color=f'C6',Type_cali=\"recali\",GPR=True,rec_split=100)\n",
    "\n",
    "# # # plot axs[2,4]\n",
    "d24 = select_df(df, data=\"C2\", k=0, T=0, model='GPR', model_class='GPR_mat', N=1000)\n",
    "lim = (min(d24['y']), max(d24['y']))\n",
    "create_sub_parity(axs[2,4], d24, 'C2 yield', lim=lim_c2, color=f'C6',Type_cali=\"recali_scale\",GPR=True,rec_split=100)\n",
    "\n",
    "\n",
    "\n",
    "# # plot axs[0,5]\n",
    "d05 = select_df(df, data=\"C2\", k=0, T=0, model='GPR', model_class='GPR_ada', N=1000)\n",
    "lim_c2 = (min(d05['y']), max(d05['y']))\n",
    "lim_c2 = (0, 1)\n",
    "text_anchor = sum(lim_c2)/len(lim_c2)\n",
    "lim = (min(d05['y']), max(d05['y']))\n",
    "create_sub_parity(axs[0,5], d05, 'C2 yield',model='GPR',GPR=True, model_class='GPR-ada', lim=lim_c2, color=f'C6',Type_cali=\"cali\",rec_split=100)\n",
    "\n",
    "# # plot axs[1,5]\n",
    "d35 = select_df(df, data=\"C2\", k=0, T=0, model='GPR', model_class='GPR_ada', N=1000)\n",
    "lim = (min(d35['y']), max(d35['y']))\n",
    "create_sub_parity(axs[1,5], d35, 'C2 yield', lim=lim_c2, color=f'C6',Type_cali=\"recali\",GPR=True,rec_split=100)\n",
    "\n",
    "# # # plot axs[2,5]\n",
    "d35 = select_df(df, data=\"C2\", k=0, T=0, model='GPR', model_class='GPR_ada', N=1000)\n",
    "lim = (min(d35['y']), max(d35['y']))\n",
    "create_sub_parity(axs[2,5], d35, 'C2 yield', lim=lim_c2, color=f'C6',GPR=True,Type_cali=\"recali_scale\",rec_split=100)\n",
    "\n",
    "\n",
    "\n",
    "# # plot axs[0,6]\n",
    "d06 = select_df(df, data=\"C2\", k=0, T=0, model='GPR', model_class='GPR_num', N=1000)\n",
    "lim_c2 = (min(d06['y']), max(d06['y']))\n",
    "lim_c2 = (0, 1)\n",
    "text_anchor = sum(lim_c2)/len(lim_c2)\n",
    "lim = (min(d06['y']), max(d06['y']))\n",
    "create_sub_parity(axs[0,6], d06, 'C2 yield',model='GPR',GPR=True,model_class='GPR_num', lim=lim_c2, color=f'C6',Type_cali=\"cali\",rec_split=100)\n",
    "\n",
    "# # plot axs[1,6]\n",
    "d16 = select_df(df, data=\"C2\", k=0, T=0, model='GPR', model_class='GPR_num', N=1000)\n",
    "lim = (min(d16['y']), max(d16['y']))\n",
    "create_sub_parity(axs[1,6], d16, 'C2 yield', lim=lim_c2, color=f'C6',Type_cali=\"recali\",GPR=True,rec_split=100)\n",
    "\n",
    "# # # plot axs[2,6]\n",
    "d26 = select_df(df, data=\"C2\", k=0, T=0, model='GPR', model_class='GPR_num', N=1000)\n",
    "lim = (min(d26['y']), max(d26['y']))\n",
    "create_sub_parity(axs[2,6], d26, 'C2 yield', lim=lim_c2, color=f'C6',Type_cali=\"recali_scale\",GPR=True,rec_split=100)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
