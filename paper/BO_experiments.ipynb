{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maykcaldas/miniconda3/envs/bolift/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import bolift\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "import copy, cloudpickle\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://github.com/google/fonts/raw/main/ofl/ibmplexmono/IBMPlexMono-Regular.ttf\",\n",
    "    \"IBMPlexMono-Regular.ttf\",\n",
    ")\n",
    "fe = font_manager.FontEntry(fname=\"IBMPlexMono-Regular.ttf\", name=\"plexmono\")\n",
    "font_manager.fontManager.ttflist.append(fe)\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"axes.facecolor\": \"#f5f4e9\",\n",
    "        \"grid.color\": \"#AAAAAA\",\n",
    "        \"axes.edgecolor\": \"#333333\",\n",
    "        \"figure.facecolor\": \"#FFFFFF\",\n",
    "        \"axes.grid\": False,\n",
    "        \"axes.prop_cycle\": plt.cycler(\"color\", plt.cm.Dark2.colors),\n",
    "        \"font.family\": fe.name,\n",
    "        \"figure.figsize\": (3.5, 3.5 / 1.2),\n",
    "        \"ytick.left\": True,\n",
    "        \"xtick.bottom\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "import random\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I saved the number of samples in the training set in the pickle file. With that, old pickle weren't compatible with the new printing format.\n",
    "# This script adds an array [0 .. len(samples)] to the old pickle files, so that they are compatible with the new printing format.\n",
    "\n",
    "import numpy as np\n",
    "d = cloudpickle.load(open(\"./out/<OLD_FORMAT_BO>.pkl\", \"rb\"))\n",
    "\n",
    "data = d\n",
    "for key, values in data.items():\n",
    "    num_aqs = values.shape[0]\n",
    "    num_entries = values.shape[1]\n",
    "    new_values = np.empty((num_aqs, num_entries, 3), dtype='<U349')\n",
    "    \n",
    "    for j in range(num_aqs):\n",
    "        for i in range(num_entries):\n",
    "            description, value = values[j, i]\n",
    "            new_values[j, i] = [description, str(i+1), value]\n",
    "    data[key] = new_values\n",
    "\n",
    "cloudpickle.dump(data, open(\"./out/<NEW_FORMAT_BO>.pkl\", \"wb\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "source": [
    "# BayesOpt Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def plot_BO(ax, data_file, title, data, axis_name, lim=None, label=False):\n",
    "    d = cloudpickle.load(open(data_file, \"rb\"))\n",
    "    N=20\n",
    "    M=1\n",
    "\n",
    "    for i in range(M):\n",
    "        if \"expected_improvement\" in d.keys():\n",
    "          ax.plot(\n",
    "            [int(s) for s in d['expected_improvement'][i,:N, 1]],\n",
    "            [float(y) for y in d['expected_improvement'][i,:N, 2]], \n",
    "            color=\"C1\", alpha=0.1\n",
    "          )\n",
    "        if \"greedy\" in d.keys():\n",
    "           ax.plot(\n",
    "            [int(s) for s in d['greedy'][i,:N, 1]],\n",
    "            [float(y) for y in d['greedy'][i,:N, 2]], \n",
    "            color=\"C2\", alpha=0.1\n",
    "          )\n",
    "        if \"upper_confidence_bound\" in d.keys():\n",
    "          ax.plot(\n",
    "            [int(s) for s in d['upper_confidence_bound'][i,:N, 1]],\n",
    "            [float(y) for y in d['upper_confidence_bound'][i,:N, 2]], \n",
    "            color=\"C3\", alpha=0.1\n",
    "          )\n",
    "        if \"probability_of_improvement\" in d.keys():\n",
    "          ax.plot(\n",
    "            [int(s) for s in d['probability_of_improvement'][i,:N, 1]],\n",
    "            [float(y) for y in d['probability_of_improvement'][i,:N, 2]], \n",
    "            color=\"C4\", alpha=0.1\n",
    "          )\n",
    "        if \"random\" in d.keys():\n",
    "          ax.plot(\n",
    "            [int(s) for s in d['random'][i,:N, 1]],\n",
    "            [float(y) for y in d['random'][i,:N, 2]], \n",
    "            color=\"C5\", alpha=0.1\n",
    "          )\n",
    "    if \"expected_improvement\" in d.keys():\n",
    "      label = \"EI\" if label else None\n",
    "      ax.plot(\n",
    "            d['expected_improvement'][:,:N, 1].astype('int').mean(axis=0),\n",
    "            d['expected_improvement'][:,:N, 2].astype('float').mean(axis=0), \n",
    "            color=\"C1\", label=label\n",
    "          )\n",
    "    if \"greedy\" in d.keys():\n",
    "      label = \"Greedy\" if label else None\n",
    "      ax.plot(\n",
    "            d['greedy'][:,:N, 1].astype('int').mean(axis=0),\n",
    "            d['greedy'][:,:N, 2].astype('float').mean(axis=0), \n",
    "            color=\"C2\", label=label\n",
    "          )\n",
    "    if \"upper_confidence_bound\" in d.keys():\n",
    "      label = \"UCB\" if label else None\n",
    "      ax.plot(\n",
    "            d['upper_confidence_bound'][:,:N, 1].astype('int').mean(axis=0),\n",
    "            d['upper_confidence_bound'][:,:N, 2].astype('float').mean(axis=0), \n",
    "            color=\"C3\", label=label\n",
    "          )\n",
    "    if \"probability_of_improvement\" in d.keys():\n",
    "      label = \"POI\" if label else None\n",
    "      ax.plot(\n",
    "            d['probability_of_improvement'][:,:N, 1].astype('int').mean(axis=0),\n",
    "            d['probability_of_improvement'][:,:N, 2].astype('float').mean(axis=0), \n",
    "            color=\"C4\", label=label\n",
    "          )\n",
    "    if \"random\" in d.keys():\n",
    "      label = \"random\" if label else None\n",
    "      ax.plot(\n",
    "            d['random'][:,:N, 1].astype('int').mean(axis=0),\n",
    "            d['random'][:,:N, 2].astype('float').mean(axis=0), \n",
    "            color=\"C5\", label=label\n",
    "          )\n",
    "    if \"random_mean\" in d.keys():\n",
    "      label = \"Random\" if label else None\n",
    "      ax.plot(\n",
    "            d['random_mean'][:, :N, 0].astype('int').mean(axis=0),\n",
    "            d['random_mean'][:, :N, 1].astype('float').mean(axis=0), \n",
    "            color=\"gray\", label=label, linestyle=\"dashed\"\n",
    "      )\n",
    "    ax.axhline(y=data.max(), color=\"C15\", linestyle=\"--\")\n",
    "    ax.text(ax.get_xlim()[1]+1, data.max(), \"max\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "    ax.axhline(y=data.quantile(0.99), color=\"C14\", linestyle=\"--\")\n",
    "    ax.text(ax.get_xlim()[1]+1, data.quantile(0.99), \"99%\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "    ax.axhline(y=data.quantile(0.95), color=\"C13\", linestyle=\"--\")\n",
    "    ax.text(ax.get_xlim()[1]+1, data.quantile(0.95), \"95%\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "    ax.axhline(y=data.mean(), color=\"C12\", linestyle=\"--\")\n",
    "    ax.text(ax.get_xlim()[1]+1, data.mean(), \"mean\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "    if not data_file[:3] == \"sol\":\n",
    "      ax.axhline(y=data.quantile(0.05), color=\"C11\", linestyle=\"--\")\n",
    "      ax.text(ax.get_xlim()[1]+1, data.quantile(0.05)+0.3, \"5%\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "      ax.axhline(y=data.min(), color=\"C10\", linestyle=\"--\")\n",
    "      ax.text(ax.get_xlim()[1]+1, data.min()-0.3, \"min\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    ax.set_xlabel(\"Number of samples\")\n",
    "    ax.set_ylabel(f\"Measured {axis_name}\")\n",
    "    # ax.set_xticks([i for i in range(0,N+1,5)], [str(x * 1) for x in [i for i in range(0,N+1,5)]])\n",
    "    if lim:\n",
    "      ax.set_ylim(lim)\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(88)\n",
    "\n",
    "data_path = \"./paper/data/C2_yield_meth_oxy_short.csv\"\n",
    "# data_path = \"./paper/data/ada_embedd_c2_dataset.csv\"\n",
    "raw_data = pd.read_csv(data_path, sep=\";\")\n",
    "# raw_data = raw_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# raw_data['completion'] = - raw_data['completion']\n",
    "\n",
    "x_name = \"prompt\"\n",
    "y_name = \"completion\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(16,4), constrained_layout=True)\n",
    "# for ax in axs.flat:\n",
    "#     ax.set_aspect(0.6)\n",
    "\n",
    "lim=(0,8)\n",
    "raw_data = pd.read_csv(\"dataset/data/1180_ocm_dataset.csv\", sep=\";\")\n",
    "plot_BO(axs[0], \"./out/C2_davinci_1180_1_tree.pkl\",\"20\", \n",
    "         raw_data[y_name], \"C$_2$ yield\", lim, label=True, data_file_random=\"./out/C2 - random - 1180.pkl\")\n",
    "\n",
    "lim=(0,10)\n",
    "raw_data = pd.read_csv(\"dataset/data/2950_ocm_dataset.csv\", sep=\";\")\n",
    "plot_BO(axs[1], \"./out/C2_davinci_2950_1_tree.pkl\",\"50\",\n",
    "         raw_data[y_name], \"C$_2$ yield\", lim, label=False, data_file_random=\"./out/C2 - random - 2950.pkl\")\n",
    "\n",
    "lim=(0,25)\n",
    "raw_data = pd.read_csv(\"dataset/data/5900_ocm_dataset.csv\", sep=\";\")\n",
    "plot_BO(axs[2], \"./out/C2_davinci_5900_1_tree.pkl\", \"100\",\n",
    "         raw_data[y_name], \"C$_2$ yield\", lim, label=False, data_file_random=\"./out/C2 - random - 5900.pkl\")\n",
    "\n",
    "lim=(0,25)\n",
    "raw_data = pd.read_csv(\"dataset/data/12744_ocm_dataset.csv\", sep=\";\")\n",
    "plot_BO(axs[3], \"./out/C2_davinci_12744_1_tree_2.pkl\", \"216\",\n",
    "         raw_data[y_name], \"C$_2$ yield\", lim, label=False, data_file_random=\"./out/C2 - random - 12744.pkl\")\n",
    "\n",
    "fig.suptitle(\"TreePool with davinci\")\n",
    "fig.legend(loc='upper center', bbox_to_anchor=(0.5,0),\n",
    "          fancybox=True, shadow=True, ncol=6)\n",
    "plt.savefig(f\"figs/BO_C2\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pools = [\n",
    "    './out/C2_davinci_1180_1_tree.pkl',\n",
    "    './out/C2_davinci_2950_1_tree.pkl',\n",
    "    './out/C2_davinci_5900_1_tree.pkl',\n",
    "    './out/C2_davinci_12744_1_tree.pkl',\n",
    "]\n",
    "for p in pools:\n",
    "    print(p)\n",
    "    d = cloudpickle.load(open(p, \"rb\"))\n",
    "    for run in d['upper_confidence_bound'][:, :, 0]:\n",
    "        print([r[14:r.find(\",\")] for r in run])\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(16,4), constrained_layout=True)\n",
    "# for ax in axs.flat:\n",
    "#     ax.set_aspect(0.6)\n",
    "\n",
    "lim=(0,8)\n",
    "raw_data = pd.read_csv(\"dataset/data/1180_ocm_dataset.csv\", sep=\";\")\n",
    "plot_BO(axs[0], \"./out/C2_davinci_1180_1_16hh.pkl\",\"20\", \n",
    "         raw_data[y_name], \"C$_2$ yield\", lim, label=True, data_file_random=\"./out/C2 - random - 1180.pkl\")\n",
    "\n",
    "lim=(0,10)\n",
    "raw_data = pd.read_csv(\"dataset/data/2950_ocm_dataset.csv\", sep=\";\")\n",
    "plot_BO(axs[1], \"./out/C2_davinci_2950_1_16hh.pkl\",\"50\",\n",
    "         raw_data[y_name], \"C$_2$ yield\", lim, label=False, data_file_random=\"./out/C2 - random - 2950.pkl\")\n",
    "\n",
    "lim=(0,25)\n",
    "raw_data = pd.read_csv(\"dataset/data/5900_ocm_dataset.csv\", sep=\";\")\n",
    "plot_BO(axs[2], \"./out/C2_davinci_5900_1_16hh.pkl\", \"100\",\n",
    "         raw_data[y_name], \"C$_2$ yield\", lim, label=False, data_file_random=\"./out/C2 - random - 5900.pkl\")\n",
    "\n",
    "lim=(0,25)\n",
    "raw_data = pd.read_csv(\"dataset/data/12744_ocm_dataset.csv\", sep=\";\")\n",
    "plot_BO(axs[3], \"./out/C2_davinci_12744_1_16hh.pkl\", \"216\",\n",
    "         raw_data[y_name], \"C$_2$ yield\", lim, label=False, data_file_random=\"./out/C2 - random - 12744.pkl\")\n",
    "         \n",
    "\n",
    "fig.suptitle(\"Subpool of 16 with half random samples with davinci\")\n",
    "fig.legend(loc='upper center', bbox_to_anchor=(0.5,0),\n",
    "          fancybox=True, shadow=True, ncol=6)\n",
    "plt.savefig(f\"figs/BO_C2\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pools = [\n",
    "    './out/C2_davinci_1180_1_16hh.pkl',\n",
    "    './out/C2_davinci_2950_1_16hh.pkl',\n",
    "    './out/C2_davinci_5900_1_16hh.pkl',\n",
    "    './out/C2_davinci_12744_1_16hh.pkl',\n",
    "]\n",
    "for p in pools:\n",
    "    print(p)\n",
    "    d = cloudpickle.load(open(p, \"rb\"))\n",
    "    for run in d['upper_confidence_bound'][:, :, 0]:\n",
    "        print([r[14:r.find(\",\")] for r in run])\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(16,4), constrained_layout=True)\n",
    "# for ax in axs.flat:\n",
    "#     ax.set_aspect(0.6)\n",
    "\n",
    "lim=(0,25)\n",
    "raw_data = pd.read_csv(\"dataset/data/12744_ocm_dataset.csv\", sep=\";\")\n",
    "plot_BO(axs[0], \"./out/C2_davinci_fulldataset_new_subpool_16_allrandom_1init.pkl\",\"all_random\",\n",
    "         raw_data[y_name], \"C$_2$ yield\", lim, label=True, data_file_random=\"./out/C2 - random - 12744.pkl\")\n",
    "\n",
    "plot_BO(axs[1], \"./out/C2_davinci_12744_1_16hh.pkl\",\"half_random\",\n",
    "         raw_data[y_name], \"C$_2$ yield\", lim, label=False, data_file_random=\"./out/C2 - random - 12744.pkl\")\n",
    "\n",
    "plot_BO(axs[2], \"./out/C2_davinci_fulldataset_subpool_16_no_random_1_init.pkl\", \"no_random\",\n",
    "# plot_BO(axs[2], \"./out/C2_davinci_fulldataset_subpool_16_no_random_newest_seed0_2_init.pkl\", \"no_random\",\n",
    "         raw_data[y_name], \"C$_2$ yield\", lim, label=False, data_file_random=\"./out/C2 - random - 12744.pkl\")\n",
    "\n",
    "plot_BO(axs[3], \"./out/C2_davinci_12744_1_tree_2.pkl\", \"TreePool\",\n",
    "         raw_data[y_name], \"C$_2$ yield\", lim, label=False, data_file_random=\"./out/C2 - random - 12744.pkl\")\n",
    "         \n",
    "\n",
    "fig.suptitle(\"216 samples with each subpool\")\n",
    "fig.legend(loc='upper center', bbox_to_anchor=(0.5,0),\n",
    "          fancybox=True, shadow=True, ncol=6)\n",
    "plt.savefig(f\"figs/BO_C2\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pools = [\n",
    "    # './out/C2_davinci_fulldataset_new_subpool_16_allrandom_1init.pkl',\n",
    "    # './out/C2_davinci_12744_1_16hh.pkl',\n",
    "    # './out/C2_davinci_fulldataset_subpool_16_no_random_1_init.pkl',\n",
    "    './out/C2_davinci_fulldataset_subpool_16_no_random_newest_seed0_2_init.pkl',\n",
    "    # './out/C2_davinci_12744_1_tree.pkl',\n",
    "]\n",
    "for p in pools:\n",
    "    print(p)\n",
    "    d = cloudpickle.load(open(p, \"rb\"))\n",
    "    for k in d.keys():\n",
    "        for run in d[k][:, :, 0]:\n",
    "            print(k, [r[14:r.find(\",\")] for r in run])\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_davinci = cloudpickle.load(open(\"paper/out/C2_davinci_100.pkl\", \"rb\"))\n",
    "print(d_davinci['expected_improvement'][:, -1, 1].astype(float))\n",
    "best_davinci = d_davinci['expected_improvement'][:, :, 1].astype(float).mean(axis=0)[-1]\n",
    "print(f\"DaVinci is top{np.sum(raw_data[y_name] > best_davinci)}: {best_davinci}\")\n",
    "\n",
    "d_gpt4 = cloudpickle.load(open(\"paper/out/C2_GPT4_100.pkl\", \"rb\"))\n",
    "print(d_gpt4['upper_confidence_bound'][:, -1, 1].astype(float))\n",
    "best_gpt4 = d_gpt4['upper_confidence_bound'][:, :, 1].astype(float).mean(axis=0)[-1]\n",
    "print(f\"Gpt4 is top{np.sum(raw_data[y_name] > best_gpt4)}: {best_gpt4}\")\n",
    "\n",
    "d_gpr = cloudpickle.load(open(\"paper/out/C2_GPR_100.pkl\", \"rb\"))\n",
    "print(d_gpr['expected_improvement'][:, -1, 1].astype(float))\n",
    "best_gpr = d_gpr['upper_confidence_bound'][:, :, 1].astype(float).mean(axis=0)[-1]\n",
    "print(f\"GPR is top{np.sum(raw_data[y_name] > best_gpr)}: {best_gpr}\")\n",
    "\n",
    "sns.histplot(raw_data[y_name])\n",
    "# print(np.sum(raw_data[y_name] > best))\n",
    "plt.xlabel(\"measured C$_2$ yield\")\n",
    "plt.axvline(best_davinci, color='C1', linestyle='--', label=\"Davinci\")\n",
    "plt.axvline(best_gpt4, color='C2', linestyle='--', label=\"GPT4\")\n",
    "plt.axvline(best_gpr, color='C3', linestyle='--', label=\"GPR\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"figs/hist_C2\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(raw_data[raw_data[y_name] > best_davinci])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iupac-sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "data_path = \"paper/data/esol_iupac.csv\"\n",
    "raw_data = pd.read_csv(data_path)\n",
    "raw_data = raw_data.dropna()\n",
    "raw_data = raw_data[[\"IUPAC\", \"measured log(solubility:mol/L)\"]]\n",
    "raw_data = raw_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# raw_data['measured log(solubility:mol/L)'] = -raw_data['measured log(solubility:mol/L)']\n",
    "x_name = \"IUPAC\"\n",
    "y_name = \"measured log(solubility:mol/L)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(12,4), constrained_layout=True)\n",
    "for ax in axs.flat:\n",
    "    ax.set_aspect(1.8)\n",
    "\n",
    "lim=(-5.5,2)\n",
    "\n",
    "plot_BO(axs[0], \"paper/out/sol_davinci_100.pkl\", \"Topk - davinci\",\n",
    "         raw_data[y_name], \"LogS solubility\", lim, label=False, data_file_random=\"paper/out/sol - random.pkl\")\n",
    "plot_BO(axs[1], \"paper/out/sol_gpt4_100.pkl\", \"Topk - GPT-4\",\n",
    "         raw_data[y_name], \"LogS solubility\", lim, label=False, data_file_random=\"paper/out/sol - random.pkl\")\n",
    "plot_BO(axs[2], \"paper/out/sol_GPR_100.pkl\", \"GPR\",\n",
    "         raw_data[y_name], \"LogS solubility\", lim, label=True, data_file_random=\"paper/out/sol - random.pkl\")\n",
    "\n",
    "fig.legend(loc='upper center', bbox_to_anchor=(0.5,0),\n",
    "          fancybox=True, shadow=True, ncol=6)\n",
    "plt.savefig(f\"figs/BO_sol\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_davinci = cloudpickle.load(open(\"paper/out/sol_davinci_100.pkl\", \"rb\"))\n",
    "d_gpt4 = cloudpickle.load(open(\"paper/out/sol_gpt4_100.pkl\", \"rb\"))\n",
    "d_gpr = cloudpickle.load(open(\"paper/out/sol_GPR_100.pkl\", \"rb\"))\n",
    "\n",
    "print(d_davinci['expected_improvement'][:, -1, 1].astype(float))\n",
    "best_davinci = d_davinci['expected_improvement'][:, :, 1].astype(float).mean(axis=0)[-1]\n",
    "print(f\"DaVinci is top{np.sum(raw_data[y_name] > best_davinci)}: {best_davinci}\")\n",
    "\n",
    "print(d_gpt4['expected_improvement'][:, -1, 1].astype(float))\n",
    "best_gpt4 = d_gpt4['expected_improvement'][:, :, 1].astype(float).mean(axis=0)[-1]\n",
    "print(f\"Gpt4 is top{np.sum(raw_data[y_name] > best_gpt4)}: {best_gpt4}\")\n",
    "\n",
    "print(d_gpr['expected_improvement'][:, -1, 1].astype(float))\n",
    "best_gpr = d_gpr['expected_improvement'][:, :, 1].astype(float).mean(axis=0)[-1]\n",
    "print(f\"GPR is top{np.sum(raw_data[y_name] > best_gpr)}: {best_gpr}\")\n",
    "\n",
    "sns.histplot(raw_data[y_name])\n",
    "plt.axvline(best_davinci, color='C1', linestyle='--', label=\"Davinci\")\n",
    "plt.axvline(best_gpt4, color='C2', linestyle='--', label=\"GPT4\")\n",
    "plt.axvline(best_gpr, color='C3', linestyle='--', label=\"GPR\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"figs/hist_sol\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(raw_data[raw_data[y_name] > best_davinci-0.08])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BayesOpt experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import uncertainty_toolbox as uct\n",
    "\n",
    "def combine(s, l):\n",
    "  '''Number of combinations of l elements with max = s'''\n",
    "  return (s**l - (s-1)**(l))\n",
    "\n",
    "def prob(s, l, n):\n",
    "  '''Probability of getting a sample with max([x0,x1,...,xl]) = s where xi={0,n}'''\n",
    "  return combine(s,l) * ((1/n)**l)\n",
    "\n",
    "def expected_value_p(l, n):\n",
    "  '''Expected value of max([x0,x1,...,xl]) where xi={0,n}'''\n",
    "  E = [s * prob(s, l, n) for s in range(1,100+1)]\n",
    "  return sum(E)\n",
    "\n",
    "def expected_value_q(l, n, data):\n",
    "  '''Expected value of max([x0,x1,...,xl]) where xi={0,n}'''\n",
    "  quants = [data.quantile(i/100) for i in range(100+1)]\n",
    "  # E = [(quants[s-1]) * prob(s, l, n) for s in range(1,100+1)]\n",
    "  E = [((quants[s-1]+quants[s])/2) * prob(s, l, n) for s in range(1,100+1)]\n",
    "  return sum(E)\n",
    "\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")\n",
    "\n",
    "# @retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def run_experiment(\n",
    "    asktell, pool, raw_data, indexes, x_name, y_name, N=10, initial_train=1, ask_K=1, aq=\"random\", start_index=0, calibrate=False\n",
    "):\n",
    "    if aq=='random_mean':\n",
    "       return [ (i, expected_value_q(i, 100, raw_data[y_name])) for i in range(1,N+1) ]\n",
    "    for i in indexes[:initial_train]:\n",
    "        asktell.tell(raw_data[x_name].iloc[i], float(raw_data[y_name].iloc[i]))\n",
    "    if calibrate:\n",
    "        # y = [float(raw_data[y_name].iloc[i]) for i in indexes[:initial_train]]\n",
    "        # pred = asktell.predict(y)\n",
    "        # ymeans = np.array([yhi.mean() for yhi in pred])\n",
    "        # ystds = np.array([yhi.std() for yhi in pred])\n",
    "        # calibration_factor = uct.recalibration.optimize_recalibration_ratio(ymeans, ystds, np.array(y), criterion=\"miscal\")\n",
    "        calibration_factor = 5.0\n",
    "        asktell.set_calibration_factor(calibration_factor)\n",
    "\n",
    "    x = raw_data[x_name].tolist()\n",
    "\n",
    "    pool.reset()\n",
    "    xi = x[start_index]\n",
    "    x.remove(xi)\n",
    "    pool.choose(xi)\n",
    "    yi = float(raw_data[raw_data[x_name] == xi][y_name].iloc[0])\n",
    "    asktell.tell(xi, yi)\n",
    "    point = [(xi, 1+initial_train, yi, yi)]\n",
    "    best = point[0][-1]\n",
    "    for i in range(1, N):\n",
    "        if i == N - 1 and aq != \"random\":\n",
    "            aq = \"greedy\"\n",
    "        px, _, py = asktell.ask(pool, \n",
    "                                k=ask_K, \n",
    "                                aq_fxn=aq, \n",
    "                                _lambda=1.0, \n",
    "                                inv_filter=16,\n",
    "                                aug_random_filter=0,\n",
    "                                )\n",
    "        for j in range(ask_K):\n",
    "          xc = px[j]\n",
    "          x.remove(xc)\n",
    "          pool.choose(xc)\n",
    "          y = float(raw_data[raw_data[x_name] == xc][y_name].iloc[0])\n",
    "          asktell.tell(xc, y)\n",
    "          best = max(y, best)\n",
    "        point.append((xc, 1+initial_train+i*ask_K, best, y))\n",
    "    return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataset(data: str, M=5):\n",
    "    match data:\n",
    "        case \"in-house\":\n",
    "            data_path = \"./dataset/data/71023_BO_ready_pool.csv\"\n",
    "            raw_data = pd.read_csv(data_path)\n",
    "\n",
    "            raw_data['Catalyst'] = raw_data['Prompt'].str.extract(r'(\\b[A-Z][a-z]?:[A-Z][a-z]?:[A-Z][a-z]?\\b)')\n",
    "            unique_cat = raw_data['Catalyst'].unique()\n",
    "            c = {c: 0.2+m*(5/len(unique_cat)) for m, c in enumerate(unique_cat)}\n",
    "            raw_data['dummy_Completion'] = raw_data['Catalyst'].apply(lambda x: np.random.normal(c[x], 0.05))\n",
    "\n",
    "            x_name = \"Prompt\"\n",
    "            y_name = \"dummy_Completion\"\n",
    "        case \"ocm\":\n",
    "            data_path = \"./dataset/data/12744_ocm_dataset.csv\"\n",
    "            raw_data = pd.read_csv(data_path, sep=\";\")\n",
    "            raw_data = raw_data.sample(frac=1).reset_index(drop=True)\n",
    "            x_name = \"prompt\"\n",
    "            y_name = \"completion\"\n",
    "        case \"sol\":\n",
    "            data_path = \"./dataset/data/esol_iupac.csv\"\n",
    "            raw_data = pd.read_csv(data_path)\n",
    "            raw_data = raw_data.dropna()\n",
    "            raw_data = raw_data[[\"IUPAC\", \"measured log(solubility:mol/L)\"]]\n",
    "            raw_data = raw_data.sample(frac=1).reset_index(drop=True)\n",
    "            x_name = \"IUPAC\"\n",
    "            y_name = \"measured log(solubility:mol/L)\"\n",
    "        case _:\n",
    "            raise ValueError(\"Unknown data\")\n",
    "        \n",
    "\n",
    "    N = raw_data.shape[0]\n",
    "    indexes = np.random.choice(raw_data.shape[0], int(N), replace=False)\n",
    "\n",
    "    print(f\"Dataset size: \\n\\t{N}\")\n",
    "    starts = raw_data.sort_values(by=y_name, ascending=True).head(100).sample(M)# np.random.randint(0, len(indexes), M)\n",
    "    print(f\"Start xs: \\n\\t{starts[x_name].to_list()}\")\n",
    "    print(f\"Start ys: \\n\\t{starts[y_name].to_list()}\")\n",
    "    starts = starts.index\n",
    "    print(f\"Start indexes: \\n\\t{starts}\\n\")\n",
    "\n",
    "    return raw_data, starts, indexes, x_name, y_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def get_asktell(model: str, kwargs: dict = {}, pool: bolift.Pool = None, knn: int = 1):\n",
    "    match model:\n",
    "        case \"instruct\":\n",
    "            kwargs['model']=\"gpt-3.5-turbo-instruct\"\n",
    "            return bolift.AskTellFewShotTopk(**kwargs)\n",
    "        case \"gpt-turbo\":\n",
    "            kwargs['model']=\"gpt-3.5-turbo\"\n",
    "            return bolift.AskTellFewShotTopk(**kwargs)\n",
    "        case \"gpt-4\":\n",
    "            kwargs['model']=\"gpt-4\"\n",
    "            return bolift.AskTellFewShotTopk(**kwargs)\n",
    "        case \"davinci\":\n",
    "            kwargs['model']=\"text-davinci-003\"\n",
    "            return bolift.AskTellFewShotTopk(**kwargs)\n",
    "        case \"curie\":\n",
    "            kwargs['model']=\"text-curie-001\"\n",
    "            return bolift.AskTellFewShotTopk(**kwargs)\n",
    "        case \"gpr\":\n",
    "            kwargs['pool'] = pool if pool else None\n",
    "            kwargs['n_components'] = 32\n",
    "            return bolift.AskTellGPR(**kwargs)\n",
    "        case \"knn\":\n",
    "            del kwargs['selector_k']\n",
    "            kwargs['knn'] = knn\n",
    "            return bolift.AskTellNearestNeighbor(**kwargs)\n",
    "        case \"krr\":\n",
    "            kwargs['alpha'] = 0.5\n",
    "            return bolift.AskTellRidgeKernelRegression(**kwargs)\n",
    "        case _:\n",
    "            raise ValueError(\"Unknown model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def read_bkp(path, pool_path, indexes, kwargs):\n",
    "    if os.path.exists(pool_path):\n",
    "        with open(pool_path, \"rb\") as f:\n",
    "            pool = cloudpickle.load(f)\n",
    "        pool.reset()\n",
    "    else:\n",
    "        x = [raw_data[x_name].iloc[i] for i in indexes]\n",
    "        pool = bolift.Pool(list(x), formatter=kwargs['x_formatter'])\n",
    "        cloudpickle.dump(pool, open(pool_path, \"wb\"))\n",
    "\n",
    "    if os.path.exists(path):\n",
    "        bayesOpts = cloudpickle.load(open(path, \"rb\"))\n",
    "    else:\n",
    "        bayesOpts = {}\n",
    "    return bayesOpts, pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config BO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "initial_train = 0\n",
    "ask_K = 5\n",
    "N=20\n",
    "M=5\n",
    "model=\"krr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in-house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "dataset=\"in-house\"\n",
    "kwargs = dict(\n",
    "    prefix=\"\",\n",
    "    prompt_template=PromptTemplate(\n",
    "        input_variables=[\"x\", \"y\", \"y_name\"],\n",
    "        template=\"Q: What is the {y_name} of {x}?@@@\\nA: {y}###\",\n",
    "    ),\n",
    "    suffix=\"What is the {y_name} of {x}?@@@\\nA:\",\n",
    "    x_formatter=lambda x: f\"experimental procedure: {x}\",\n",
    "    y_name=\"C2 yield\",\n",
    "    y_formatter=lambda y: f\"{y:.2f}\",\n",
    "    selector_k=5,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "path = f\"./out/{dataset}_{model}_42000_{initial_train}_{ask_K}_16nr.pkl\"\n",
    "pool_path = \"./dataset/data/42000_in-house_pool.pkl\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "dataset=\"ocm\"\n",
    "kwargs = dict(\n",
    "    prefix=\"\",\n",
    "    prompt_template=PromptTemplate(\n",
    "        input_variables=[\"x\", \"y\", \"y_name\"],\n",
    "        template=\"Q: What is the {y_name} of {x}?@@@\\nA: {y}###\",\n",
    "    ),\n",
    "    suffix=\"What is the {y_name} of {x}?@@@\\nA:\",\n",
    "    x_formatter=lambda x: f\"experimental procedure: {x}\",\n",
    "    y_name=\"C2 yield\",\n",
    "    y_formatter=lambda y: f\"{y:.2f}\",\n",
    "    selector_k=5,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "path = f\"./out/{dataset}_{model}_12744_{initial_train}_{ask_K}_16nr.pkl\"\n",
    "pool_path = \"./dataset/data/12744_ocm_pool.pkl\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solubility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "dataset=\"sol\"\n",
    "kwargs = dict(\n",
    "    prefix=\"\",\n",
    "    prompt_template=PromptTemplate(\n",
    "        input_variables=[\"x\", \"y\", \"y_name\"],\n",
    "        template=\"Q: What is the {y_name} of {x}?@@@\\nA: {y}###\",\n",
    "    ),\n",
    "    suffix=\"What is the {y_name} of {x}?@@@\\nA:\",\n",
    "    x_formatter=lambda x: f\"iupac name {x}\",\n",
    "    y_name=\"measured log solubility in mols per litre\",\n",
    "    y_formatter=lambda y: f\"{y:.2f}\",\n",
    "    selector_k=5,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "path = f\"./out/{dataset}_{model}_882_{initial_train}_{ask_K}_16nr.pkl\"\n",
    "pool_path = \"./out/sol_pool.pkl\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run BO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: \n",
      "\t882\n",
      "Start xs: \n",
      "\t['1-methoxy-4-[2,2,2-trichloro-1-(4-methoxyphenyl)ethyl]benzene', '1,2,4,5-tetrachlorobenzene', '(2,3,5,6-tetrafluoro-4-methylphenyl)methyl 3-(2-chloro-3,3,3-trifluoroprop-1-enyl)-2,2-dimethylcyclopropane-1-carboxylate', '5-tert-butyl-3-(2,4-dichloro-5-propan-2-yloxyphenyl)-1,3,4-oxadiazol-2-one', 'N-ethyl-N-(2-methylprop-2-enyl)-2,6-dinitro-4-(trifluoromethyl)aniline']\n",
      "Start ys: \n",
      "\t[-6.89, -5.56, -7.321, -5.696, -6.124]\n",
      "Start indexes: \n",
      "\tIndex([370, 21, 847, 785, 724], dtype='int64')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='Changing the sparsity structure of a csr_matrix is expensive.*')\n",
    "warnings.filterwarnings('ignore', message='Input data is not contained to the unit cube.*')\n",
    "warnings.filterwarnings('ignore', message='Input data is not standardized.*')\n",
    "warnings.filterwarnings('ignore', message=\"Keyword arguments .* will be ignored because they are not allowed parameters for function .*\", category=UserWarning)\n",
    "\n",
    "raw_data, starts, indexes, x_name, y_name= get_dataset(dataset, M=M)\n",
    "bayesOpts, pool = read_bkp(path, pool_path, indexes, kwargs)\n",
    "\n",
    "asktell = get_asktell(model, kwargs=kwargs, pool=bolift.Pool(list(pool.sample(200))), knn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_mean start: 0,  1,  2,  3,  4,  random_mean done\n",
      "random start: 0,  1,  2,  3,  4,  random done\n",
      "expected_improvement start: 0,  "
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AskTellNearestNeighbor' object has no attribute 'inv_prompt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb Cell 36\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(M):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mprint\u001b[39m(i, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m,  \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     point \u001b[39m=\u001b[39m run_experiment(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         copy\u001b[39m.\u001b[39;49mdeepcopy(asktell),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         copy\u001b[39m.\u001b[39;49mdeepcopy(pool),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         raw_data,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         indexes,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         x_name,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         y_name,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         N\u001b[39m=\u001b[39;49mN,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         aq\u001b[39m=\u001b[39;49maq,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         start_index\u001b[39m=\u001b[39;49mstarts[i],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         calibrate\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         initial_train\u001b[39m=\u001b[39;49minitial_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         ask_K\u001b[39m=\u001b[39;49mask_K\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     points\u001b[39m.\u001b[39mappend(point)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m points \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(points)\n",
      "\u001b[1;32m/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb Cell 36\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m N \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m aq \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrandom\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     aq \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgreedy\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m px, _, py \u001b[39m=\u001b[39m asktell\u001b[39m.\u001b[39;49mask(pool, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m                         k\u001b[39m=\u001b[39;49mask_K, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m                         aq_fxn\u001b[39m=\u001b[39;49maq, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m                         _lambda\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m                         inv_filter\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m                         aug_random_filter\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m                         )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(ask_K):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#X50sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m   xc \u001b[39m=\u001b[39m px[j]\n",
      "File \u001b[0;32m~/miniconda3/envs/bolift/lib/python3.11/site-packages/bolift/asktell.py:413\u001b[0m, in \u001b[0;36mAskTellFewShotMulti.ask\u001b[0;34m(self, possible_x, aq_fxn, k, inv_filter, aug_random_filter, _lambda)\u001b[0m\n\u001b[1;32m    411\u001b[0m possible_x_l \u001b[39m=\u001b[39m []\n\u001b[1;32m    412\u001b[0m \u001b[39mif\u001b[39;00m inv_filter:\n\u001b[0;32m--> 413\u001b[0m     approx_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minv_predict(best \u001b[39m*\u001b[39;49m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mnormal(\u001b[39m1.0\u001b[39;49m, \u001b[39m0.05\u001b[39;49m))\n\u001b[1;32m    414\u001b[0m     possible_x_l\u001b[39m.\u001b[39mextend(possible_x\u001b[39m.\u001b[39mapprox_sample(approx_x, inv_filter))\n\u001b[1;32m    415\u001b[0m \u001b[39mif\u001b[39;00m aug_random_filter:\n",
      "File \u001b[0;32m~/miniconda3/envs/bolift/lib/python3.11/site-packages/bolift/asktell.py:289\u001b[0m, in \u001b[0;36mAskTellFewShotMulti.inv_predict\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ready:\n\u001b[1;32m    286\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    287\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMust tell at least one example before inverse predicting.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m     )\n\u001b[0;32m--> 289\u001b[0m query \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minv_prompt\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    290\u001b[0m     y\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat_y(y), y_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y_name, x_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_x_name\n\u001b[1;32m    291\u001b[0m )\n\u001b[1;32m    292\u001b[0m query \u001b[39m=\u001b[39m wrap_chatllm(query, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minv_llm)\n\u001b[1;32m    293\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minv_llm(query)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AskTellNearestNeighbor' object has no attribute 'inv_prompt'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', message='Changing the sparsity structure of a csr_matrix is expensive.*')\n",
    "warnings.filterwarnings('ignore', message='Input data is not contained to the unit cube.*')\n",
    "warnings.filterwarnings('ignore', message='Input data is not standardized.*')\n",
    "warnings.filterwarnings('ignore', message=\"Keyword arguments .* will be ignored because they are not allowed parameters for function .*\", category=UserWarning)\n",
    "\n",
    "for aq in ['random_mean', 'expected_improvement', 'random']: #[\"random\", \"expected_improvement\", \"greedy\", 'upper_confidence_bound', 'probability_of_improvement']:\n",
    "    print(aq, \"start:\", end=\" \")\n",
    "    points = []\n",
    "    for i in range(M):\n",
    "        print(i, end=\",  \")\n",
    "        point = run_experiment(\n",
    "            copy.deepcopy(asktell),\n",
    "            copy.deepcopy(pool),\n",
    "            raw_data,\n",
    "            indexes,\n",
    "            x_name,\n",
    "            y_name,\n",
    "            N=N,\n",
    "            aq=aq,\n",
    "            start_index=starts[i],\n",
    "            calibrate=True,\n",
    "            initial_train=initial_train,\n",
    "            ask_K=ask_K\n",
    "        )\n",
    "        points.append(point)\n",
    "    points = np.array(points)\n",
    "    bayesOpts[aq] = points\n",
    "    print(aq, \"done\")\n",
    "    if isinstance(asktell, bolift.AskTellGPR):\n",
    "        asktell.save_cache(\"GPR_ada_embed_cache.csv\")\n",
    "    cloudpickle.dump(bayesOpts, open(path, \"wb\"))\n",
    "cloudpickle.dump(bayesOpts, open(path, \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './out/ocm_gpr_12744_0_5_16nr.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb Cell 37\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#Y145sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m title \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath[\u001b[39m6\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m4\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#Y145sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m d \u001b[39m=\u001b[39m cloudpickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39;49m(path, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#Y145sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m data\u001b[39m=\u001b[39mraw_data[y_name]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maykcaldas/Documents/WhiteLab/BO-LIFT/paper/BO_experiments.ipynb#Y145sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m lim\u001b[39m=\u001b[39m(data\u001b[39m.\u001b[39mmin()\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, data\u001b[39m.\u001b[39mmax()\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/bolift/lib/python3.11/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './out/ocm_gpr_12744_0_5_16nr.pkl'"
     ]
    }
   ],
   "source": [
    "title = f\"{path[6:-4]}\"\n",
    "d = cloudpickle.load(open(path, \"rb\"))\n",
    "data=raw_data[y_name]\n",
    "lim=(data.min()-1, data.max()+1)\n",
    "\n",
    "# name = \"LogS\"\n",
    "name = \"C$_2$ yield\"\n",
    "\n",
    "\n",
    "def plot_config():\n",
    "    plt.title(title)\n",
    "    plt.axhline(y=data.max(), color=\"C15\", linestyle=\"--\")\n",
    "    plt.text(plt.xlim()[1]+1, data.max(), \"max\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "    plt.axhline(y=data.quantile(0.99), color=\"C14\", linestyle=\"--\")\n",
    "    plt.text(plt.xlim()[1]+1, data.quantile(0.99), \"99%\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "    plt.axhline(y=data.quantile(0.95), color=\"C13\", linestyle=\"--\")\n",
    "    plt.text(plt.xlim()[1]+1, data.quantile(0.95), \"95%\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "    plt.axhline(y=data.mean(), color=\"C12\", linestyle=\"--\")\n",
    "    plt.text(plt.xlim()[1]+1, data.mean(), \"mean\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "    plt.axhline(y=data.quantile(0.05), color=\"C11\", linestyle=\"--\")\n",
    "    plt.text(plt.xlim()[1]+1, data.quantile(0.05), \"5%\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "    plt.axhline(y=data.min(), color=\"C10\", linestyle=\"--\")\n",
    "    plt.text(plt.xlim()[1]+1, data.min(), \"Min\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "    plt.ylim(lim)\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5,-0.1),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "\n",
    "#Debugging plots\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(6,4), constrained_layout=True)\n",
    "plot_BO(axs, path, title, \n",
    "         raw_data[y_name], name, lim, label=True)\n",
    "fig.legend(loc='upper center', bbox_to_anchor=(0.5,0),\n",
    "          fancybox=True, shadow=True, ncol=6)\n",
    "plt.show()\n",
    "\n",
    "# Plot best value on the entire run\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.xlabel(\"Number of samples\")\n",
    "# plt.ylabel(\"Max C$_2$ yield\")\n",
    "plt.ylabel(f\"Max {name}\")\n",
    "for i in range(M):\n",
    "    plt.plot(d['expected_improvement'][i,:,1], d['expected_improvement'][i, :, 2].astype(float), label=f\"run {i}\")\n",
    "# plt.plot(d[\"expected_improvement\"][i,:,1], d[\"expected_improvement\"][:, :, 2].astype(float).mean(axis=0), label=f\"EI\", color=\"C1\")\n",
    "# plt.plot(d[\"random\"][i,:,1], d[\"random\"][:, :, 2].astype(float).mean(axis=0), label=f\"random\", color=\"C5\")\n",
    "plot_config()\n",
    "plt.show()\n",
    "\n",
    "# Plot current values on each iteration\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.xlabel(\"Number of samples\")\n",
    "plt.ylabel(f\"{name}\")\n",
    "for i in range(M):\n",
    "    plt.plot(d['expected_improvement'][i,:,1], d['expected_improvement'][i, :, 3].astype(float), label=f\"run {i}\")\n",
    "# plt.plot(d[\"expected_improvement\"][i,:,1], d[\"expected_improvement\"][:, :, 3].astype(float).mean(axis=0), label=f\"EI\", color=\"C1\")\n",
    "# plt.plot(d[\"random\"][i,:,1], d[\"random\"][:, :, 3].astype(float).mean(axis=0), label=f\"random\", color=\"C5\")\n",
    "plot_config()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in-house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_asktell():\n",
    "  return bolift.AskTellFewShotTopk(\n",
    "    # prefix=\"You are a bot who knows chemistry and catalysts. \" \\\n",
    "    #       \"Below, you'll see examples of experimental procedures to synthesize catalysts and the measured CO STY in a oxidative methane coupling reaction. \" \\\n",
    "    #       \"The following question should be answered with a number and finished with ###\\n\",\n",
    "    prefix=\"\",\n",
    "    prompt_template=PromptTemplate(\n",
    "        input_variables=[\"x\", \"y\", \"y_name\"],\n",
    "        template=\"Q: What is the {y_name} of {x}?@@@\\nA: {y}###\",\n",
    "    ),\n",
    "    suffix=\"What is the {y_name} of {x}?@@@\\nA:\",\n",
    "    x_formatter=lambda x: f\"experimental procedure: {x}\",\n",
    "    y_name=\"C2 yield\",\n",
    "    y_formatter=lambda y: f\"{y:.2f}\",\n",
    "    # model=\"text-curie-001\",\n",
    "    # model=\"text-davinci-003\",\n",
    "    model = \"gpt-3.5-turbo-instruct\",\n",
    "    # model=\"gpt-4\",\n",
    "    selector_k=5,\n",
    "    temperature=0.7,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000 42000\n",
      "                                                  Prompt  Completion  \\\n",
      "25207  2.0 g of Fe:Ni:Zn(1:10:5)/ZrO2 catalyst is pro...         NaN   \n",
      "19621  2.0 g of Fe:Ni:Zn(10:5:5)/MgO catalyst is prod...         NaN   \n",
      "35006  2.0 g of Fe:Ni:Zn(1:10:1)/Al2O3 catalyst is pr...         NaN   \n",
      "32209  2.0 g of Fe:Ni:Zn(5:1:1)/ZrO2 catalyst is prod...         NaN   \n",
      "9817   2.0 g of Fe:Ni:Zn(10:1:1)/TiO2 (rutile) cataly...         NaN   \n",
      "\n",
      "       Catalyst  dummy_Completion  \n",
      "25207  Fe:Ni:Zn          0.117423  \n",
      "19621  Fe:Ni:Zn          0.128967  \n",
      "35006  Fe:Ni:Zn          0.123826  \n",
      "32209  Fe:Ni:Zn          0.094579  \n",
      "9817   Fe:Ni:Zn          0.130724  \n",
      "Index([25207, 19621, 35006, 32209, 9817], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "data_path = \"./dataset/data/71023_BO_ready_pool.csv\"\n",
    "path_random = \"./out/in-house - random - 42000.pkl\"\n",
    "# template:    db_model_dbFilter_initial_pool\n",
    "path = \"./out/in-house_davinci_42000_0_16nr_krandom.pkl\"\n",
    "pool_path = \"./dataset/data/42000_in-house_pool.pkl\"\n",
    "\n",
    "initial_train = 0\n",
    "ask_K = 1\n",
    "raw_data = pd.read_csv(data_path)\n",
    "\n",
    "raw_data['Catalyst'] = raw_data['Prompt'].str.extract(r'(\\b[A-Z][a-z]?:[A-Z][a-z]?:[A-Z][a-z]?\\b)')\n",
    "unique_cat = raw_data['Catalyst'].unique()\n",
    "c = {c: 0.2+m*(5/len(unique_cat)) for m, c in enumerate(unique_cat)}\n",
    "raw_data['dummy_Completion'] = raw_data['Catalyst'].apply(lambda x: np.random.normal(c[x], 0.05))\n",
    "\n",
    "N = raw_data.shape[0]\n",
    "indexes = np.random.choice(raw_data.shape[0], int(N), replace=False)\n",
    "x_name = \"Prompt\"\n",
    "y_name = \"dummy_Completion\"\n",
    "print(N, len(indexes))\n",
    "\n",
    "if os.path.exists(pool_path):\n",
    "  with open(pool_path, \"rb\") as f:\n",
    "    pool = cloudpickle.load(f)\n",
    "  pool.reset()\n",
    "else:\n",
    "  x = [raw_data[x_name].iloc[i] for i in indexes]\n",
    "  pool = bolift.Pool(list(x), formatter=lambda x: f\"experimental procedure: {x}\")\n",
    "  cloudpickle.dump(pool, open(pool_path, \"wb\"))\n",
    "\n",
    "N = 20\n",
    "M = 5\n",
    "starts = raw_data.sort_values(by=y_name, ascending=True).head(100).sample(M)# np.random.randint(0, len(indexes), M)\n",
    "print(starts)\n",
    "starts = starts.index\n",
    "print(starts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(path):\n",
    "    bayesOpts_random = cloudpickle.load(open(path_random, \"rb\")) #random_mean\n",
    "    bayesOpts = cloudpickle.load(open(path, \"rb\"))\n",
    "else:\n",
    "    bayesOpts = {}\n",
    "\n",
    "for aq in ['random', 'expected_improvement']: #[\"random\", \"expected_improvement\", \"greedy\", 'upper_confidence_bound', 'probability_of_improvement']:\n",
    "    print(aq, \"start:\", end=\" \")\n",
    "    points = []\n",
    "    for i in range(M):\n",
    "        asktell = get_asktell()\n",
    "        print(i, end=\",  \")\n",
    "        point = run_experiment(\n",
    "            copy.deepcopy(asktell),\n",
    "            copy.deepcopy(pool),\n",
    "            raw_data,\n",
    "            indexes,\n",
    "            x_name,\n",
    "            y_name,\n",
    "            N=N,\n",
    "            aq=aq,\n",
    "            start_index=starts[i],\n",
    "            calibrate=True,\n",
    "            initial_train=initial_train,\n",
    "            ask_K=ask_K\n",
    "        )\n",
    "        points.append(point)\n",
    "    points = np.array(points)\n",
    "    bayesOpts[aq] = points\n",
    "    print(aq, \"done\")\n",
    "    # asktell.save_cache(\"GPR_ada_embed_cache.csv\")\n",
    "    cloudpickle.dump(bayesOpts, open(path, \"wb\"))\n",
    "cloudpickle.dump(bayesOpts, open(path, \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debugging plots\n",
    "import re\n",
    "path=\"./out/in-house_davinci_42000_0_16nr_krandom.pkl\"\n",
    "title = \"in-house / no_random \"\n",
    "d = cloudpickle.load(open(path, \"rb\"))\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(6,4), constrained_layout=True)\n",
    "# for ax in axs.flat:\n",
    "#     ax.set_aspect(0.6)\n",
    "lim=(-0.5, 6)\n",
    "plot_BO(axs, path, title, \n",
    "         raw_data[y_name], \"C$_2$ yield\", lim, label=True, data_file_random=path_random)\n",
    "fig.legend(loc='upper center', bbox_to_anchor=(0.5,0),\n",
    "          fancybox=True, shadow=True, ncol=6)\n",
    "plt.savefig(f\"figs/BO_C2\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.xlabel(\"Number of samples\")\n",
    "plt.ylabel(\"Catalyst mean STY\")\n",
    "plt.title(title)\n",
    "for i in range(M):\n",
    "    cats = [re.search(r'(\\b[A-Z][a-z]?:[A-Z][a-z]?:[A-Z][a-z]?\\b)',k).group(0) for k in d['expected_improvement'][i, :, 0]]\n",
    "    print(cats)\n",
    "    cats_ndx = [c[cat] for cat in cats]\n",
    "    plt.plot(d['expected_improvement'][i,:,1], cats_ndx, label=f\"run {i}\")\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5,-0.1),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.xlabel(\"Number of samples\")\n",
    "plt.ylabel(\"Max catalyst mean STY\")\n",
    "plt.title(title)\n",
    "for i in range(M):\n",
    "    plt.plot(d['expected_improvement'][i,:,1], d['expected_improvement'][i, :, 2].astype(float), label=f\"run {i}\")\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5,-0.1),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.xlabel(\"Number of samples\")\n",
    "plt.ylabel(\"Catalyst mean STY\")\n",
    "plt.title(title)\n",
    "for i in range(M):\n",
    "    plt.plot(d['expected_improvement'][i,:,1], d['expected_improvement'][i, :, 3].astype(float), label=f\"run {i}\")\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5,-0.1),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['2.0 g of Zn:Mo:W(5:10:10)/MgO catalyst is produced by impregnating 1.9 g of MgO with zinc nitrate hexahydrate (0.0200 g, 0.306 mmol Zn), ammonium molybdate(para) tetrahydrate (0.0400 g, 0.417 mmol Mo), ammonium metatungstate hydrate (0.0400 g, 0.218 mmol W). The impregnated sample is heated to 90 °C, dried for four hours, then calcined at 450 °C for an additional four hours. A 25.0 mg portion of the calcined sample is pretreated at 450 °C for two hours under a flow of H2 (20 mL/min), then used for CO2 hydrogenation at 275 °C with a CO2/H2/Ar mixture (22.2%/66.7%/11.1%) flowing at 45 mL/min.',\n",
       "  '2.0 g of W:V:Mn(1:1:5)/ZrO2 catalyst is produced by impregnating 1.9 g of ZrO2 with ammonium metatungstate hydrate (0.0143 g, 0.078 mmol W), vanadium(iii) chloride (0.0143 g, 0.280 mmol V), manganese(ii) nitrate hydrate (0.0714 g, 1.300 mmol Mn). The impregnated sample is heated to 90 °C, dried for four hours, then calcined at 450 °C for an additional four hours. A 150.0 mg portion of the calcined sample is pretreated at 450 °C for two hours under a flow of H2 (20 mL/min), then used for CO2 hydrogenation at 275 °C with a CO2/H2/Ar mixture (22.2%/66.7%/11.1%) flowing at 45 mL/min.',\n",
       "  '2.0 g of Cu:Mo:V(10:10:5)/ZrO2 catalyst is produced by impregnating 1.9 g of ZrO2 with copper(ii) nitrate hydrate (0.0400 g, 0.629 mmol Cu), ammonium molybdate(para) tetrahydrate (0.0400 g, 0.417 mmol Mo), vanadium(iii) chloride (0.0200 g, 0.393 mmol V). The impregnated sample is heated to 90 °C, dried for four hours, then calcined at 450 °C for an additional four hours. A 25.0 mg portion of the calcined sample is then used for CO2 hydrogenation at 275 °C with a CO2/H2/Ar mixture (22.2%/66.7%/11.1%) flowing at 45 mL/min.',\n",
       "  '2.0 g of Cu:Mo:V(10:5:1)/TiO2 (rutile) catalyst is produced by impregnating 1.9 g of TiO2 (rutile) with copper(ii) nitrate hydrate (0.0625 g, 0.984 mmol Cu), ammonium molybdate(para) tetrahydrate (0.0312 g, 0.326 mmol Mo), vanadium(iii) chloride (0.0063 g, 0.123 mmol V). The impregnated sample is heated to 90 °C, dried for four hours, then calcined at 450 °C for an additional four hours. A 150.0 mg portion of the calcined sample is pretreated at 450 °C for two hours under a flow of H2 (20 mL/min), then used for CO2 hydrogenation at 275 °C with a CO2/H2/Ar mixture (22.2%/66.7%/11.1%) flowing at 45 mL/min.',\n",
       "  '2.0 g of Fe:Mo:V(10:5:10)/MgO catalyst is produced by impregnating 1.9 g of MgO with iron(iii) nitrate nonahydrate (0.0400 g, 0.716 mmol Fe), ammonium molybdate(para) tetrahydrate (0.0200 g, 0.208 mmol Mo), vanadium(iii) chloride (0.0400 g, 0.785 mmol V). The impregnated sample is heated to 90 °C, dried for four hours, then calcined at 450 °C for an additional four hours. A 25.0 mg portion of the calcined sample is then used for CO2 hydrogenation at 275 °C with a CO2/H2/Ar mixture (22.2%/66.7%/11.1%) flowing at 45 mL/min.'],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_name, y_name = \"Prompt\", \"Completion\"\n",
    "raw_data_w_label = raw_data.dropna()\n",
    "asktell = get_asktell()\n",
    "asktell.tell(raw_data_w_label[x_name].iloc[0], float(raw_data_w_label[y_name].iloc[0]))\n",
    "asktell.ask(pool, k=5, aq_fxn=\"expected_improvement\", _lambda=1.0, inv_filter=16, aug_random_filter=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000 42000\n",
      "If C2 yield is 2.78, then input is @@@\n",
      "experimental procedure: 2.0 g of Ni:Cu:Mn(5:1:1)/SiO2 catalyst is produced by impregnating 1.9 g of SiO2 with nickel(ii) nitrate hexahydrate (0.0714 g, 1.217 mmol Ni), copper(ii) nitrate hydrate (0.0143 g, 0.225 mmol Cu), manganese(ii) nitrate hydrate (0.0143 g, 0.260 mmol Mn). The impregnated sample is heated to 90 °C, dried for four hours, then calcined at 450 °C for an additional four hours. A 25.0 mg portion of the calcined sample is pretreated at 450 °C for two hours under a flow of H2 (20 mL/min), then used for CO2 hydrogenation at 275 °C with a CO2/H2/Ar mixture (22.2%/66.7%/11.1%) flowing at 45 mL/min.###\n",
      "\n",
      "If C2 yield is 5.09, then input is @@@\n",
      "experimental procedure: 2.0 g of W:V:Mn(10:10:1)/MgO catalyst is produced by impregnating 1.9 g of MgO with ammonium metatungstate hydrate (0.0476 g, 0.259 mmol W), vanadium(iii) chloride (0.0476 g, 0.935 mmol V), manganese(ii) nitrate hydrate (0.0048 g, 0.087 mmol Mn). The impregnated sample is heated to 90 °C, dried for four hours, then calcined at 450 °C for an additional four hours. A 150.0 mg portion of the calcined sample is then used for CO2 hydrogenation at 275 °C with a CO2/H2/Ar mixture (22.2%/66.7%/11.1%) flowing at 45 mL/min.###\n",
      "\n",
      "If C2 yield is 0.52, then input is @@@\n",
      "experimental procedure: 2.0 g of Fe:Ni:V(10:10:1)/Al2O3 catalyst is produced by impregnating 1.9 g of Al2O3 with iron(iii) nitrate nonahydrate (0.0476 g, 0.853 mmol Fe), nickel(ii) nitrate hexahydrate (0.0476 g, 0.811 mmol Ni), vanadium(iii) chloride (0.0048 g, 0.093 mmol V). The impregnated sample is heated to 90 °C, dried for four hours, then calcined at 450 °C for an additional four hours. A 25.0 mg portion of the calcined sample is pretreated at 450 °C for two hours under a flow of H2 (20 mL/min), then used for CO2 hydrogenation at 275 °C with a CO2/H2/Ar mixture (22.2%/66.7%/11.1%) flowing at 45 mL/min.###\n",
      "\n",
      "If C2 yield is 3.65, then input is @@@\n",
      "experimental procedure: 2.0 g of Zn:Cu:Mn(1:5:1)/MgO catalyst is produced by impregnating 1.9 g of MgO with zinc nitrate hexahydrate (0.0143 g, 0.219 mmol Zn), copper(ii) nitrate hydrate (0.0714 g, 1.124 mmol Cu), manganese(ii) nitrate hydrate (0.0143 g, 0.260 mmol Mn). The impregnated sample is heated to 90 °C, dried for four hours, then calcined at 450 °C for an additional four hours. A 25.0 mg portion of the calcined sample is pretreated at 450 °C for two hours under a flow of H2 (20 mL/min), then used for CO2 hydrogenation at 275 °C with a CO2/H2/Ar mixture (22.2%/66.7%/11.1%) flowing at 45 mL/min.###\n",
      "\n",
      "If C2 yield is 0.20, then input is @@@\n",
      "experimental procedure: 2.0 g of Fe:Ni:Zn(1:1:5)/Al2O3 catalyst is produced by impregnating 1.9 g of Al2O3 with iron(iii) nitrate nonahydrate (0.0143 g, 0.256 mmol Fe), nickel(ii) nitrate hexahydrate (0.0143 g, 0.243 mmol Ni), zinc nitrate hexahydrate (0.0714 g, 1.093 mmol Zn). The impregnated sample is heated to 90 °C, dried for four hours, then calcined at 450 °C for an additional four hours. A 25.0 mg portion of the calcined sample is pretreated at 450 °C for two hours under a flow of H2 (20 mL/min), then used for CO2 hydrogenation at 275 °C with a CO2/H2/Ar mixture (22.2%/66.7%/11.1%) flowing at 45 mL/min.###\n",
      "\n",
      "If C2 yield is 15.00, then input is @@@\n",
      "\n",
      "\n",
      "experimental procedure: 2.0 g of Co:Ni:Cu(1:1:5)/SiO2 catalyst is produced by impregnating 1.9 g of SiO2 with cobalt(ii) nitrate hexahydrate (0.0714 g, 1.217 mmol Co), nickel(ii) nitrate hexahydrate (0.0714 g, 1.217 mmol Ni), copper(ii) nitrate hydrate (0.357 g, 5.616 mmol Cu). The impregnated sample is heated to 90 °C, dried for four hours, then calcined at 450 °C for an additional four hours. A 25.0 mg portion of the calcined sample is pretreated at 450 °C for two hours under a flow of H2 (20 mL/min), then used for CO2 hydrogenation at 275 °C with a CO2/H2/Ar mixture (22.2%/66.7%/11.1%) flowing at 45 mL/min.###\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.cache import InMemoryCache\n",
    "import langchain\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "np.random.seed(0)\n",
    "data_path = \"./dataset/data/71023_BO_ready_pool.csv\"\n",
    "path_random = \"./out/in-house - random - 42000.pkl\"\n",
    "# template:    db_model_dbFilter_initial_pool\n",
    "path = \"./out/in-house_davinci_42000_0_16nr_pref.pkl\"\n",
    "pool_path = \"./dataset/data/42000_in-house_pool.pkl\"\n",
    "initial_train = 1\n",
    "ask_K = 1\n",
    "raw_data = pd.read_csv(data_path)\n",
    "N = raw_data.shape[0]\n",
    "indexes = np.random.choice(raw_data.shape[0], int(N), replace=False)\n",
    "x_name = \"Prompt\"\n",
    "y_name = \"dummy_Completion\"\n",
    "\n",
    "asktell=get_asktell()\n",
    "\n",
    "raw_data['Catalyst'] = raw_data['Prompt'].str.extract(r'(\\b[A-Z][a-z]?:[A-Z][a-z]?:[A-Z][a-z]?\\b)')\n",
    "unique_cat = raw_data['Catalyst'].unique()\n",
    "c = {c: 0.2+m*(5/len(unique_cat)) for m, c in enumerate(unique_cat)}\n",
    "raw_data['dummy_Completion'] = raw_data['Catalyst'].apply(lambda x: np.random.normal(c[x], 0.05))\n",
    "\n",
    "print(N, len(indexes))\n",
    "for i in [1,123,6578,2134,-2]:#starts[2]:\n",
    "    # print(raw_data[x_name].iloc[i], float(raw_data[y_name].iloc[i]))\n",
    "    asktell.tell(raw_data[x_name].iloc[i], float(raw_data[y_name].iloc[i]))\n",
    "\n",
    "def wrap_chatllm(query_list, llm):\n",
    "    if type(llm) == ChatOpenAI:\n",
    "        system_message_prompt = SystemMessage(\n",
    "            content=\"You are a bot that can predict chemical and material properties. Do not explain answers, just provide numerical predictions.\"\n",
    "        )\n",
    "        if type(query_list) == str:\n",
    "            query_list = [system_message_prompt, HumanMessage(content=query_list)]\n",
    "        else:\n",
    "            query_list = [\n",
    "                [system_message_prompt, HumanMessage(content=q)] for q in query_list\n",
    "            ]\n",
    "    return query_list\n",
    "\n",
    "# asktell.inv_predict(y=15)\n",
    "query = asktell.inv_prompt.format(\n",
    "            y=asktell.format_y(15.0), y_name=asktell._y_name, x_name=asktell._x_name\n",
    "    )\n",
    "\n",
    "print(query)\n",
    "print()\n",
    "\n",
    "print(\n",
    "    asktell.inv_llm(\n",
    "        wrap_chatllm(query, asktell.inv_llm)\n",
    "        )\n",
    "    )\n",
    "\n",
    "# print(asktell.prompt.format(x=asktell.format_x(\"a given procedure\"), y_name=asktell._y_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asktell = bolift.AskTellFewShotMulti(\n",
    "#   x_formatter=lambda x: f\"experimental procedure: {x}\",\n",
    "#   y_name=\"C2 yield\",\n",
    "#   y_formatter=lambda y: f\"{y:.2f}\",\n",
    "#   model=\"text-curie-001\",\n",
    "#   selector_k=5,\n",
    "#   temperature=0.05\n",
    "# )\n",
    "\n",
    "# Choose a Name from the list. Use the last part of the name to determine which 'sup' to use. Use 'sup' as the support and remember it should always be \"(1.0 g)\".\n",
    "# Choose one from mol1 as M1. The corresponding value is always from 'm2_mol' at the first position. Choose one from mol2 as M2. The corresponding value is always from 'm2_mol' at the second position. Choose one from mol3 as M3. The corresponding value is always from 'm3_mol' at the first position. Select a temperature from Temp. Choose three different flow rates: one from 'ArVol_F' for Ar, one from 'CH4Vol_F' for CH4, and one from 'O2Vol_F' for O2. Ensure their sum equals a value from 'Vol_T' chosen. Based on the sum from step 7, choose a corresponding contact time from 'cont_time'.\n",
    "\n",
    "asktell = bolift.AskTellFewShotTopk(\n",
    "#   prefix=\"You are a bot who knows chemistry and catalysts. \" \\\n",
    "#         \"Below, you'll see examples of experimental procedures to synthesize catalysts and the measured C2 yield in a oxidative methane coupling reaction. \" \\\n",
    "#         \"The following question should be answered with a number and finished with ###\\n\",\n",
    "#   inv_prefix='''\n",
    "# Name =['Mn-Na2WO4/BN', 'Mn-Na2WO4/MgO', 'Mn-Na2WO4/Al2O3',   'Mn-Na2WO4/SiO2', 'Mn-Na2WO4/SiC', 'Mn-Na2WO4/SiCnf', 'Mn-Na2WO4/BEA', 'Mn-Na2WO4/ZSM-5', 'Mn-Na2WO4/TiO2', 'Mn-Na2WO4/ZrO2', 'Mn-Na2WO4/Nb2O5', 'Mn-Na2WO4/CeO2',   'Mn-Li2WO4/SiO2', 'Mn-MgWO4/SiO2', 'Mn-K2WO4/SiO2',   'Mn-CaWO4/SiO2', 'Mn-SrWO4/SiO2', 'Mn-BaWO4/SiO2',   'Mn-Li2MoO4/SiO2', 'Mn-Na2MoO4/SiO2', 'Mn-K2MoO4/SiO2',   'Mn-FeMoO4/SiO2', 'Mn-ZnMoO4/SiO2', 'Ti-Na2WO4/SiO2',   'V-Na2WO4/SiO2', 'Fe-Na2WO4/SiO2', 'Co-Na2WO4/SiO2',   'Ni-Na2WO4/SiO2', 'Cu-Na2WO4/SiO2', 'Zn-Na2WO4/SiO2',   'Y-Na2WO4/SiO2', 'Zr-Na2WO4/SiO2', 'Mo-Na2WO4/SiO2',   'Pd-Na2WO4/SiO2', 'La-Na2WO4/SiO2', 'Ce-Na2WO4/SiO2',   'Nd-Na2WO4/SiO2', 'Eu-Na2WO4/SiO2', 'Tb-Na2WO4/SiO2',   'Hf-Na2WO4/SiO2', 'Blank', 'BN', 'MgO', 'Al2O3', 'SiO2', 'SiC',   'SiCnf', 'BEA', 'ZSM-5', 'TiO2', 'ZrO2', 'Nb2O5', 'CeO2',   'Na2WO4/SiO2', 'Mn-WOx/SiO2', 'Mn-MoOx/SiO2', 'Mn-Na/SiO2',   'WOx/SiO2', 'Na/SiO2'] mol1 = ['Mn', 'Ti', 'V', 'Fe', 'Co', 'Ni', 'Cu', 'Zn', 'Y', 'Zr', 'Mo', 'Pd', 'La', 'Ce', 'Nd', 'Eu', 'Tb', 'Hf', 'n.a.'] mol2= ['Na', 'Li', 'Mg', 'K', 'Ca', 'Sr', 'Ba', 'Fe', 'Zn', 'n.a.'] mol3  =['W', 'Mo', 'n.a.'] sup =  ['BN', 'MgO', 'Al2O3', 'SiO2', 'SiC', 'SiCnf', 'BEA', 'ZSM-5','TiO2', 'ZrO2', 'Nb2O5', 'CeO2', 'n.a.'] m2_mol = [0.37 , 0.185, 0.  ] m3_mol = [0.185, 0.  ] Temp=[900, 850, 800, 775, 700, 750] Vol_T=  [10, 15, 20] ArVol_F = [ 1.5,  2.3,  3. ,  4. ,  6. ,  8. ,  7. , 10.5, 14. ] CH4Vol_F = [ 5.7,  8.5, 11.3,  6.4,  9.6, 12.8,  6.8, 10.2, 13.6,  7.3, 10.9,   14.6,  4. ,  6. ,  8. ,  4.5,  9. ,  4.8,  7.2,  5.1,  7.7, 10.3,   2. ,  3. ,  2.3,  3.4,  2.4,  3.6,  2.6,  3.9] O2Vol_F = [2.8, 4.3, 5.7, 2.1, 3.2, 1.7, 2.6, 3.4, 1.2, 1.8, 2.4, 2. , 3. , 4. , 1.5, 2.3, 0.9, 1.3, 1. , 0.8, 1.1, 0.6, 0.4] cont_time= [0.75, 0.5 , 0.38]\n",
    "# These are the only parameters that you can choose from when selecting how to fill in the corresponding values within the paragraph template below.\n",
    "  \n",
    "# To synthesize (Name) , (sup) (1.0 g) was impregnated with 4.5 mL of an aqueous solution consisting of (M1) ( mol1) , M2 ( mol2) , M3 (mol3) , at 50 ºC for 6 h. Once activated the reaction is ran at (Temp) ºC. The total flow rate was (Vol_T)mL/min (Ar: (ArVol_F)  mL/min, CH4:(Vol_F) mL/min, O2: (Vol_F) mL/min), leading to a contact time of (cont_time) s.\n",
    "\n",
    "# Can you give me eight new different, filled experimental procedures following these instructions and the examples below to answer the following question?\n",
    "# Finish each procedure with ###.\n",
    "# You can select parameters different from those you have seen before\n",
    "# ''',\n",
    "  prefix=\"\"\n",
    "  prompt_template=PromptTemplate(\n",
    "      input_variables=[\"x\", \"y\", \"y_name\"],\n",
    "      template=\"Q: What is the {y_name} of {x}?@@@\\nA: {y}###\",\n",
    "  ),\n",
    "  suffix=\"What is the {y_name} of {x}?@@@\\nA:\",\n",
    "  x_formatter=lambda x: f\"experimental procedure: {x}\",\n",
    "  y_name=\"C2 yield\",\n",
    "  y_formatter=lambda y: f\"{y:.2f}\",\n",
    "  # model=\"text-curie-001\",\n",
    "  model=\"text-davinci-003\",\n",
    "  # model=\"gpt-4\",\n",
    "  selector_k=5,\n",
    "  temperature=0.7,\n",
    ")\n",
    "\n",
    "# asktell = bolift.AskTellGPR(\n",
    "#   prefix=\"The following question should be answered with a number\\n\",\n",
    "#   prompt_template=PromptTemplate(\n",
    "#       input_variables=[\"x\", \"y\", \"y_name\"],\n",
    "#       template=\"Q: What is the {y_name} of {x}?@@@\\nA: {y}###\",\n",
    "#   ),\n",
    "#   suffix=\"What is the {y_name} of {x}?@@@\\nA:\",\n",
    "#   x_formatter=lambda x: f\"experimental procedure: {x}\",\n",
    "#   y_name=\"C2 yield\",\n",
    "#   y_formatter=lambda y: f\"{y:.2f}\",\n",
    "#   model='text-ada-001',\n",
    "#   pool=bolift.Pool([raw_data[x_name].iloc[i] for i in range(1000)], formatter=lambda x: f\"experimental procedure: {x}\"),\n",
    "#   n_components=32,\n",
    "#   # cache_path=\"GPR_ada_embed_cache.csv\"\n",
    "# )\n",
    "\n",
    "# asktell = bolift.AskTellRidgeKernelRegression(\n",
    "#     prefix=\"The following question should be answered with a number\\n\",\n",
    "#     prompt_template=PromptTemplate(\n",
    "#         input_variables=[\"x\", \"y\", \"y_name\"],\n",
    "#         template=\"Q: What is the {y_name} of {x}?@@@\\nA: {y}###\",\n",
    "#     ),\n",
    "#     suffix=\"What is the {y_name} of {x}?@@@\\nA:\",\n",
    "#     x_formatter=lambda x: f\"iupac name {x}\",\n",
    "#     y_name=\"measured log solubility in mols per litre\",\n",
    "#     y_formatter=lambda y: f\"{y:.2f}\",\n",
    "#     model=\"text-ada-001\",\n",
    "#     alpha=0.5\n",
    "#   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_asktell():\n",
    "#     return bolift.AskTellFewShotTopk(\n",
    "#     prefix=\"\",\n",
    "#     prompt_template=PromptTemplate(\n",
    "#         input_variables=[\"x\", \"y\", \"y_name\"],\n",
    "#         template=\"Q: What is the {y_name} of {x}?@@@\\nA: {y}###\",\n",
    "#     ),\n",
    "#     suffix=\"What is the {y_name} of {x}?@@@\\nA:\",\n",
    "#     x_formatter=lambda x: f\"experimental procedure: {x}\",\n",
    "#     y_name=\"C2 yield\",\n",
    "#     y_formatter=lambda y: f\"{y:.2f}\",\n",
    "#     # model=\"text-curie-001\",\n",
    "#     model=\"gpt-3.5-turbo-instruct\",\n",
    "#     # model=\"gpt-4\",\n",
    "#     selector_k=5,\n",
    "#     temperature=0.7,\n",
    "#     )\n",
    "\n",
    "def get_asktell():\n",
    "    return bolift.AskTellGPR(\n",
    "    prefix=\"The following question should be answered with a number\\n\",\n",
    "    prompt_template=PromptTemplate(\n",
    "        input_variables=[\"x\", \"y\", \"y_name\"],\n",
    "        template=\"Q: What is the {y_name} of {x}?@@@\\nA: {y}###\",\n",
    "    ),\n",
    "    suffix=\"What is the {y_name} of {x}?@@@\\nA:\",\n",
    "    x_formatter=lambda x: f\"experimental procedure: {x}\",\n",
    "    y_name=\"C2 yield\",\n",
    "    y_formatter=lambda y: f\"{y:.2f}\",\n",
    "    model='text-ada-001',\n",
    "    pool=bolift.Pool([raw_data[x_name].iloc[i] for i in range(1000)], formatter=lambda x: f\"experimental procedure: {x}\"),\n",
    "    n_components=32,\n",
    "    #   cache_path=\"GPR_ada_embed_cache.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(88)\n",
    "\n",
    "data_path = \"./dataset/data/12744_ocm_dataset.csv\"\n",
    "\n",
    "path_random = \"./out/C2 - random - 12744.pkl\"\n",
    "# template:    db_model_dbFilter_initial_pool\n",
    "path = \"./out/C2_GPR_12744_0_16nr.pkl\"\n",
    "pool_path = \"./dataset/data/12744_ocm_pool_faiss.pkl\"\n",
    "\n",
    "initial_train = 0\n",
    "ask_K = 1\n",
    "\n",
    "raw_data = pd.read_csv(data_path, sep=\";\")\n",
    "\n",
    "# raw_data['completion'] = - raw_data['completion']\n",
    "\n",
    "N = raw_data.shape[0]\n",
    "indexes = np.random.choice(raw_data.shape[0], int(N), replace=False)\n",
    "x_name = \"prompt\"\n",
    "y_name = \"completion\"\n",
    "print(N, len(indexes))\n",
    "\n",
    "if os.path.exists(pool_path):\n",
    "  with open(pool_path, \"rb\") as f:\n",
    "    pool = cloudpickle.load(f)\n",
    "  pool.reset()\n",
    "else:\n",
    "  x = [raw_data[x_name].iloc[i] for i in indexes]\n",
    "  pool = bolift.Pool(list(x), formatter=lambda x: f\"experimental procedure: {x}\")\n",
    "  cloudpickle.dump(pool, open(pool_path, \"wb\"))\n",
    "\n",
    "N = 20\n",
    "M = 5\n",
    "starts = raw_data.sort_values(by=y_name, ascending=True).head(100).sample(M)# np.random.randint(0, len(indexes), M)\n",
    "print(starts)\n",
    "starts = starts.index\n",
    "print(starts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(path):\n",
    "    bayesOpts_random = cloudpickle.load(open(path_random, \"rb\")) #random_mean\n",
    "    bayesOpts = cloudpickle.load(open(path, \"rb\"))\n",
    "else:\n",
    "    bayesOpts = {}\n",
    "\n",
    "for aq in ['random', 'expected_improvement']: #[\"random\", \"expected_improvement\", \"greedy\", 'upper_confidence_bound', 'probability_of_improvement']:\n",
    "    print(aq, \"start:\", end=\" \")\n",
    "    points = []\n",
    "    for i in range(M):\n",
    "        asktell = get_asktell()\n",
    "        print(i, end=\",  \")\n",
    "        point = run_experiment(\n",
    "            copy.deepcopy(asktell),\n",
    "            copy.deepcopy(pool),\n",
    "            raw_data,\n",
    "            indexes,\n",
    "            x_name,\n",
    "            y_name,\n",
    "            N=N,\n",
    "            aq=aq,\n",
    "            start_index=starts[i],\n",
    "            calibrate=True,\n",
    "            initial_train=initial_train,\n",
    "            ask_K=ask_K\n",
    "        )\n",
    "        points.append(point)\n",
    "    points = np.array(points)\n",
    "    bayesOpts[aq] = points\n",
    "    print(aq, \"done\")\n",
    "    # asktell.save_cache(\"GPR_ada_embed_cache.csv\")\n",
    "    cloudpickle.dump(bayesOpts, open(path, \"wb\"))\n",
    "cloudpickle.dump(bayesOpts, open(path, \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debugging plots\n",
    "import re\n",
    "path = \"./out/C2_GPR_12744_0_16nr.pkl\"\n",
    "title = \"OCM / no_random\"\n",
    "d = cloudpickle.load(open(path, \"rb\"))\n",
    "aq = \"random\"\n",
    "\n",
    "data = raw_data[y_name]\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(6,4), constrained_layout=True)\n",
    "# for ax in axs.flat:\n",
    "#     ax.set_aspect(0.6)\n",
    "lim=(0, 25)\n",
    "plot_BO(axs, path, title, \n",
    "         raw_data[y_name], \"C$_2$ yield\", lim, label=True, data_file_random=path_random)\n",
    "fig.legend(loc='upper center', bbox_to_anchor=(0.5,0),\n",
    "          fancybox=True, shadow=True, ncol=6)\n",
    "plt.savefig(f\"figs/BO_C2\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.xlabel(\"Number of samples\")\n",
    "plt.ylabel(\"Max C2 yield\")\n",
    "plt.title(title)\n",
    "for i in range(5):\n",
    "    plt.plot(d[aq][i,:,1], d[aq][i, :, 2].astype(float), label=f\"run {i}\")\n",
    "plt.axhline(y=data.max(), color=\"C15\", linestyle=\"--\")\n",
    "plt.text(plt.xlim()[1]+1, data.max(), \"max\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "plt.axhline(y=data.quantile(0.99), color=\"C14\", linestyle=\"--\")\n",
    "plt.text(plt.xlim()[1]+1, data.quantile(0.99), \"99%\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "plt.axhline(y=data.quantile(0.95), color=\"C13\", linestyle=\"--\")\n",
    "plt.text(plt.xlim()[1]+1, data.quantile(0.95), \"95%\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "plt.axhline(y=data.mean(), color=\"C12\", linestyle=\"--\")\n",
    "plt.text(plt.xlim()[1]+1, data.mean(), \"mean\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5,-0.1),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.xlabel(\"Number of samples\")\n",
    "plt.ylabel(\"C2 yield\")\n",
    "plt.title(title)\n",
    "# for i in range(5):\n",
    "#     plt.plot(d[aq][i,:,1], d[aq][i, :, 3].astype(float), label=f\"run {i}\")\n",
    "plt.plot(d[\"expected_improvement\"][i,:,1], d[\"expected_improvement\"][:, :, 3].astype(float).mean(axis=0), label=f\"EI\", color=\"C1\")\n",
    "plt.plot(d[\"random\"][i,:,1], d[\"random\"][:, :, 3].astype(float).mean(axis=0), label=f\"random\", color=\"C5\")\n",
    "plt.axhline(y=data.max(), color=\"C15\", linestyle=\"--\")\n",
    "plt.text(plt.xlim()[1]+1, data.max(), \"max\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "plt.axhline(y=data.quantile(0.99), color=\"C14\", linestyle=\"--\")\n",
    "plt.text(plt.xlim()[1]+1, data.quantile(0.99), \"99%\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "plt.axhline(y=data.quantile(0.95), color=\"C13\", linestyle=\"--\")\n",
    "plt.text(plt.xlim()[1]+1, data.quantile(0.95), \"95%\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "plt.axhline(y=data.mean(), color=\"C12\", linestyle=\"--\")\n",
    "plt.text(plt.xlim()[1]+1, data.mean(), \"mean\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5,-0.1),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "d_davinci = cloudpickle.load(open(path, \"rb\"))\n",
    "print(d_davinci['expected_improvement'][:, -1, -1].astype(float))\n",
    "best_davinci = d_davinci['expected_improvement'][:, :, -1].astype(float).mean(axis=0)[-1]\n",
    "print(f\"DaVinci is top{np.sum(raw_data[y_name] > best_davinci)}: {best_davinci}\")\n",
    "\n",
    "sns.histplot(raw_data[y_name])\n",
    "# print(np.sum(raw_data[y_name] > best))\n",
    "plt.xlabel(\"measured C$_2$ yield\")\n",
    "plt.axvline(best_davinci, color='C1', linestyle='--', label=\"Davinci\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"figs/hist_C2\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(raw_data[raw_data[y_name] > best_davinci])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = cloudpickle.load(open(path, \"rb\"))\n",
    "for k in range(5):\n",
    "    print([k[14:k.find(\",\")] for k in d['expected_improvement'][k, :, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.cache import InMemoryCache\n",
    "import langchain\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "np.random.seed(0) # 88\n",
    "data_path = \"./dataset/data/C2_yield_meth_oxy_short.csv\"\n",
    "path_random = \"./out/C2 - random - 12744.pkl\"\n",
    "path = \"./out/C2_davinci_12744_1_16hh.pkl\"\n",
    "pool_path = \"./dataset/data/12744_ocm_pool.pkl\"\n",
    "initial_train = 1\n",
    "ask_K = 1\n",
    "# raw_data = pd.read_csv(data_path, sep=\";\")\n",
    "raw_data = pd.read_csv(data_path)\n",
    "N = raw_data.shape[0]\n",
    "indexes = np.random.choice(raw_data.shape[0], int(N), replace=False)\n",
    "x_name = \"prompt\"\n",
    "y_name = \"completion\"\n",
    "print(N, len(indexes))\n",
    "for i in starts[1:2]:\n",
    "    print(raw_data[x_name].iloc[i], float(raw_data[y_name].iloc[i]))\n",
    "    asktell.tell(raw_data[x_name].iloc[i], float(raw_data[y_name].iloc[i]))\n",
    "\n",
    "def wrap_chatllm(query_list, llm):\n",
    "    if type(llm) == ChatOpenAI:\n",
    "        system_message_prompt = SystemMessage(\n",
    "            content=\"You are a bot that can predict chemical and material properties. Do not explain answers, just provide numerical predictions.\"\n",
    "        )\n",
    "        if type(query_list) == str:\n",
    "            query_list = [system_message_prompt, HumanMessage(content=query_list)]\n",
    "        else:\n",
    "            query_list = [\n",
    "                [system_message_prompt, HumanMessage(content=q)] for q in query_list\n",
    "            ]\n",
    "    return query_list\n",
    "\n",
    "# asktell.inv_predict(y=15)\n",
    "query = asktell.inv_prompt.format(\n",
    "            y=asktell.format_y(15.0), y_name=asktell._y_name, x_name=asktell._x_name\n",
    "    )\n",
    "\n",
    "print(query)\n",
    "print()\n",
    "\n",
    "print(\n",
    "    asktell.inv_llm(\n",
    "        wrap_chatllm(query, asktell.inv_llm)\n",
    "        )\n",
    "    )\n",
    "\n",
    "# print(asktell.prompt.format(x=asktell.format_x(\"a given procedure\"), y_name=asktell._y_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IUPAC-Solubility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "data_path = \"./dataset/data/esol_iupac.csv\"\n",
    "raw_data = pd.read_csv(data_path)\n",
    "raw_data = raw_data.dropna()\n",
    "raw_data = raw_data[[\"IUPAC\", \"measured log(solubility:mol/L)\"]]\n",
    "raw_data = raw_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# raw_data['measured log(solubility:mol/L)'] = -raw_data['measured log(solubility:mol/L)']\n",
    "\n",
    "print(raw_data.columns)\n",
    "\n",
    "N = raw_data.shape[0]\n",
    "indexes = [i for i in range(N)]  # np.random.choice(raw_data.shape[0], int(N), replace=False)\n",
    "x_name = \"IUPAC\"\n",
    "y_name = \"measured log(solubility:mol/L)\"\n",
    "print(len(raw_data), len(indexes))\n",
    "\n",
    "asktell = bolift.AskTellFewShotTopk(\n",
    "  prefix=\"\",\n",
    "  prompt_template=PromptTemplate(\n",
    "      input_variables=[\"x\", \"y\", \"y_name\"],\n",
    "      template=\"Q: What is the {y_name} of {x}?@@@\\nA: {y}###\",\n",
    "  ),\n",
    "  suffix=\"What is the {y_name} of {x}?@@@\\nA:\",\n",
    "  x_formatter=lambda x: f\"iupac name {x}\",\n",
    "  y_name=\"measured log solubility in mols per litre\",\n",
    "  y_formatter=lambda y: f\"{y:.2f}\",\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  selector_k=5,\n",
    "  temperature=0.7,\n",
    ")\n",
    "\n",
    "# asktell = bolift.AskTellFewShotMulti(\n",
    "#     x_formatter=lambda x: f\"iupac name {x}\",\n",
    "#     y_name=\"measured log solubility in mols per litre\",\n",
    "#     y_formatter=lambda y: f\"{y:.2f}\",\n",
    "#     model=\"text-curie-001\",\n",
    "#     selector_k=5,\n",
    "#     temperature=0.05\n",
    "# )\n",
    "\n",
    "# asktell = bolift.AskTellGPR(\n",
    "#   prefix=\"The following question should be answered with a number\\n\",\n",
    "#   prompt_template=PromptTemplate(\n",
    "#       input_variables=[\"x\", \"y\", \"y_name\"],\n",
    "#       template=\"Q: What is the {y_name} of {x}?@@@\\nA: {y}###\",\n",
    "#   ),\n",
    "#   suffix=\"What is the {y_name} of {x}?@@@\\nA:\",\n",
    "#   x_formatter=lambda x: f\"iupac name {x}\",\n",
    "#   y_name=\"measured log solubility in mols per litre\",\n",
    "#   y_formatter=lambda y: f\"{y:.2f}\",\n",
    "#   model='text-ada-001',\n",
    "#   pool=bolift.Pool(raw_data[x_name].to_list(), formatter=lambda x: f\"iupac name {x}\"),\n",
    "#   n_components=16,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "x = [raw_data[x_name].iloc[i] for i in indexes]\n",
    "path_random = \"./out/sol - random.pkl\"\n",
    "path = \"./out/sol_davinci_0.pkl\"\n",
    "pool_path = \"./out/sol_pool.pkl\"\n",
    "\n",
    "if os.path.exists(pool_path):\n",
    "  with open(pool_path, \"rb\") as f:\n",
    "    pool = cloudpickle.load(f)\n",
    "  pool.reset()\n",
    "else:\n",
    "  x = [raw_data[x_name].iloc[i] for i in indexes]\n",
    "  pool = bolift.Pool(list(x), formatter=lambda x: f\"experimental procedure: {x}\")\n",
    "  cloudpickle.dump(pool, open(pool_path, \"wb\"))\n",
    "\n",
    "N = 15\n",
    "M = 5\n",
    "starts = np.random.randint(0, len(indexes), M)\n",
    "# starts = [110, 374, 790, 365, 523, 119, 560, 199, 239, 694, 608, 850, 599, 405, 510, 514, 264, 266, 261, 294, 612]\n",
    "# print([raw_data[y_name].iloc[i] for i in starts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(path):\n",
    "    bayesOpts_random = cloudpickle.load(open(path_random, \"rb\"))\n",
    "    bayesOpts = cloudpickle.load(open(path, \"rb\"))\n",
    "else:\n",
    "    bayesOpts = {}\n",
    "\n",
    "for aq in [\"random\", \"expected_improvement\"]: #[\"random\", \"expected_improvement\", \"greedy\", 'upper_confidence_bound', 'probability_of_improvement']:\n",
    "    print(aq, \"start:\", end=\" \")\n",
    "    points = []\n",
    "    for i in range(M):\n",
    "        print(i, end=\",  \")\n",
    "        point = run_experiment(\n",
    "            copy.deepcopy(asktell),\n",
    "            copy.deepcopy(pool),\n",
    "            raw_data,\n",
    "            indexes,\n",
    "            x_name,\n",
    "            y_name,\n",
    "            N=N,\n",
    "            aq=aq,\n",
    "            start_index=starts[i],\n",
    "            calibrate=True,\n",
    "            initial_train=0\n",
    "        )\n",
    "        points.append(point)\n",
    "    # plot mean\n",
    "    points = np.array(points)\n",
    "    bayesOpts[aq] = points\n",
    "    print(aq, \"done\")\n",
    "    # asktell.save_cache(\"GPR_ada_embed_cache.csv\")\n",
    "    cloudpickle.dump(bayesOpts, open(path, \"wb\"))\n",
    "cloudpickle.dump(bayesOpts, open(path, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = cloudpickle.load(open(path, \"rb\"))\n",
    "d_r = cloudpickle.load(open(path_random, \"rb\"))\n",
    "N=15\n",
    "M=5\n",
    "aq = \"random\"\n",
    "title = \"LogS GPR\"\n",
    "\n",
    "\n",
    "data = raw_data[y_name]\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(6,4), constrained_layout=True)\n",
    "# for ax in axs.flat:\n",
    "#     ax.set_aspect(0.6)\n",
    "lim=(-5, 2)\n",
    "plot_BO(axs, path, title, \n",
    "         raw_data[y_name], \"C$_2$ yield\", lim, label=True, data_file_random=path_random)\n",
    "fig.legend(loc='upper center', bbox_to_anchor=(0.5,0),\n",
    "          fancybox=True, shadow=True, ncol=6)\n",
    "plt.savefig(f\"figs/BO_C2\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.xlabel(\"Number of samples\")\n",
    "plt.ylabel(\"Max LogS\")\n",
    "plt.title(title)\n",
    "for i in range(5):\n",
    "    plt.plot(d[aq][i,:,1], d[aq][i, :, 2].astype(float), label=f\"run {i}\")\n",
    "plt.axhline(y=data.max(), color=\"C15\", linestyle=\"--\")\n",
    "plt.text(plt.xlim()[1]+1, data.max(), \"max\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "plt.axhline(y=data.quantile(0.99), color=\"C14\", linestyle=\"--\")\n",
    "plt.text(plt.xlim()[1]+1, data.quantile(0.99), \"99%\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "plt.axhline(y=data.quantile(0.95), color=\"C13\", linestyle=\"--\")\n",
    "plt.text(plt.xlim()[1]+1, data.quantile(0.95), \"95%\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "plt.axhline(y=data.mean(), color=\"C12\", linestyle=\"--\")\n",
    "plt.text(plt.xlim()[1]+1, data.mean(), \"mean\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5,-0.1),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.xlabel(\"Number of samples\")\n",
    "plt.ylabel(\"LogS\")\n",
    "plt.title(title)\n",
    "# for i in range(5):\n",
    "#     plt.plot(d[aq][i,:,1], d[aq][i, :, 3].astype(float), label=f\"run {i}\")\n",
    "plt.plot(d[\"expected_improvement\"][i,:,1], d[\"expected_improvement\"][:, :, 3].astype(float).mean(axis=0), label=f\"EI\", color=\"C1\")\n",
    "plt.plot(d[\"random\"][i,:,1], d[\"random\"][:, :, 3].astype(float).mean(axis=0), label=f\"random\", color=\"C5\")\n",
    "plt.axhline(y=data.max(), color=\"C15\", linestyle=\"--\")\n",
    "plt.text(plt.xlim()[1]+1, data.max(), \"max\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "plt.axhline(y=data.quantile(0.99), color=\"C14\", linestyle=\"--\")\n",
    "plt.text(plt.xlim()[1]+1, data.quantile(0.99), \"99%\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "plt.axhline(y=data.quantile(0.95), color=\"C13\", linestyle=\"--\")\n",
    "plt.text(plt.xlim()[1]+1, data.quantile(0.95), \"95%\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "plt.axhline(y=data.mean(), color=\"C12\", linestyle=\"--\")\n",
    "plt.text(plt.xlim()[1]+1, data.mean(), \"mean\", va=\"center\", ha=\"left\", backgroundcolor=\"w\", fontsize=8)\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5,-0.1),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "d['expected_improvement'][1][-1][1]\n",
    "best = d['expected_improvement'][:, :, 1].astype(float).mean(axis=0)[-1]\n",
    "print(best)\n",
    "\n",
    "sns.histplot(raw_data[y_name])\n",
    "print(np.sum(raw_data[y_name] > best))\n",
    "plt.axvline(best, color='red', linestyle='--')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alloy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "data_path = \"paper/data/yield_strength.csv\"\n",
    "raw_data = pd.read_csv(data_path)\n",
    "# raw_data = raw_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(raw_data.columns)\n",
    "\n",
    "N = raw_data.shape[0]\n",
    "indexes = np.random.choice(raw_data.shape[0], int(N), replace=False)\n",
    "# shuffle test\n",
    "\n",
    "print(N, len(indexes))\n",
    "\n",
    "asktell = bolift.AskTellFewShotTopk(\n",
    "    prefix=\"\",\n",
    "    prompt_template=PromptTemplate(\n",
    "        input_variables=[\"x\", \"y\", \"y_name\"],\n",
    "        template=\"Q: What is the {y_name} of {x}?@@@\\nA: {y}###\",\n",
    "    ),\n",
    "    suffix=\"What is the {y_name} of {x}?@@@\\nA:\",\n",
    "    # x_formatter=lambda x: f\"alloy composition: {x}\",\n",
    "    y_name=\"yield strength\",\n",
    "    y_formatter=lambda y: f\"{y:.2f}\",\n",
    "    model=\"gpt-4\",\n",
    "    selector_k=5,\n",
    ")\n",
    "\n",
    "\n",
    "x_name = \"composition\"\n",
    "y_name = \"yield strength\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "M = 5\n",
    "starts = np.random.randint(0, len(indexes), M)\n",
    "plt.figure(figsize=(3.5, 3.5 / 1.2))\n",
    "random_points = []\n",
    "for i in range(M):\n",
    "    point = run_experiment(\n",
    "        asktell,\n",
    "        raw_data,\n",
    "        indexes,\n",
    "        x_name,\n",
    "        y_name,\n",
    "        N=N,\n",
    "        aq=\"random\",\n",
    "        start_index=starts[i],\n",
    "    )\n",
    "    random_points.append(point)\n",
    "    plt.plot(range(N + 1), [y for x, y in point], color=\"C0\", alpha=0.1)\n",
    "# plot mean\n",
    "random_points = np.array(random_points)\n",
    "plt.plot(\n",
    "    range(N + 1),\n",
    "    random_points[:, :, 1].astype(float).mean(axis=0),\n",
    "    color=\"C0\",\n",
    "    label=\"Random\",\n",
    ")\n",
    "\n",
    "greedy_points = []\n",
    "for i in range(M):\n",
    "    point = run_experiment(\n",
    "        asktell,\n",
    "        raw_data,\n",
    "        indexes,\n",
    "        x_name,\n",
    "        y_name,\n",
    "        N=N,\n",
    "        aq=\"greedy\",\n",
    "        start_index=starts[i],\n",
    "    )\n",
    "    greedy_points.append(point)\n",
    "    plt.plot(range(N + 1), [y for x, y in point], color=\"C2\", alpha=0.1)\n",
    "# plot mean\n",
    "greedy_points = np.array(greedy_points)\n",
    "plt.plot(\n",
    "    range(N + 1),\n",
    "    greedy_points[:, :, 1].astype(float).mean(axis=0),\n",
    "    color=\"C2\",\n",
    "    label=\"Greedy\",\n",
    ")\n",
    "\n",
    "ei_points = []\n",
    "for i in range(M):\n",
    "    point = run_experiment(\n",
    "        asktell,\n",
    "        raw_data,\n",
    "        indexes,\n",
    "        x_name,\n",
    "        y_name,\n",
    "        N=N,\n",
    "        aq=\"expected_improvement\",\n",
    "        start_index=starts[i],\n",
    "    )\n",
    "    ei_points.append(point)\n",
    "    plt.plot(range(N + 1), [y for x, y in point], color=\"C1\", alpha=0.1)\n",
    "# plot mean\n",
    "ei_points = np.array(ei_points)\n",
    "plt.plot(\n",
    "    range(N + 1), ei_points[:, :, 1].astype(float).mean(axis=0), color=\"C1\", label=\"EI\"\n",
    ")\n",
    "\n",
    "plt.axhline(y=raw_data[\"yield strength\"].min(), color=\"C0\", linestyle=\"--\", label=\"min\")\n",
    "plt.axhline(\n",
    "    y=raw_data[\"yield strength\"].mean(), color=\"C1\", linestyle=\"--\", label=\"mean\"\n",
    ")\n",
    "plt.axhline(y=raw_data[\"yield strength\"].max(), color=\"C2\", linestyle=\"--\", label=\"max\")\n",
    "# give 5% quantiles\n",
    "plt.axhline(\n",
    "    y=raw_data[\"yield strength\"].quantile(0.05), color=\"C3\", linestyle=\"--\", label=\"5%\"\n",
    ")\n",
    "plt.axhline(\n",
    "    y=raw_data[\"yield strength\"].quantile(0.95), color=\"C4\", linestyle=\"--\", label=\"95%\"\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Samples\")\n",
    "# reduce number of ticks\n",
    "# plt.xticks([0, 5, 10])\n",
    "# plt.ylim(-10, 0)\n",
    "# plt.yticks(np.linspace(-10, 0, 3))\n",
    "plt.legend(loc=\"center left\", bbox_to_anchor=(1.05, 0.5))\n",
    "plt.savefig(\"concept_multi.png\", dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
