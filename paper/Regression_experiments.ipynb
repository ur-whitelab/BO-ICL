{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Github README Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "data_path = \"./dataset/data/esol_iupac.csv\"\n",
    "raw_data = pd.read_csv(data_path)\n",
    "\n",
    "def query2IUPAC(text):\n",
    "  try:\n",
    "    '''This function queries the one given molecule name and returns a SMILES string from the record'''\n",
    "    #query the PubChem database\n",
    "    r = requests.get('https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/smiles/' + text + '/property/IUPACName/JSON')\n",
    "    data = r.json()\n",
    "    smi = data[\"PropertyTable\"][\"Properties\"][0][\"IUPACName\"]\n",
    "    return smi\n",
    "  except:\n",
    "    return None\n",
    "\n",
    "# raw_data[\"IUPAC\"] = raw_data[\"SMILES\"].map(lambda sml: query2IUPAC(sml))\n",
    "raw_data = raw_data[[\"IUPAC\", \"measured log(solubility:mol/L)\"]]\n",
    "raw_data = raw_data.dropna()\n",
    "raw_data[50:65]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### README example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bolift\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "asktell = bolift.AskTellFewShotTopk()\n",
    "\n",
    "asktell.tell(\"3-chloroaniline\", -1.37)\n",
    "asktell.tell(\"nitromethane\", 0.26)\n",
    "asktell.tell(\"1-bromobutane\", -2.43)\n",
    "asktell.tell(\"3-chlorophenol\", -0.7)\n",
    "\n",
    "yhat = asktell.predict(\"penta-1,4-diene\t\")\n",
    "print(yhat.mean(), yhat.std())\n",
    "\n",
    "pool_list = [\n",
    "  \"1,5-dimethylnaphthalene\",\n",
    "  \"2-aminophenol\",\n",
    "  \"1hexa-1,5-diene\",\n",
    "  \"1,1,2,3,4,4-hexachlorobuta-1,3-diene\"\n",
    "]\n",
    "pool=bolift.Pool(pool_list)\n",
    "print(asktell.ask(pool))\n",
    "\n",
    "asktell.tell(\"phenol\", -0.5)\n",
    "yhat = asktell.predict(\"penta-1,4-diene\")\n",
    "print(yhat.mean(), yhat.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.join(current_dir,'../bolift')\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "import bolift\n",
    "from bolift.llm_model import GaussDist, DiscreteDist\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "import itertools\n",
    "import openai\n",
    "import glob\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")\n",
    "# @retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def run_ablation_experiment(asktell, train_data, test_data, system_message=\"\"):\n",
    "    if isinstance(asktell, bolift.AskTellGPR) or isinstance(asktell, bolift.AskTellFinetuning):\n",
    "        i=-1 #Hack to pass the case we have len(train_data) == 1\n",
    "        for i in range(len(train_data)-1):\n",
    "            asktell.tell(train_data.iloc[i, 0], float(train_data.iloc[i, 1]), train=False)\n",
    "        asktell.tell(train_data.iloc[i+1, 0], float(train_data.iloc[i+1, 1]), train=True)\n",
    "    else:\n",
    "        for i in range(len(train_data)):\n",
    "            asktell.tell(train_data.iloc[i, 0], float(train_data.iloc[i, 1]))\n",
    "    x    = []\n",
    "    y    = []\n",
    "    yhat = []\n",
    "    for j in range(len(test_data)):\n",
    "        x.append(test_data.iloc[j, 0])\n",
    "        y.append(float(test_data.iloc[j, 1]))\n",
    "        if isinstance(asktell, bolift.AskTellNearestNeighbor):\n",
    "            yhat.append(asktell.predict(test_data.iloc[j, 0]))\n",
    "        else:\n",
    "            yhat.append(asktell.predict(test_data.iloc[j, 0], system_message=system_message))\n",
    "\n",
    "    x_filter = [xi for xi, yhi in zip(x, yhat)]# if len(yhi.values) > 0]\n",
    "    y_filter = [yi for yi, yhi in zip(y, yhat)]# if len(yhi.values) > 0]\n",
    "    yhat_filter = [yhi for yi, yhi in zip(y, yhat)]# if len(yhi.values) > 0]\n",
    "    return x_filter, y_filter, yhat_filter\n",
    "\n",
    "def save_csv(filename, x, y, yhat, data, model, T, k, N, model_class, tokens):\n",
    "    if not os.path.exists(filename):\n",
    "        f = open(filename, \"w\")\n",
    "        f.write(\"y;yhat;yprobs;data;model;Temperature;k_selected;N_train;model_class;n_tokens;x\\n\")\n",
    "    else:\n",
    "        f = open(filename, \"a\")\n",
    "\n",
    "    for xi, yi, yhi in zip(x, y, yhat):\n",
    "        # print(yi, yhi, data, model, T, k, N, model_class, tokens, xi)\n",
    "        if isinstance(yhi, DiscreteDist):\n",
    "            if len(yhi.values) > 0:\n",
    "                for v,p in zip(yhi.values, yhi.probs):\n",
    "                    f.write(f\"{yi};{v};{p:.4f};{data};{model};{T};{k};{N};{model_class};{tokens};{xi}\\n\")\n",
    "        if isinstance(yhi, GaussDist):\n",
    "            # f.write(f\"{yi};{yhi.mean()};{yhi.std():.4f};{data};{model};{T};{k};{N};{model_class};{tokens};{xi}\\n\")\n",
    "            f.write(f\"{yi};{yhi.mean()};{0};{data};{model};{T};{k};{N};{model_class};{tokens};{xi}\\n\")\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(data: str, N: int, split=0.8):\n",
    "    match data:\n",
    "        case \"in-house\":\n",
    "            data_path = \"./dataset/data/71023_BO_ready_pool.csv\"\n",
    "            raw_data = pd.read_csv(data_path)\n",
    "            raw_data['Catalyst'] = raw_data['Prompt'].str.extract(r'(\\b[A-Z][a-z]?:[A-Z][a-z]?:[A-Z][a-z]?\\b)')\n",
    "            unique_cat = raw_data['Catalyst'].unique()\n",
    "            c = {c: 0.2+m*(5/len(unique_cat)) for m, c in enumerate(unique_cat)}\n",
    "            raw_data['dummy_Completion'] = raw_data['Catalyst'].apply(lambda x: np.random.normal(c[x], 0.05))\n",
    "\n",
    "            x_name = \"Prompt\"\n",
    "            y_name = \"dummy_Completion\"\n",
    "        case \"ocm\":\n",
    "            data_path = \"./dataset/data/12708_ocm_dataset.csv\"\n",
    "            raw_data = pd.read_csv(data_path, sep=\";\")\n",
    "            raw_data = raw_data.sample(frac=1).reset_index(drop=True)\n",
    "            x_name = \"prompt\"\n",
    "            y_name = \"completion\"\n",
    "        case \"biasfree_ocm\":\n",
    "            data_path = \"./dataset/data/bias_free_ocmdataset_p_comp.csv\"\n",
    "            raw_data = pd.read_csv(data_path, sep=\",\")\n",
    "            raw_data = raw_data.sample(frac=1).reset_index(drop=True)\n",
    "            x_name = \"prompt\"\n",
    "            y_name = \"completion\"\n",
    "        case \"sol\":\n",
    "            data_path = \"./dataset/data/esol_iupac.csv\"\n",
    "            raw_data = pd.read_csv(data_path)\n",
    "            raw_data = raw_data.dropna()\n",
    "            raw_data = raw_data[[\"IUPAC\", \"measured log(solubility:mol/L)\"]]\n",
    "            raw_data = raw_data.sample(frac=1).reset_index(drop=True)\n",
    "            x_name = \"IUPAC\"\n",
    "            y_name = \"measured log(solubility:mol/L)\"\n",
    "        case \"alloy\":\n",
    "            data_path = \"./dataset/data/charge_transfer_dataset.csv\"\n",
    "            raw_data = pd.read_csv(data_path, sep=\",\")\n",
    "            raw_data = raw_data[['prompt', 'completion']]\n",
    "            raw_data = raw_data.sample(frac=1).reset_index(drop=True)\n",
    "            x_name = \"prompt\"\n",
    "            y_name = \"completion\"\n",
    "        case _:\n",
    "            raise ValueError(\"Unknown data\")\n",
    "        \n",
    "    n_data = raw_data.shape[0]\n",
    "    indexes = np.random.choice(n_data, int(n_data), replace=False)\n",
    "    train = np.random.choice(n_data, int(n_data * split), replace=False)\n",
    "    test = np.setdiff1d(np.arange(n_data), train)\n",
    "    test = np.random.choice(test, min(200, len(test)), replace=False) # limiting too large test set to avoid expense with OpenAI requests\n",
    "\n",
    "    if N > len(train):\n",
    "        raise ValueError(f\"N must be less than the training set size. Trainin set size: {len(train)}\")\n",
    "    train_data = raw_data.iloc[train, :].reset_index(drop=True)[:N]\n",
    "    test_data = raw_data.iloc[test, :].reset_index(drop=True)\n",
    "    print(f\"Dataset size:  \\t{n_data}\")\n",
    "    print(f\"Training size: \\t{len(train_data)}\")\n",
    "    print(f\"Test size:     \\t{len(test_data)}\")\n",
    "\n",
    "    return raw_data, train_data, test_data, indexes, x_name, y_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_asktell(model: str, kwargs: dict = {}, pool: bolift.Pool = None, knn: int = 1):\n",
    "    match model:\n",
    "        case \"mistral-7b-instruct:free\":\n",
    "            kwargs['model']=\"openrouter/mistralai/mistral-7b-instruct:free\"\n",
    "            return bolift.AskTellFewShotTopk(**kwargs)\n",
    "        case \"gemini-2.5-flash-preview\":\n",
    "            kwargs['model']=\"openrouter/google/gemini-2.5-flash-preview\"\n",
    "            return bolift.AskTellFewShotTopk(**kwargs)\n",
    "        case \"gpt-3.5-turbo-instruct\":\n",
    "            kwargs['model']=\"gpt-3.5-turbo-instruct\"\n",
    "            return bolift.AskTellFewShotTopk(**kwargs)\n",
    "        case \"gpt-3.5-turbo-0125\":\n",
    "            kwargs['model']=\"gpt-3.5-turbo-0125\"\n",
    "            return bolift.AskTellFewShotTopk(**kwargs)\n",
    "        case \"gpt-4\":\n",
    "            kwargs['model']=\"gpt-4\"\n",
    "            return bolift.AskTellFewShotTopk(**kwargs)\n",
    "        case \"gpt-4o\":\n",
    "            kwargs['model']=\"gpt-4o-2024-05-13\"\n",
    "            return bolift.AskTellFewShotTopk(**kwargs)\n",
    "        case \"gpt-4o-mini\":\n",
    "            kwargs['model']=\"gpt-4o-mini-2024-07-18\"\n",
    "            return bolift.AskTellFewShotTopk(**kwargs)\n",
    "        case \"haiku\":\n",
    "            kwargs['model']=\"claude-3-haiku-20240307\"\n",
    "            return bolift.AskTellFewShotTopk(**kwargs)\n",
    "        case \"sonnet\":\n",
    "            kwargs['model']=\"claude-3-5-sonnet-20240620\"\n",
    "            return bolift.AskTellFewShotTopk(**kwargs)\n",
    "        case \"opus\":\n",
    "            kwargs['model']=\"claude-3-opus-20240229\"\n",
    "            return bolift.AskTellFewShotTopk(**kwargs)\n",
    "        case \"gpt-4-0125-preview\":\n",
    "            kwargs['model']=\"gpt-4-0125-preview\"\n",
    "            return bolift.AskTellFewShotTopk(**kwargs)\n",
    "        case \"davinci\":\n",
    "            kwargs['model']=\"davinci-002\"\n",
    "            return bolift.AskTellFewShotTopk(**kwargs)\n",
    "        case \"gpr\":\n",
    "            s = kwargs['selector_k']\n",
    "            kwargs['selector_k'] = 0\n",
    "            kwargs['pool'] = pool if pool else None\n",
    "            kwargs['n_components'] = 32\n",
    "            model = bolift.AskTellGPR(**kwargs) \n",
    "            del kwargs['pool']\n",
    "            del kwargs['n_components']\n",
    "            kwargs['selector_k'] = s\n",
    "            return model\n",
    "        case \"knn\":\n",
    "            s = kwargs['selector_k']\n",
    "            del kwargs['selector_k']\n",
    "            kwargs['knn'] = knn\n",
    "            model = bolift.AskTellNearestNeighbor(**kwargs)\n",
    "            del kwargs['knn']\n",
    "            kwargs['selector_k'] = s\n",
    "            return model\n",
    "        case \"krr\":\n",
    "            kwargs['alpha'] = 0.5\n",
    "            model = bolift.AskTellRidgeKernelRegression(**kwargs)\n",
    "            del kwargs['alpha']\n",
    "            return model\n",
    "        case \"finetune\":\n",
    "            s = kwargs['selector_k']\n",
    "            del kwargs['selector_k']\n",
    "            kwargs['model']=\"gpt-3.5-turbo\"\n",
    "            model = bolift.AskTellFinetuning(**kwargs)\n",
    "            kwargs['selector_k'] = s\n",
    "            return model\n",
    "        case _:\n",
    "            raise ValueError(\"Unknown model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(exp, dataset, system_message=\"\", *args, **kwargs):\n",
    "    T_list = exp['T_list']\n",
    "    k_list = exp['k_list']\n",
    "    N_list = exp['N_list']\n",
    "    models_list = exp['models_list']\n",
    "    out_csv_file = exp['out_csv_file']\n",
    "    model_class=\"topk\"\n",
    "    for T, k, N, model in itertools.product(T_list, k_list, N_list, models_list):\n",
    "        if model == \"gpr\" and N <= 5: continue # GPR needs at least 5 data points\n",
    "        print(f\"Running {dataset} {model_class} regression with T={T}, k={k}, N={N}, model={model}\", end=\" \")\n",
    "        raw_data, train_data, test_data, indexes, x_name, y_name = get_dataset(dataset, N, split=0.8)\n",
    "        kwargs['temperature'] = T\n",
    "        kwargs['selector_k'] = k\n",
    "        pool=None\n",
    "        if model == \"gpr\":\n",
    "            pool = bolift.Pool(raw_data[x_name].tolist())\n",
    "        asktell = get_asktell(model, kwargs=kwargs, pool=pool, knn=5)\n",
    "        x, y, yhat =  run_ablation_experiment(asktell, train_data, test_data, system_message=system_message)\n",
    "        save_csv(out_csv_file, x, y, yhat, dataset, model, T, k, N, model_class, asktell.tokens_used)\n",
    "        print(\" --> done\")\n",
    "\n",
    "def save_backup(out_csv_file):\n",
    "    if os.path.exists(f\"{out_csv_file}.csv\"):\n",
    "        i = 1\n",
    "        while os.path.exists(f\"{out_csv_file}{i}.csv\"):\n",
    "            i += 1\n",
    "        os.rename(f\"{out_csv_file}.csv\", f\"{out_csv_file}{i}.csv\")\n",
    "\n",
    "def merge_exps(out_csv_file):\n",
    "    save_backup(out_csv_file)\n",
    "    all_files = glob.glob(\"regression-results_exp*.csv\")\n",
    "    exps = []\n",
    "\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0, sep=\";\")\n",
    "        exps.append(df)\n",
    "\n",
    "    frame = pd.concat(exps, axis=0, ignore_index=True)\n",
    "    frame.to_csv(f\"{out_csv_file}.csv\", index=False, sep=\";\")\n",
    "\n",
    "    for filename in all_files:\n",
    "        os.remove(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config experiment\n",
    "\n",
    "These values and datasets should be loaded accordingly with the experiments that are being done.\n",
    "The union of all values considered in our experiments is available below.\n",
    "    \n",
    "```python\n",
    "T_list = [0.01, 0.1, 0.7, 1.0]\n",
    "k_list = [1, 2, 3, 4, 5]\n",
    "N_list = [1, 2, 5, 10, 50, 100, 250, 500, 700, 1000]\n",
    "models_list = [\"gpt-3.5-turbo-instruct\", \"gpt-3.5-turbo-0125\", \"gpt-4-0125-preview\", \"gpt-4o\" \"davinci-002\", \"KNN\", \"RNN\", \"GPR\", \"FineTunning\"]\n",
    "out_csv_file = \"regression_results.csv\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = {\n",
    "    \"exp_1\" : {\n",
    "        \"T_list\" : [0.05],\n",
    "        \"k_list\" : [1, 2, 5, 10],\n",
    "        \"N_list\" : [1000],\n",
    "        \"models_list\" : [\"gpt-3.5-turbo-0125\", \"gpt-4-0125-preview\", \"gpt-4o\"],\n",
    "        \"out_csv_file\" : \"regression-results1.csv\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in-house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=\"in-house\"\n",
    "kwargs = dict(\n",
    "    prefix=\"\",\n",
    "    prompt_template=PromptTemplate(\n",
    "        input_variables=[\"x\", \"y\", \"y_name\"],\n",
    "        template=\"Q: What is the {y_name} of {x}?@@@\\nA: {y}###\",\n",
    "    ),\n",
    "    suffix=\"What is the {y_name} of {x}?@@@\\nA:\",\n",
    "    x_formatter=lambda x: f\"experimental procedure: {x}\",\n",
    "    y_name=\"CO STY\",\n",
    "    y_formatter=lambda y: f\"{y:.2f}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=\"ocm\"\n",
    "# dataset=\"biasfree_ocm\"\n",
    "kwargs = dict(\n",
    "    # prefix=\"You are a bot who knows chemistry and catalysts. \" \\\n",
    "    #         \"Below, you'll see examples of experimental procedures to synthesize catalysts and the measured C2 yield in a oxidative methane coupling reaction. \" \\\n",
    "    #         \"The following question should be answered with a number and finished with ###\\n\",\n",
    "    prefix=\"\",\n",
    "    prompt_template=PromptTemplate(\n",
    "        input_variables=[\"x\", \"y\", \"y_name\"],   \n",
    "        template=\"Q: What is the {y_name} of {x}?@@@\\nA: {y}###\",\n",
    "    ),\n",
    "    suffix=\"What is the {y_name} of {x}?@@@\\nA:\",\n",
    "    x_formatter=lambda x: f\"experimental procedure: {x}\",\n",
    "    y_name=\"C2 yield\",\n",
    "    y_formatter=lambda y: f\"{y:.2f}\",\n",
    ")\n",
    "\n",
    "inv_system_message_path = \"./prompts/inv_prompt_1.txt\"\n",
    "system_message_path = \"./prompts/prompt_1.txt\"\n",
    "\n",
    "exps = {\n",
    "    # \"exp_1\" : { # Experiment 1 -> Varying k\n",
    "    #     \"T_list\" : [0.05],\n",
    "    #     \"k_list\" : [1, 2, 5, 10],\n",
    "    #     \"N_list\" : [1000],\n",
    "    #     \"models_list\" : [\"gpt-3.5-turbo-0125\"],\n",
    "    #     \"out_csv_file\" : \"regression-results_exp1.csv\",\n",
    "    # },\n",
    "    # \"exp_2\": { # Experiment 2 -> Varying T\n",
    "    #     \"T_list\" : [0.01, 0.1, 0.5, 0.7, 1.0, 1.5],\n",
    "    #     \"k_list\" : [5],\n",
    "    #     \"N_list\" : [1000],\n",
    "    #     \"models_list\" : [\"gpt-3.5-turbo-0125\"],\n",
    "    #     \"out_csv_file\" : \"regression-results_exp2.csv\",\n",
    "    # },\n",
    "    \"exp_3\": { # Experiment 3 -> Varying N\n",
    "        \"T_list\" : [0.7],\n",
    "        \"k_list\" : [5],\n",
    "        \"N_list\" : [1, 5, 10, 25, 50, 100, 250, 500, 1000],\n",
    "        # \"models_list\" : [\"gpt-3.5-turbo-0125\"],\n",
    "        \"models_list\" : [\"gemini-2.5-flash-preview\"],\n",
    "        \"out_csv_file\" : \"regression-results_exp3.csv\",\n",
    "    },\n",
    "    # \"exp_4\": { # Experiment 4 -> Varying the model\n",
    "    #     \"T_list\" : [0.7],\n",
    "    #     \"k_list\" : [5],\n",
    "    #     \"N_list\" : [1000],\n",
    "    #     \"models_list\" : [\"gpt-4o\", \"gpt-3.5-turbo-0125\", \"gpt-4-0125-preview\", \"gpr\"],\n",
    "    #     \"out_csv_file\" : \"regression-results_exp4.csv\",\n",
    "    # }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alloy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=\"alloy\"\n",
    "# dataset=\"biasfree_ocm\"\n",
    "\n",
    "kwargs = dict(\n",
    "    # prefix=\"You are a bot who knows chemistry and catalysts. \" \\\n",
    "    #         \"Below, you'll see examples of experimental procedures to synthesize catalysts and the measured C2 yield in a oxidative methane coupling reaction. \" \\\n",
    "    #         \"The following question should be answered with a number and finished with ###\\n\",\n",
    "    prefix=\"\",\n",
    "    prompt_template=PromptTemplate(\n",
    "        input_variables=[\"x\", \"y\", \"y_name\"],\n",
    "        template=\"Q: What is the {y_name} of {x}?@@@\\nA: {y}###\",\n",
    "    ),\n",
    "    suffix=\"What is the {y_name} of {x}?@@@\\nA:\",\n",
    "    x_formatter=lambda x: f\"the corresponding experimental procedure: {x}\",\n",
    "    y_name=\"the log(charge transfer) [coulombs/cm²]\", # inverse prompt : If {y_name} is {y}, then {x_name} is @@@\\n{x}###\"\n",
    "    y_formatter=lambda y: f\"{y:.2f}\",\n",
    "    selector_k=5,\n",
    "    temperature=0.7,\n",
    "    use_logprobs=False\n",
    ")\n",
    "\n",
    "inv_system_message_path = \"./prompts/gpt4_alloy_dataset_tale.txt\"\n",
    "system_message_path = \"./prompts/prompt_2_alloy_binary.txt\"\n",
    "\n",
    "exps = {\n",
    "    # \"exp_1\" : { # Experiment 1 -> Varying k\n",
    "    #     \"T_list\" : [0.05],\n",
    "    #     \"k_list\" : [1, 2, 5, 10],\n",
    "    #     \"N_list\" : [1000],\n",
    "    #     \"models_list\" : [\"gpt-3.5-turbo-0125\"],\n",
    "    #     \"out_csv_file\" : \"regression-results_exp1.csv\",\n",
    "    # },\n",
    "    # \"exp_2\": { # Experiment 2 -> Varying T\n",
    "    #     \"T_list\" : [0.01, 0.1, 0.5, 0.7, 1.0, 1.5],\n",
    "    #     \"k_list\" : [5],\n",
    "    #     \"N_list\" : [1000],\n",
    "    #     \"models_list\" : [\"gpt-3.5-turbo-0125\"],\n",
    "    #     \"out_csv_file\" : \"regression-results_exp2.csv\",\n",
    "    # },\n",
    "    # \"exp_3\": { # Experiment 3 -> Varying N\n",
    "    #     \"T_list\" : [0.7],\n",
    "    #     \"k_list\" : [5],\n",
    "    #     \"N_list\" : [1, 5, 10, 25, 50, 100, 250, 500, 1000],\n",
    "    #     \"models_list\" : [\"gpt-3.5-turbo-0125\"],\n",
    "    #     \"out_csv_file\" : \"regression-results_exp3.csv\",\n",
    "    # },\n",
    "    \"exp_4\": {\n",
    "        \"T_list\" : [0.7],\n",
    "        \"k_list\" : [5],\n",
    "        \"N_list\" : [10,100],\n",
    "        \"models_list\" : [\"davinci-002\"],\n",
    "        \"out_csv_file\" : \"regression-results_exp4.csv\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solubility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=\"sol\"\n",
    "kwargs = dict(\n",
    "    prefix=\"\",\n",
    "    prompt_template=PromptTemplate(\n",
    "        input_variables=[\"x\", \"y\", \"y_name\"],\n",
    "        template=\"Q: What is the {y_name} of {x}?@@@\\nA: {y}###\",\n",
    "    ),\n",
    "    suffix=\"What is the {y_name} of {x}?@@@\\nA:\",\n",
    "    x_formatter=lambda x: f\"iupac name {x}\",\n",
    "    y_name=\"measured log solubility in mols per litre\",\n",
    "    y_formatter=lambda y: f\"{y:.2f}\",\n",
    ")\n",
    "\n",
    "\n",
    "# inv_system_message_path = \"./prompts/inv_prompt_1.txt\"\n",
    "system_message_path = \"./prompts/prompt_sol.txt\"\n",
    "\n",
    "exps = {\n",
    "    # \"exp_1\" : { # Experiment 1 -> Varying k\n",
    "    #     \"T_list\" : [0.05],\n",
    "    #     \"k_list\" : [1, 2, 5, 10],\n",
    "    #     \"N_list\" : [700],\n",
    "    #     \"models_list\" : [\"gpt-3.5-turbo-0125\"],\n",
    "    #     \"out_csv_file\" : \"regression-results_exp1.csv\",\n",
    "    # },\n",
    "    # \"exp_2\": { # Experiment 2 -> Varying T\n",
    "    #     \"T_list\" : [0.01, 0.1, 0.5, 1.0],\n",
    "    #     \"k_list\" : [5],\n",
    "    #     \"N_list\" : [700],\n",
    "    #     \"models_list\" : [\"gpt-3.5-turbo-0125\"],\n",
    "    #     \"out_csv_file\" : \"regression-results_exp2.csv\",\n",
    "    # },\n",
    "    # \"exp_3\": { # Experiment 3 -> Varying N\n",
    "    #     \"T_list\" : [0.7],\n",
    "    #     \"k_list\" : [5],\n",
    "    #     \"N_list\" : [1, 5, 10, 25, 50, 100, 250, 500, 700],\n",
    "    #     \"models_list\" : [\"gpt-3.5-turbo-0125\"],\n",
    "    #     \"out_csv_file\" : \"regression-results_exp3.csv\",\n",
    "    # },\n",
    "    \"exp_4\": { # Experiment 4 -> Varying the model\n",
    "        \"T_list\" : [0.7],\n",
    "        \"k_list\" : [5],\n",
    "        \"N_list\" : [700],\n",
    "        # \"models_list\" : [\"gpt-3.5-turbo-instruct\", \"davinci-002\", \"gpt-4-0125-preview\"],\n",
    "        \"models_list\" : [\"knn\", \"krr\"],\n",
    "        \"out_csv_file\" : \"regression-results_exp4_sol.csv\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(system_message_path):\n",
    "    with open(system_message_path, \"r\") as f:\n",
    "        system_message = f.read()\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Running experiment {i+1}\")\n",
    "    for e in exps:\n",
    "        exp = exps[e]\n",
    "        run_experiment(exp, dataset, system_message=system_message, **kwargs)\n",
    "\n",
    "    merge_exps(\"gemini-regression\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"out/regression/gemini-regression1.csv\", sep=\";\")\n",
    "df = df[df.model == \"gemini-2.5-flash-preview\"]\n",
    "\n",
    "# plot y by yhat\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.scatterplot(data=df, x=\"y\", y=\"yhat\", hue=\"model\", style=\"model\")\n",
    "plt.plot([-10, 20], [-10, 20], color=\"black\", linestyle=\"--\")\n",
    "plt.xlabel(\"True value\")\n",
    "plt.ylabel(\"Predicted value\")\n",
    "plt.legend().remove()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test of the last regression experiment\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "lim=(min(y)-1,max(y)+1)\n",
    "# lim=(-20,40)\n",
    "plt.plot(lim, lim)\n",
    "plt.xlim(lim)\n",
    "plt.ylim(lim)\n",
    "# plt.scatter(X_test[:,0], [yhi.mean() for yhi in yhat], color=\"red\", alpha=0.2)\n",
    "# plt.scatter(X_test[:,0], y, color=\"blue\", alpha=0.2)\n",
    "# plt.scatter(X_train[:,0],train_data['completion'].to_list(), color=\"green\", alpha=0.2)\n",
    "plt.scatter(y, [yhi.mean() for yhi in yhat], color=\"red\", alpha=0.2)\n",
    "plt.scatter(train_data['completion'].to_list(),train_data['completion'].to_list())\n",
    "# plt.errorbar(y, \n",
    "#             [yhi.mean() for yhi in yhat], \n",
    "#             yerr=[yhi.std() for yhi in yhat],\n",
    "#             fmt='.', color='gray', alpha=0.4)\n",
    "plt.text(lim[0] + 0.1*(max(y)-min(y)), lim[1] - 1*0.1*(max(y)-min(y)), f\"correlation = {np.corrcoef(y, [yhi.mean() for yhi in yhat])[0,1]:.3f}\")\n",
    "plt.text(lim[0] + 0.1*(max(y)-min(y)), lim[1] - 2*0.1*(max(y)-min(y)), f\"MAE = {mean_absolute_error(y, [yhi.mean() for yhi in yhat]):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "import uncertainty_toolbox as uct\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as font_manager\n",
    "urllib.request.urlretrieve('https://github.com/google/fonts/raw/main/ofl/ibmplexmono/IBMPlexMono-Regular.ttf', 'IBMPlexMono-Regular.ttf')\n",
    "fe = font_manager.FontEntry(\n",
    "    fname='IBMPlexMono-Regular.ttf',\n",
    "    name='plexmono')\n",
    "font_manager.fontManager.ttflist.append(fe)\n",
    "plt.rcParams.update({'axes.facecolor':'#f5f4e9',\n",
    "            'grid.color' : '#AAAAAA',\n",
    "            'axes.edgecolor':'#333333',\n",
    "            'figure.facecolor':'#FFFFFF',\n",
    "            'axes.grid': False,\n",
    "            'axes.prop_cycle':   plt.cycler('color', plt.cm.Dark2.colors),\n",
    "            'font.family': fe.name,\n",
    "            'figure.figsize': (3.5,3.5 / 1.2),\n",
    "            'ytick.left': True,\n",
    "            'xtick.bottom': True\n",
    "           })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"sol\"\n",
    "max_N= 700\n",
    "\n",
    "# Load and merge all 5 dataframes\n",
    "dfs = []\n",
    "for i in range(1, 6):\n",
    "    file_path = f\"out/regression/{data}-regression-{i}.csv\"\n",
    "    try:\n",
    "        temp_df = pd.read_csv(file_path, sep=';')\n",
    "        temp_df['source'] = f\"run_{i}\"  # Add file origin\n",
    "        dfs.append(temp_df)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "\n",
    "# Merge all dataframes\n",
    "all_df = pd.concat(dfs, ignore_index=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df[(all_df['data'] == data)].groupby(['Temperature', 'data', 'k_selected', 'model_class', \"N_train\", \"model\"]).size().reset_index().sort_values(by=[\"model_class\", \"Temperature\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def mse(y, pred):\n",
    "  # return np.mean((y-pred)**2)\n",
    "  return mean_squared_error(y, pred)\n",
    "\n",
    "def mae(y, pred):\n",
    "  return mean_absolute_error(y, pred)\n",
    "\n",
    "def r2(y, pred):\n",
    "  return r2_score(y, pred)\n",
    "\n",
    "def corr(y, pred):\n",
    "  return np.corrcoef(y, pred)[0,1]\n",
    "\n",
    "def acc(y, pred, threshold):\n",
    "  acc = sum((abs(pred - y)<threshold))/len(pred)\n",
    "  return acc\n",
    "\n",
    "def log_likelihood(y, pred, ystd, eps=0):\n",
    "  y = np.array(y)\n",
    "  pred = np.array(pred)\n",
    "  ystd = np.array(ystd)\n",
    "  yvar = ystd**2 + eps\n",
    "  neg_ll = 0.5 * (np.log(yvar) + ((y - pred)**2 / yvar))\n",
    "  return np.sum(neg_ll)/len(y)\n",
    "\n",
    "def select_df(df, data, k, T, model, model_class, N):\n",
    "  config = {'k': k,\n",
    "            'T': T,\n",
    "            'data': data,\n",
    "            'model': model,\n",
    "            'model_class': model_class,\n",
    "            'N': N,\n",
    "            }\n",
    "\n",
    "  q = f\"\"\n",
    "  if T != 'any':\n",
    "    q += f\"Temperature=={T} and \"\n",
    "  if k != 'any':  \n",
    "    q+= f\"k_selected=={k} and \"\n",
    "  if model != 'any': \n",
    "    q+= f\"model=='{model}' and \"\n",
    "  q+= f\"model_class=='{model_class}' and \"\n",
    "  if N != 'any':\n",
    "    q+= f\"N_train=={N} and \"\n",
    "  q += f\"data=='{data}'\"\n",
    "  sel = df.query(q)\n",
    "  if sel.empty:\n",
    "    raise ValueError(f\"Dataframe is empty for the configuration {config}\")\n",
    "  return sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_parities(df, data_property, data_range, nrows, ncols, data=None, k=None, T=None, model=None, model_class=None, N=None, axis_name=None, calibration=None, recal_ind=1, out_name=None, GPR=False):\n",
    "  config = {'k': k,\n",
    "            'T': T,\n",
    "            'data': data,\n",
    "            'model': model,\n",
    "            'model_class': model_class,\n",
    "            'N': N,\n",
    "            }\n",
    "\n",
    "  if sum([1 for i in config.values() if i is None]) > 1:\n",
    "    raise ValueError(\"Only the property being varied in data_range can me passed as None.\")\n",
    "\n",
    "  if nrows*ncols < len(data_range):\n",
    "    raise ValueError('''There's not enough space to plat all data in data_range.\n",
    "    Decrease the size of data_range or increase ncols or nrows.''')\n",
    "\n",
    "  fig, axs = plt.subplots(nrows=nrows, ncols=ncols, sharey=False, figsize=(12, 4), dpi=600)\n",
    "  for i, p in enumerate(data_range):\n",
    "    config[data_property] = p\n",
    "    y=[]\n",
    "    yhat=[]\n",
    "    yprob=[]\n",
    "    ax = axs if ncols*nrows == 1 else axs.flatten()[i]\n",
    "\n",
    "    df_sel = select_df(df, **config)\n",
    "\n",
    "    for prompt in df_sel['x'].unique():\n",
    "        y.append(df_sel[df_sel['x']==prompt]['y'].unique()[0])\n",
    "        # max_p = np.argmax(df_sel[df_sel['y']==d]['yprobs'].values)\n",
    "        yhat.append(df_sel[df_sel['x']==prompt]['yhat'].values)\n",
    "        yprob.append(df_sel[df_sel['x']==prompt]['yprobs'].values)\n",
    "    yprobs = [yhi.std() for yhi in yhat]\n",
    "    if GPR:\n",
    "        ymeans = np.array([yhi.mean() for yhi in yhat])\n",
    "        ystds = np.array([ypi.mean() for ypi in yprob])\n",
    "    else:\n",
    "        ymeans = np.array([\n",
    "                  np.sum(yhi*ypi) if len(yhi)>1 else yhi.mean()\n",
    "                  for yhi,ypi in zip(yhat, yprob)\n",
    "                ])\n",
    "        ystds = np.array([\n",
    "                  np.sqrt(np.sum((yhi-ymi)**2*ypi)) if np.sum((yhi-ymi)**2*ypi)>1 else 0.1 #ypi.mean()\n",
    "                  for yhi,ypi,ymi in zip(yhat, yprob, ymeans)\n",
    "                ])\n",
    "\n",
    "    if calibration:\n",
    "        if calibration == \"scaling_factor\":\n",
    "          std_scaling = uct.recalibration.optimize_recalibration_ratio(ymeans[:recal_ind], ystds[:recal_ind], np.array(y[:recal_ind]),\n",
    "                                                                        criterion=\"miscal\")\n",
    "          ystds = ystds * std_scaling\n",
    "        elif calibration == \"isotonic\":\n",
    "          exp_props, obs_props= uct.metrics_calibration.get_proportion_lists_vectorized(ymeans[:recal_ind], ystds[:recal_ind], np.array(y[:recal_ind]))\n",
    "          recal_model = uct.recalibration.iso_recal(exp_props, obs_props)\n",
    "          recal_bounds = uct.metrics_calibration.get_prediction_interval(ymeans, ystds, 0.95, recal_model)\n",
    "          ystds=np.array([ymeans - recal_bounds.lower,\n",
    "                 recal_bounds.upper - ymeans])\n",
    "\n",
    "    ax.plot(y,y)\n",
    "    ax.errorbar(y, \n",
    "                ymeans, \n",
    "                yerr=ystds,\n",
    "                fmt='.', color='gray', alpha=0.3)\n",
    "    ax.scatter(\n",
    "        y, ymeans, s=6, alpha=1, color=f\"C{i}\"\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f\"{data_property}={p}\")\n",
    "\n",
    "    lim = (min(y), max(y))\n",
    "    \n",
    "    if model in [\"krr\", \"knn\"]:\n",
    "       print(ystds)\n",
    "       metrics = {\n",
    "          \"accuracy\": uct.metrics.get_all_accuracy_metrics(ymeans, np.array(y), verbose=False)\n",
    "                  }\n",
    "    else:\n",
    "        metrics = uct.metrics.get_all_metrics(ymeans, ystds, np.array(y), verbose=False)\n",
    "    ax.text(lim[0] + 0.1*(max(y)-min(y)), lim[1] - 1*0.1*(max(y)-min(y)), f\"$(\\\\uparrow$)correlation = {metrics['accuracy']['corr']:.3f}\")\n",
    "    if model_class not in [\"KRR\", \"KNN\"]:\n",
    "      ax.text(lim[0] + 0.1*(max(y)-min(y)), lim[1] - 2*0.1*(max(y)-min(y)), f\"$(\\\\downarrow$)neg-ll = {metrics['scoring_rule']['nll']:.3f}\")\n",
    "    ax.text(lim[0] + 0.1*(max(y)-min(y)), lim[1] - 3*0.1*(max(y)-min(y)), f\"$(\\\\downarrow$)MAE = {metrics['accuracy']['mae']:.3f}\")\n",
    "\n",
    "    ax.set_ylim(lim[0],lim[1])\n",
    "    ax.set_xlim(lim[0],lim[1])\n",
    "\n",
    "    ax.set_xlabel(f\"measured {axis_name}\")\n",
    "    if (i%ncols==0):\n",
    "      ax.set_ylabel(f\"predicted {axis_name}\")\n",
    "\n",
    "  # plt.tight_layout()\n",
    "  plt.show()\n",
    "  # if (out_name):\n",
    "  #   plt.savefig(f\"figs/{out_name}\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ablation(df, data_property, data_range, nrows, ncols, data=None, k=None, T=None, model=None, model_class=None, N=None, out_name=None, GPR=False):\n",
    "  config = {'k': k,\n",
    "            'T': T,\n",
    "            'data': data,\n",
    "            'model': model,\n",
    "            'model_class': model_class,\n",
    "            'N': N,\n",
    "            }\n",
    "\n",
    "  MAE_list = []\n",
    "  RMSE_list = []\n",
    "  r_list = []\n",
    "  nll_list = []\n",
    "  prop_list = []\n",
    "  for i, p in enumerate(data_range):\n",
    "    config[data_property] = p\n",
    "    y=[]\n",
    "    yhat=[]\n",
    "    yprobs=[]\n",
    "    yprob=[]\t\n",
    "\n",
    "    df_sel = select_df(df, **config)\n",
    "\n",
    "    for prompt in df_sel['x'].unique():\n",
    "        y.append(df_sel[df_sel['x']==prompt]['y'].unique()[0])\n",
    "        # max_p = np.argmax(df_sel[df_sel['y']==d]['yprobs'].values)\n",
    "        yhat.append(df_sel[df_sel['x']==prompt]['yhat'].values)\n",
    "        yprob.append(df_sel[df_sel['x']==prompt]['yprobs'].values)\n",
    "    yprobs = [yhi.std() for yhi in yhat]\n",
    "    if GPR:\n",
    "        ymeans = np.array([yhi.mean() for yhi in yhat])\n",
    "        ystds = np.array([ypi.mean() for ypi in yprob])\n",
    "    else:\n",
    "        ymeans = np.array([\n",
    "                  np.sum(yhi*ypi) if len(yhi)>1 else yhi.mean()\n",
    "                  for yhi,ypi in zip(yhat, yprob)\n",
    "                ])\n",
    "        ystds = np.array([\n",
    "                  np.sqrt(np.sum((yhi-ymi)**2*ypi)) if yhi.std()>1 else ypi.mean()\n",
    "                  for yhi,ypi,ymi in zip(yhat, yprob, ymeans)\n",
    "                ])\n",
    "\n",
    "    metrics = uct.metrics.get_all_metrics(ymeans, ystds, np.array(y), verbose=False)\n",
    "    r_list.append(metrics['accuracy']['corr'])\n",
    "    RMSE_list.append(metrics['accuracy']['rmse'])\n",
    "    MAE_list.append(metrics['accuracy']['mae'])\n",
    "    nll_list.append(metrics['scoring_rule']['nll'])\n",
    "    prop_list.append(p)\n",
    "    print(f\"{model_class}(N:{config['N']}/k:{config['k']}/T:{config['T']}) => RMSE: | MAE: {MAE_list[-1]} | r: {r_list[-1]} | nll: {nll_list[-1]}\")\n",
    "\n",
    "  fig, axs = plt.subplots(nrows=nrows, ncols=ncols, sharey=False, figsize=(4*ncols, 4*nrows), dpi=300)\n",
    "  \n",
    "  axs[0].plot(prop_list, MAE_list)\n",
    "  axs[0].set_xlabel(data_property)\n",
    "  axs[0].set_ylabel(\"$\\\\rightarrow$MAE\")\n",
    "  \n",
    "  axs[1].plot(prop_list, r_list)\n",
    "  axs[1].set_xlabel(data_property)\n",
    "  axs[1].set_ylabel(\"$\\\\leftarrow$correlation\")\n",
    "\n",
    "  axs[2].plot(prop_list, nll_list)\n",
    "  axs[2].set_xlabel(data_property)\n",
    "  axs[2].set_yscale('log')\n",
    "  axs[2].set_ylabel(\"$\\\\rightarrow$negative log-likelihood\")\n",
    "\n",
    "  plt.tight_layout()\n",
    "  # plt.show()\n",
    "  if (out_name):\n",
    "    plt.savefig(f\"figs/{out_name}\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_ablation_data(df, data_property, data_range, data=None, k=None, T=None, model=None, model_class=None, N=None, GPR=False):\n",
    "  config = {'k': k,\n",
    "          'T': T,\n",
    "          'data': data,\n",
    "          'model': model,\n",
    "          'model_class': model_class,\n",
    "          'N': N,\n",
    "          }\n",
    "   \n",
    "  MAE_list = []\n",
    "  RMSE_list = []\n",
    "  r_list = []\n",
    "  nll_list = []\n",
    "  prop_list = []\n",
    "  for i, p in enumerate(data_range):\n",
    "    config[data_property] = p\n",
    "    y=[]\n",
    "    yhat=[]\n",
    "    yprobs=[]\n",
    "    yprob=[]\n",
    "\n",
    "    df_sel = select_df(df, **config)\n",
    "\n",
    "    for prompt in df_sel['x'].unique():\n",
    "        y.append(df_sel[df_sel['x']==prompt]['y'].unique()[0])\n",
    "        # max_p = np.argmax(df_sel[df_sel['y']==d]['yprobs'].values)\n",
    "        yhat.append(df_sel[df_sel['x']==prompt]['yhat'].values)\n",
    "        yprob.append(df_sel[df_sel['x']==prompt]['yprobs'].values)\n",
    "    yprobs = [yhi.std() for yhi in yhat]\n",
    "    if GPR:\n",
    "        ymeans = np.array([yhi.mean() for yhi in yhat])\n",
    "        ystds = np.array([ypi.mean() for ypi in yprob])\n",
    "    else:\n",
    "        ymeans = np.array([\n",
    "                  np.sum(yhi*ypi) if len(yhi)>1 else yhi.mean()\n",
    "                  for yhi,ypi in zip(yhat, yprob)\n",
    "                ])\n",
    "        ystds = np.array([\n",
    "                  np.sqrt(np.sum((yhi-ymi)**2*ypi)) if np.sum((yhi-ymi)**2*ypi)>0 else 10\n",
    "                  for yhi,ypi,ymi in zip(yhat, yprob, ymeans)\n",
    "                ])\n",
    "\n",
    "    if model_class in [\"KRR\", \"KNN\"]:\n",
    "       metrics = {\n",
    "          \"accuracy\": uct.metrics.get_all_accuracy_metrics(ymeans, np.array(y), verbose=False)\n",
    "                  }\n",
    "    else:\n",
    "      metrics = uct.metrics.get_all_metrics(ymeans, ystds, np.array(y), verbose=False)\n",
    "      nll_list.append(metrics['scoring_rule']['nll'])\n",
    "    r_list.append(metrics['accuracy']['corr'])\n",
    "    RMSE_list.append(metrics['accuracy']['rmse'])\n",
    "    MAE_list.append(metrics['accuracy']['mae'])\n",
    "    prop_list.append(p)\n",
    "    with open(\"Table.tex\", \"a\") as t:\n",
    "      t.write(f\"{config['data']}&{model_class}&{model}&{config['T']}&{config['k']}&{config['N']}&{RMSE_list[-1]}&{MAE_list[-1]}&{r_list[-1]}&{nll_list[-1] if nll_list else '-'}&\\\\\\\\\\n\")\n",
    "    # print(f\"{model_class}(N:{config['N']}/k:{config['k']}/T:{config['T']}) => RMSE: | MAE: {MAE_list[-1]} | r: {r_list[-1]} | nll: {nll_list[-1]}\")\n",
    "   \n",
    "  return prop_list, MAE_list, r_list, nll_list\n",
    "\n",
    "def create_sub_ablation(axs, df, lims, data_property, data_range, color='C0', data=None, k=None, T=None, model=None, model_class=None, N=None, label=False, GPR=False):\n",
    "  config = {'k': k,\n",
    "            'T': T,\n",
    "            'data': data,\n",
    "            'model': model,\n",
    "            'model_class': model_class,\n",
    "            'N': N,\n",
    "            }\n",
    "\n",
    "  prop_list, MAE_list, r_list, nll_list = get_sub_ablation_data(df, data_property, data_range, **config, GPR=GPR)\n",
    "\n",
    "  for ax in axs:\n",
    "    ax.label_outer()\n",
    "\n",
    "  if label:\n",
    "    if model_class==\"GPR-BOT\":\n",
    "      axs[0].plot(prop_list, MAE_list, label=\"GPR\", color=color)\n",
    "    else:\n",
    "      axs[0].plot(prop_list, MAE_list, label=model_class, color=color)\n",
    "  else:\n",
    "    axs[0].plot(prop_list, MAE_list, color=color)\n",
    "  axs[0].set_ylabel(\"MAE\\n$\\leftarrow$\")\n",
    "  axs[0].set_ylim(lims[0])\n",
    "  axs[0].set_label(model_class)\n",
    "  \n",
    "  axs[1].plot(prop_list, r_list, color=color)\n",
    "  axs[1].set_xlabel(data_property)\n",
    "  axs[1].set_ylabel(\"r\\n$\\\\rightarrow$\")\n",
    "  axs[1].set_ylim(lims[1])\n",
    "  axs[1].set_label(model_class)\n",
    "\n",
    "  if False: #model_class not in [\"KRR\", \"KNN\"]:\n",
    "    axs[2].plot(prop_list, nll_list, color=color)\n",
    "    axs[2].set_xlabel(data_property)\n",
    "    axs[2].set_yscale('log')\n",
    "    axs[2].set_ylabel(\"neg-ll\\n$\\leftarrow$\")\n",
    "    # axs[1].set_label(model_class)\n",
    "\n",
    "  for ax in axs:\n",
    "    ax.label_outer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub_shadow(axs, df, lims, data_property, data_range, color='C0', data=None, k=None, T=None, model=None, model_class=None, N=None, label=False, GPR=False):\n",
    "\n",
    "    all_MAE = []\n",
    "    all_r = []\n",
    "    config = {'k': k,\n",
    "            'T': T,\n",
    "            'data': data,\n",
    "            'model': model,\n",
    "            'model_class': model_class,\n",
    "            'N': N,\n",
    "            }\n",
    "\n",
    "    for i in range(1, 6):  # Loop through the 5 CSV files\n",
    "        df = pd.read_csv(f\"out/regression/{data}-regression-{i}.csv\", sep=';')\n",
    "        df_sel = select_df(df, **config)\n",
    "        \n",
    "        prop_list, MAE_list, r_list, nll_list = get_sub_ablation_data(df_sel, data_property, data_range, data=data, k=k, T=T, model=model, model_class=model_class, N=N)\n",
    "\n",
    "        all_MAE.append(MAE_list)\n",
    "        all_r.append(r_list)\n",
    "\n",
    "    all_MAE = np.array(all_MAE)\n",
    "    all_r = np.array(all_r)\n",
    "\n",
    "    # Compute average MAE and r\n",
    "    avg_MAE = np.mean(all_MAE, axis=0)\n",
    "    avg_r = np.mean(all_r, axis=0)\n",
    "\n",
    "    # Compute min and max for uncertainty region\n",
    "    min_MAE = np.min(all_MAE, axis=0)\n",
    "    max_MAE = np.max(all_MAE, axis=0)\n",
    "    min_r = np.min(all_r, axis=0)\n",
    "    max_r = np.max(all_r, axis=0)\n",
    "\n",
    "    # Plot average curve with uncertainty region\n",
    "    axs[0].fill_between(prop_list, min_MAE, max_MAE, color=color, alpha=0.3)\n",
    "    axs[0].plot(prop_list, avg_MAE, color=color)\n",
    "    axs[0].set_ylabel(\"MAE\\n$\\leftarrow$\")\n",
    "    axs[0].set_ylim(lims[0])\n",
    "    axs[0].legend()\n",
    "\n",
    "    axs[1].fill_between(prop_list, min_r, max_r, color=color, alpha=0.3)\n",
    "    axs[1].plot(prop_list, avg_r, color=color)\n",
    "    axs[1].set_ylabel(\"r\\n$\\\\rightarrow$\")\n",
    "    axs[1].set_ylim(lims[1])\n",
    "    axs[1].legend()\n",
    "\n",
    "    axs[1].set_xlabel(data_property)\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.label_outer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_parity_data():\n",
    "   pass\n",
    "   \n",
    "   \n",
    "def create_sub_parity(ax, df_sel, axis_name, model_class, lim=[-1,1], color='gray', GPR=False, title=None, calibration=None, recal_ind=0, show_metrics=True):\n",
    "    y=[]\n",
    "    yhat=[]\n",
    "    yprob=[]\n",
    "    for prompt in df_sel['x'].unique():\n",
    "        y.append(df_sel[df_sel['x']==prompt]['y'].unique()[0])\n",
    "        # max_p = np.argmax(df_sel[df_sel['y']==d]['yprobs'].values)\n",
    "        yhat.append(df_sel[df_sel['x']==prompt]['yhat'].values)\n",
    "        yprob.append(df_sel[df_sel['x']==prompt]['yprobs'].values)\n",
    "    yprobs = [yhi.std() for yhi in yhat]\n",
    "    if GPR:\n",
    "        ymeans = np.array([yhi.mean() for yhi in yhat])\n",
    "        ystds = np.array([ypi.mean() for ypi in yprob])\n",
    "    else:\n",
    "        ymeans = np.array([\n",
    "                  np.sum(yhi*ypi) if len(yhi)>1 else yhi.mean()\n",
    "                  for yhi,ypi in zip(yhat, yprob)\n",
    "                ])\n",
    "        ystds = np.array([\n",
    "                  np.sqrt(np.sum((yhi-ymi)**2*ypi)) if len(yhi)>1 else ypi.mean()\n",
    "                  for yhi,ypi,ymi in zip(yhat, yprob, ymeans)\n",
    "                ])\n",
    "        # hack to fix uncertainties in finetuned model. 3.559 is the training set (N=1000) std\n",
    "        ystds = np.array([ysi if ysi!=10 else 3.559 for ysi in ystds]) \n",
    "  \n",
    "    if calibration:\n",
    "        if calibration == \"scaling_factor\":\n",
    "          std_scaling = uct.recalibration.optimize_recalibration_ratio(ymeans[:recal_ind], ystds[:recal_ind], np.array(y[:recal_ind]),\n",
    "                                                                        criterion=\"miscal\")\n",
    "          ystds = ystds * std_scaling\n",
    "        elif calibration == \"isotonic\":\n",
    "          exp_props, obs_props= uct.metrics_calibration.get_proportion_lists_vectorized(ymeans[:recal_ind], ystds[:recal_ind], np.array(y[:recal_ind]))\n",
    "          recal_model = uct.recalibration.iso_recal(exp_props, obs_props)\n",
    "          recal_bounds = uct.metrics_calibration.get_prediction_interval(ymeans, ystds, 0.95, recal_model)\n",
    "          ystds=np.array([ymeans - recal_bounds.lower,\n",
    "                 recal_bounds.upper - ymeans])\n",
    "\n",
    "    if model_class in [\"KRR\", \"KNN\"] or calibration==\"isotonic\":\n",
    "       metrics = {\n",
    "          \"accuracy\": uct.metrics.get_all_accuracy_metrics(ymeans, np.array(y), verbose=False)\n",
    "                  }\n",
    "       metrics_to_return = [metrics['accuracy']['corr'], metrics['accuracy']['mae'], None]\n",
    "    else:\n",
    "      metrics = uct.metrics.get_all_metrics(ymeans, ystds, np.array(y), verbose=False)\n",
    "      metrics_to_return = [metrics['accuracy']['corr'], metrics['accuracy']['mae'], metrics['scoring_rule']['nll']]\n",
    "      if show_metrics:\n",
    "        ax.text(lim[0] + 0.1*(max(y)-min(y)), lim[1] - 2*0.1*(max(y)-min(y)), f\"$(\\\\downarrow$)neg-ll = {metrics_to_return[2]:.3f}\")\n",
    "    if show_metrics:\n",
    "      ax.text(lim[0] + 0.1*(max(y)-min(y)), lim[1] - 1*0.1*(max(y)-min(y)), f\"$(\\\\uparrow$)correlation = {metrics_to_return[1]:.3f}\")\n",
    "      ax.text(lim[0] + 0.1*(max(y)-min(y)), lim[1] - 3*0.1*(max(y)-min(y)), f\"$(\\\\downarrow$)MAE = {metrics_to_return[0]:.3f}\")\n",
    "\n",
    "    # with open(\"Table.tex\", \"a\") as t:\n",
    "    #   t.write(f\"{config['data']}&{model_class}&{model}&{config['T']}&{config['k']}&{config['N']}&{RMSE_list[-1]}&{MAE_list[-1]}&{r_list[-1]}&{nll_list[-1] if nll_list else '-'}&\\\\\\\\\\n\")\n",
    "    # print(f\"{model_class}(N:{config['N']}/k:{config['k']}/T:{config['T']}) => RMSE: | MAE: {MAE_list[-1]} | r: {r_list[-1]} | nll: {nll_list[-1]}\")\n",
    "\n",
    "    ax.set_xlabel(f\"measured {axis_name}\")\n",
    "    ax.set_ylabel(f\"predicted {axis_name}\")\n",
    "    ax.set_ylim(lim[0],lim[1])\n",
    "    ax.set_xlim(lim[0],lim[1])\n",
    "    ax.set_xticks(np.arange(lim[0],lim[1]+0.1,4.0))\n",
    "\n",
    "    if title:\n",
    "      ax.set_title(title)\n",
    "\n",
    "    ax.plot(y,y)\n",
    "    ax.plot(lim,lim)\n",
    "    if model_class not in [\"KRR\", \"KNN\"]:\n",
    "      ax.errorbar(y, \n",
    "                  ymeans, \n",
    "                  yerr=ystds,\n",
    "                  fmt='.', color='gray', alpha=0.2)\n",
    "    ax.scatter(\n",
    "        y, ymeans, s=6, alpha=1, color=color\n",
    "    )\n",
    "    return metrics_to_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,16), constrained_layout=True)\n",
    "subfigs = fig.subfigures(1,1, wspace=0.1, hspace=0.1)\n",
    "\n",
    "lims = [(0,5),(0,1),(-1,1)]\n",
    "\n",
    "sub00 = subfigs.subplots(2,1, sharex=True, sharey=False)\n",
    "df1 = all_df[all_df['source'] == f'run_1']\n",
    "d01 = select_df(df1, data=data, k=5, T=0.7, model='gemini-2.5-flash-preview', model_class='topk', N='any')\n",
    "\n",
    "create_sub_shadow(sub00, d01, lims, 'N', sorted(d01['N_train'].unique()), color='C1',data=data, k=5, T=0.7, model='gemini-2.5-flash-preview', model_class='topk', N='any', label=True)\n",
    "d01 = select_df(df1, data=data, k=5, T=0.7, model='gpt-4o', model_class='topk', N='any')\n",
    "create_sub_shadow(sub00, d01, lims, 'N', sorted(d01['N_train'].unique()), color='C2',data=data, k=5, T=0.7, model='gpt-4o', model_class='topk', N='any', label=True)\n",
    "d01 = select_df(df1, data=data, k=5, T=0.7, model='knn', model_class='topk', N='any')\n",
    "create_sub_shadow(sub00, d01, lims, 'N', sorted(d01['N_train'].unique()), color='C3',data=data, k=5, T=0.7, model='knn', model_class='topk', N='any', label=True)\n",
    "d01 = select_df(df1, data=data, k=5, T=0.7, model='krr', model_class='topk', N='any')\n",
    "create_sub_shadow(sub00, d01, lims, 'N', sorted(d01['N_train'].unique()), color='C4',data=data, k=5, T=0.7, model='krr', model_class='topk', N='any', label=True)\n",
    "d01 = select_df(df1, data=data, k=5, T=0.7, model='gpr', model_class='topk', N='any')\n",
    "create_sub_shadow(sub00, d01, lims, 'N', sorted(d01['N_train'].unique()), color='C5',data=data, k=5, T=0.7, model='gpr', model_class='topk', N='any', label=True)\n",
    "\n",
    "fig.legend(loc='upper center', bbox_to_anchor=(0.5 ,0),\n",
    "          fancybox=True, shadow=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_shadow_models_fig():\n",
    "\n",
    "  fig = plt.figure(figsize=(4,6), constrained_layout=True)\n",
    "  subfigs = fig.subfigures(1,1, wspace=0.1, hspace=0.1) \n",
    "\n",
    "  lims = [(0,5),(0,1),(-1,1)]\n",
    "\n",
    "  sub00 = subfigs.subplots(2,1, sharex=True, sharey=False)\n",
    "  df0 = all_df[all_df['source'] == f'run_1']\n",
    "  d00 = select_df(df0, data=data, k=5, T=0.7, model='gemini-2.5-flash-preview', model_class='topk', N='any')\n",
    "  create_sub_shadow(sub00, d00, lims, 'N', sorted(d00['N_train'].unique()), data=data, color='C1', k=5, T=0.7, model='gemini-2.5-flash-preview', model_class='topk', N='any', label=False)\n",
    "  d01 = select_df(df0, data=data, k=5, T=0.7, model='gpt-4o', model_class='topk', N='any')\n",
    "  create_sub_shadow(sub00, d01, lims, 'N', sorted(d01['N_train'].unique()), data=data, color='C2', k=5, T=0.7, model='gpt-4o', model_class='topk', N='any', label=False)\n",
    "  d02 = select_df(df0, data=data, k=5, T=0.7, model='knn', model_class='topk', N='any')\n",
    "  create_sub_shadow(sub00, d02, lims, 'N', sorted(d02['N_train'].unique()), data=data, color='C3', k=5, T=0.7, model='knn', model_class='topk', N='any', label=False)\n",
    "  d03 = select_df(df0, data=data, k=5, T=0.7, model='krr', model_class='topk', N='any')\n",
    "  d03 = d03[d03['N_train']!=1]\n",
    "  create_sub_shadow(sub00, d03, lims, 'N', sorted(d03['N_train'].unique()), data=data, color='C4', k=5, T=0.7, model='krr', model_class='topk', N='any', label=False)\n",
    "  d04 = select_df(df0, data=data, k=5, T=0.7, model='gpr', model_class='topk', N='any')\n",
    "  create_sub_shadow(sub00, d04, lims, 'N', sorted(d04['N_train'].unique()), data=data, color='C5', k=5, T=0.7, model='gpr', model_class='topk', N='any', label=False)\n",
    "\n",
    "  fig.legend(loc='upper center', bbox_to_anchor=(0.5 ,0),\n",
    "            fancybox=True, shadow=True, ncol=5)\n",
    "\n",
    "  # plt.tight_layout()\n",
    "  plt.savefig(f\"./out/figs/{data}_metrics_models.png\", dpi=300, bbox_inches='tight')\n",
    "  plt.show()\n",
    "\n",
    "make_shadow_models_fig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_metrics(ax, metrics, lim):\n",
    "  corr = [m[0] for m in metrics]\n",
    "  mae = [m[1] for m in metrics]\n",
    "  nll = [m[2] for m in metrics]\n",
    "  ax.text(lim[0] + 0.01*(lim[1]-lim[0]), lim[1] - 1*0.1*(lim[1]-lim[0]), f\"$(\\\\uparrow$)correlation = {np.mean(corr):.3f}±{np.std(corr):.3f}\")\n",
    "  ax.text(lim[0] + 0.01*(lim[1]-lim[0]), lim[1] - 2*0.1*(lim[1]-lim[0]), f\"$(\\\\downarrow$)MAE = {np.mean(mae):.3f}±{np.std(mae):.3f}\")\n",
    "  if all([n is not None for n in nll]):\n",
    "    ax.text(lim[0] + 0.01*(lim[1]-lim[0]), lim[1] - 3*0.1*(lim[1]-lim[0]), f\"$(\\\\downarrow$)neg-ll = {np.mean(nll):.3f}±{np.std(nll):.3f}\")\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12,8), constrained_layout=True)\n",
    "for ax in axs.flat:\n",
    "    ax.set_aspect(1)\n",
    "\n",
    "gpt35_metrics = []\n",
    "gemini_metrics = []\n",
    "gpt4o_metrics = []\n",
    "krr_metrics = []\n",
    "finetune_metrics = []\n",
    "gpr_metrics = []\n",
    "\n",
    "for i in range(1,6):\n",
    "    df = all_df[all_df['source'] == f'run_{i}']\n",
    "    d00 = select_df(df, data=data, k=5, T=0.7, model='gpt-3.5-turbo-0125', model_class='topk', N=max_N)\n",
    "    lim = (min(d00['y']), max(d00['y']))\n",
    "    lim = (-2, 25)\n",
    "    lim = (-15, 5) # Sol limits with some space\n",
    "    text_anchor = sum(lim)/len(lim)\n",
    "    gpt35_metrics.append(create_sub_parity(axs[0,0], d00, 'LogS solubility', lim=lim, model_class=\"topk\", color=f'C0', title=\"gpt-3.5\", show_metrics=False))\n",
    "    d01 = select_df(df, data=data, k=5, T=0.7, model='gpt-4o-mini', model_class='topk', N=max_N)\n",
    "    gemini_metrics.append(create_sub_parity(axs[0,1], d01, 'LogS solubility', lim=lim, model_class=\"topk\", color=f'C1', title=\"gpt-4o-mini\", show_metrics=False))\n",
    "    d02 = select_df(df, data=data, k=5, T=0.7, model='gpt-4o', model_class='topk', N=max_N)\n",
    "    gpt4o_metrics.append(create_sub_parity(axs[0,2], d02, 'LogS solubility', lim=lim, model_class=\"topk\", color=f'C2', title=\"gpt-4o\", show_metrics=False))\n",
    "\n",
    "    if i not in [5]:\n",
    "        d10 = select_df(df, data=data, k=5, T=0.7, model='krr', model_class='topk', N=max_N)\n",
    "        krr_metrics.append(create_sub_parity(axs[1,0], d10, 'LogS solubility', lim=lim, model_class=\"KRR\", color=f'C4', title=\"KRR\", show_metrics=False))\n",
    "    if i not in [1,2,5]:\n",
    "        d11 = select_df(df, data=data, k=5, T=0.7, model='finetune', model_class='topk', N=max_N)\n",
    "        finetune_metrics.append(create_sub_parity(axs[1,1], d11, 'LogS solubility', lim=lim, model_class=\"KRR\", color=f'C5', title=\"finetune\", show_metrics=False))\n",
    "    d12 = select_df(df, data=data, k=5, T=0.7, model='gpr', model_class='topk', N=max_N)\n",
    "    gpr_metrics.append(create_sub_parity(axs[1,2], d12, 'LogS solubility', lim=lim, model_class=\"topk\", color=f'C6', title=\"GPR\", show_metrics=False))\n",
    "\n",
    "show_metrics(axs[0,0], gpt35_metrics, lim)\n",
    "show_metrics(axs[0,1], gemini_metrics, lim)\n",
    "show_metrics(axs[0,2], gpt4o_metrics, lim)\n",
    "show_metrics(axs[1,0], krr_metrics, lim)\n",
    "show_metrics(axs[1,1], finetune_metrics, lim)\n",
    "show_metrics(axs[1,2], gpr_metrics, lim)\n",
    "\n",
    "plt.savefig(f\"./out/figs/{data}_par_models\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_data = df[(df['data'] == 'ocm')]\n",
    "c2_data.groupby(['Temperature', 'data', 'k_selected', 'model_class', \"N_train\", \"model\"]).size().reset_index().sort_values(by=[\"model_class\", \"Temperature\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parities(df, \n",
    "              'model', \n",
    "              [\"gemini-2.5-flash-preview\", \"gpt-4-0125-preview\", \"gpt-4o\"], #sorted(c2_data[(c2_data['model_class']==\"topk\") & (c2_data['model']==\"text-curie-001\")]['N_train'].unique()), \n",
    "              nrows=1, ncols=3,\n",
    "              data='ocm', \n",
    "              k=5, \n",
    "              T=0.7, \n",
    "              model=None, \n",
    "              model_class='topk', \n",
    "              N=1000,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_C2_topk_N_curie.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parities(df, \n",
    "              'N', \n",
    "              [1,50,250,1000], #sorted(c2_data[(c2_data['model_class']==\"topk\") & (c2_data['model']==\"text-curie-001\")]['N_train'].unique()), \n",
    "              nrows=1, ncols=4,\n",
    "              data='ocm', \n",
    "              k=5, \n",
    "              T=0.7, \n",
    "              model='gpt-3.5-turbo-0125', \n",
    "              model_class='topk', \n",
    "              N=None,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_C2_topk_N_curie.png\")\n",
    "\n",
    "plot_parities(df, \n",
    "              'k', \n",
    "              [1,2,5,10], #sorted(c2_data[(c2_data['model_class']==\"topk\") & (c2_data['model']==\"text-curie-001\")]['k_selected'].unique()), \n",
    "              nrows=1, ncols=4,\n",
    "              data='ocm', \n",
    "              k=None, \n",
    "              T=0.05, \n",
    "              model='gpt-3.5-turbo-0125', \n",
    "              model_class='topk', \n",
    "              N=10,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_C2_topk_k_curie.png\")\n",
    "\n",
    "plot_parities(df, \n",
    "              'T', \n",
    "              [0.01,0.1,0.5,1.0], #sorted(c2_data[(c2_data['model_class']==\"topk\") & (c2_data['model']==\"text-curie-001\")]['k_selected'].unique()), \n",
    "              nrows=1, ncols=4,\n",
    "              data='ocm', \n",
    "              k=5, \n",
    "              T=None, \n",
    "              model='gpt-3.5-turbo-0125', \n",
    "              model_class='topk', \n",
    "              N=1000,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_C2_topk_T_curie.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### topk-davinci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parities(c2_data, \n",
    "              'T', \n",
    "              sorted(c2_data[(c2_data['model_class']==\"topk\") & (c2_data['model']==\"text-davinci-003\")]['Temperature'].unique()), \n",
    "              nrows=1, ncols=4,\n",
    "              data='C2',\n",
    "              k=5,\n",
    "              T=None,\n",
    "              model='text-davinci-003',\n",
    "              model_class='topk',\n",
    "              N=1000,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_C2_multi_T_curie.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_ablation(c2_data, \n",
    "#               'N', \n",
    "#               sorted(c2_data[(c2_data['model_class']==\"topk\") & (c2_data['model']==\"text-davinci-003\")]['N_train'].unique()), \n",
    "#               nrows=1, ncols=3,\n",
    "#               data='C2',\n",
    "#               k=5,\n",
    "#               T=0.05,\n",
    "#               model='text-davinci-003',\n",
    "#               model_class='topk',\n",
    "#               N=None,\n",
    "#               out_name=\"ablation_C2_topk_N_davinci.png\")\n",
    "\n",
    "# plot_ablation(c2_data, \n",
    "#               'T', \n",
    "#               sorted(c2_data[(c2_data['model_class']==\"topk\") & (c2_data['model']==\"text-davinci-003\")]['Temperature'].unique()), \n",
    "#               nrows=1, ncols=3,\n",
    "#               data='C2',\n",
    "#               k=5,\n",
    "#               T=None,\n",
    "#               model='text-davinci-003',\n",
    "#               model_class='topk',\n",
    "#               N=1000,\n",
    "#               out_name=\"ablation_C2_multi_T_davinci.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parities(c2_data, \n",
    "              'N', \n",
    "              [1,10,250,500], #sorted(c2_data[(c2_data['model_class']==\"GPR-BOT\") & (c2_data['model']==\"text-ada-001\")]['N_train'].unique()), \n",
    "              nrows=1, ncols=4,\n",
    "              data='C2', \n",
    "              k=32, \n",
    "              T=0.05, \n",
    "              model='text-ada-001', \n",
    "              model_class='GPR-BOT', \n",
    "              N=None,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_C2_GPR_N.png\",\n",
    "              GPR=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_ablation(c2_data, \n",
    "#               'N', \n",
    "#               sorted(c2_data[(c2_data['model_class']==\"GPR-BOT\") & (c2_data['model']==\"text-ada-001\")]['N_train'].unique()), \n",
    "#               nrows=1, ncols=3,\n",
    "#               data='C2',\n",
    "#               k=32,\n",
    "#               T=0.05,\n",
    "#               model='text-ada-001',\n",
    "#               model_class='GPR-BOT',\n",
    "#               N=None,\n",
    "#               out_name=\"ablation_C2_GPR_N_ada.png\",\n",
    "#               GPR=True)\n",
    "\n",
    "# plot_ablation(c2_data, \n",
    "#               'k',\n",
    "#               sorted(c2_data[(c2_data['model_class']==\"GPR-BOT\") & (c2_data['model']==\"text-ada-001\")]['k_selected'].unique()), \n",
    "#               nrows=1, ncols=3,\n",
    "#               data='C2',\n",
    "#               k=None,\n",
    "#               T=0.05,\n",
    "#               model='text-ada-001',\n",
    "#               model_class='GPR-BOT',\n",
    "#               N=500,\n",
    "#               out_name=\"ablation_C2_GPR_N_ada.png\",\n",
    "#               GPR=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parities(c2_data, \n",
    "              'N', \n",
    "              [5,10,25,50,100,250,500,1000], #sorted(c2_data[(c2_data['model_class']==\"GPR-BOT\") & (c2_data['model']==\"text-ada-001\")]['N_train'].unique()), \n",
    "              nrows=2, ncols=4,\n",
    "              data='C2', \n",
    "              k=1, \n",
    "              T=0.05, \n",
    "              model='text-ada-001', \n",
    "              model_class='KNN', \n",
    "              N=None,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_C2_KNN_N.png\",\n",
    "              GPR=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parities(c2_data, \n",
    "              'N', \n",
    "              [50,100,250,1000], #sorted(c2_data[(c2_data['model_class']==\"finetune\")]['N_train'].unique()), \n",
    "              nrows=1, ncols=4,\n",
    "              data='C2', \n",
    "              k=0, \n",
    "              T=0.05, \n",
    "              model='any', \n",
    "              model_class='finetune', \n",
    "              N=None,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_C2_FT_N.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_ablation(df, \n",
    "#               'N', \n",
    "#               sorted(c2_data[(c2_data['model_class']==\"finetune\")]['N_train'].unique()), \n",
    "#               nrows=1, ncols=3,\n",
    "#               data='C2',\n",
    "#               k=0,\n",
    "#               T=0.05,\n",
    "#               model='any',\n",
    "#               model_class='finetune',\n",
    "#               N=None,\n",
    "#               out_name=\"ablation_C2_FT_N_ada.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### curie X davinci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models = df[\n",
    "    (df['model_class']==\"topk\") &\n",
    "    ((df['model']==\"text-curie-001\") | (df['model']==\"text-davinci-003\") | (df['model']==\"gpt-4\")) &\n",
    "    (df['k_selected']==5) &\n",
    "    (df['Temperature']==0.7)\n",
    "]\n",
    "df_models\n",
    "plot_parities(df_models, \n",
    "              'model', \n",
    "              [\n",
    "                \"text-curie-001\",\n",
    "                \"text-davinci-003\",\n",
    "                \"gpt-4\"\n",
    "              ], #sorted(c2_data[c2_data['model_class']==\"multi\"]['model'].unique()), \n",
    "              nrows=1, ncols=3,\n",
    "              data='C2', \n",
    "              k=5,\n",
    "              T=0.7,\n",
    "              model=None,\n",
    "              model_class='topk', \n",
    "              N=1000,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_C2_topk_N_curieXdavinci.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iupac sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iupac_sol_data = df[(df['data'] == 'sol')]\n",
    "iupac_sol_data.groupby(['Temperature', 'data','k_selected', 'model_class', \"N_train\", \"model\"]).size().reset_index().sort_values(by=[\"model_class\", \"Temperature\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parities(iupac_sol_data, \n",
    "              'N', \n",
    "              [1,10,250,700], #sorted(iupac_sol_data[iupac_sol_data['model_class']==\"topk\"]['N_train'].unique()), \n",
    "              nrows=1, ncols=4,\n",
    "              data='sol', \n",
    "              k=5, \n",
    "              T=0.7, \n",
    "              model='gpt-3.5-turbo-0125', \n",
    "              model_class='topk',\n",
    "              N=None,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"LogS solubility\",\n",
    "              out_name=\"par_sol_topk_N_curie.png\")\n",
    "\n",
    "plot_parities(iupac_sol_data, \n",
    "              'k', \n",
    "              [1,5,10], #sorted(iupac_sol_data[iupac_sol_data['model_class']==\"multi\"]['N_train'].unique()), \n",
    "              nrows=1, ncols=3,\n",
    "              data='sol', \n",
    "              k=None,\n",
    "              T=0.05, \n",
    "              model='gpt-3.5-turbo-0125', \n",
    "              model_class='topk', \n",
    "              N=700,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"LogS solubility\",\n",
    "              out_name=\"par_sol_topk_k_curie.png\")\n",
    "\n",
    "plot_parities(iupac_sol_data, \n",
    "              'T', \n",
    "              [0.05, 0.5, 0.7, 1.0], #sorted(iupac_sol_data[iupac_sol_data['model_class']==\"multi\"]['N_train'].unique()), \n",
    "              nrows=1, ncols=4,\n",
    "              data='sol', \n",
    "              k=5,\n",
    "              T=None, \n",
    "              model='gpt-3.5-turbo-0125', \n",
    "              model_class='topk', \n",
    "              N=700,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"LogS solubility\",\n",
    "              out_name=\"par_sol_topk_T_curie.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ablation(iupac_sol_data, \n",
    "              'N', \n",
    "              sorted(iupac_sol_data[iupac_sol_data['model_class']==\"topk\"]['N_train'].unique()), \n",
    "              nrows=1, ncols=3,\n",
    "              data='iupac-sol',\n",
    "              k=5,\n",
    "              T=0.05,\n",
    "              model='text-curie-001',\n",
    "              model_class='topk',\n",
    "              N=None,\n",
    "              out_name=\"ablation_sol_topk_N_curie.png\")\n",
    "\n",
    "plot_ablation(iupac_sol_data, \n",
    "              'k', \n",
    "              [1,5,10], #sorted(iupac_sol_data[iupac_sol_data['model_class']==\"topk\"]['k_selected'].unique()), \n",
    "              nrows=1, ncols=3,\n",
    "              data='iupac-sol',\n",
    "              k=None,\n",
    "              T=0.05,\n",
    "              model='text-curie-001',\n",
    "              model_class='topk',\n",
    "              N=700,\n",
    "              out_name=\"ablation_sol_topk_k_curie.png\")\n",
    "\n",
    "plot_ablation(iupac_sol_data, \n",
    "              'T', \n",
    "              sorted(iupac_sol_data[iupac_sol_data['model_class']==\"topk\"]['Temperature'].unique()), \n",
    "              nrows=1, ncols=3,\n",
    "              data='iupac-sol',\n",
    "              k=5,\n",
    "              T=None,\n",
    "              model='text-curie-001',\n",
    "              model_class='topk',\n",
    "              N=700,\n",
    "              out_name=\"ablation_sol_topk_T_curie.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parities(iupac_sol_data, \n",
    "              'N', \n",
    "              [1,10,250,700], #sorted(iupac_sol_data[(iupac_sol_data['model_class']==\"GPR-BOT\") & (iupac_sol_data['model']==\"text-ada-001\")]['N_train'].unique()), \n",
    "              nrows=1, ncols=4,\n",
    "              data='iupac-sol', \n",
    "              k=32, \n",
    "              T=0.05, \n",
    "              model='text-ada-001', \n",
    "              model_class='GPR-BOT', \n",
    "              N=None,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"LoS solubility\",\n",
    "              out_name=\"par_sol_GPR_N.png\",\n",
    "              GPR=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ablation(df, \n",
    "              'N', \n",
    "              sorted(iupac_sol_data[(iupac_sol_data['model_class']==\"GPR-BOT\") & (iupac_sol_data['model']==\"text-ada-001\")]['N_train'].unique()), \n",
    "              nrows=1, ncols=3,\n",
    "              data='iupac-sol',\n",
    "              k=32,\n",
    "              T=0.05,\n",
    "              model='text-ada-001',\n",
    "              model_class='GPR-BOT',\n",
    "              N=None,\n",
    "              out_name=\"ablation_sol_GPR_N_ada.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parities(iupac_sol_data, \n",
    "              'N', \n",
    "              [5,10,25,50,100,250,500,700], #sorted(c2_data[(c2_data['model_class']==\"GPR-BOT\") & (c2_data['model']==\"text-ada-001\")]['N_train'].unique()), \n",
    "              nrows=2, ncols=4,\n",
    "              data='iupac-sol', \n",
    "              k=1, \n",
    "              T=0.05, \n",
    "              model='text-ada-001', \n",
    "              model_class='KNN', \n",
    "              N=None,\n",
    "              calibration=None,\n",
    "              recal_ind=300,\n",
    "              axis_name=\"C2 yield\",\n",
    "              out_name=\"par_sol_KNN_N.png\",\n",
    "              GPR=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parities(iupac_sol_data, \n",
    "              'N', \n",
    "              [50, 250, 700],#sorted(iupac_sol_data[iupac_sol_data['model_class']==\"finetune\"]['N_train'].unique()), \n",
    "              nrows=1, ncols=3,\n",
    "              data='iupac-sol', \n",
    "              k=0, \n",
    "              T=0.05, \n",
    "              model='any', \n",
    "              N=None,\n",
    "              axis_name=\"LogS solubility\",\n",
    "              out_name=\"par_sol_FT_N.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ablation(iupac_sol_data, \n",
    "              'N', \n",
    "              sorted(iupac_sol_data[iupac_sol_data['model_class']==\"finetune\"]['N_train'].unique()), \n",
    "              nrows=1, ncols=3,\n",
    "              data='iupac-sol',\n",
    "              k=0,\n",
    "              T=0.05,\n",
    "              model='any',\n",
    "              model_class='finetune',\n",
    "              N=None,\n",
    "              out_name=\"ablation_sol_FT_N_ada.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alloy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alloy_data = df[(df['data'] == 'alloy')]\n",
    "alloy_data.groupby(['Temperature', 'k_selected', 'model_class', \"N_train\", \"model\"]).size().reset_index().sort_values(by=[\"model_class\", \"Temperature\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrated MMR vs Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(14,12), constrained_layout=True)\n",
    "for ax in axs.flat:\n",
    "    ax.set_aspect(1)\n",
    "\n",
    "d00 = select_df(df, data=\"C2\", k=5, T=0.7, model='text-curie-001', model_class='topk_NN', N=1000)\n",
    "lim_c2 = (min(d00['y']), max(d00['y']))\n",
    "lim_c2 = (-2, 25)\n",
    "text_anchor = sum(lim_c2)/len(lim_c2)\n",
    "create_sub_parity(axs[0], d00, 'C2 yield', lim=lim_c2, model_class=\"topk_NN\", color=f'C4', title=\"topk_cos_sim|N=1000|T=.7|k=5|curie\",calibration='scaling_factor',recal_ind=300)\n",
    "\n",
    "d00 = select_df(df, data=\"C2\", k=5, T=0.7, model='text-curie-001', model_class='multi_NN', N=1000)\n",
    "lim_c2 = (min(d00['y']), max(d00['y']))\n",
    "lim_c2 = (-2, 25)\n",
    "text_anchor = sum(lim_c2)/len(lim_c2)\n",
    "create_sub_parity(axs[1], d00, 'C2 yield', lim=lim_c2, model_class=\"multi_NN\", color=f'C4', title=\"multi_cos_sim|N=1000|T=.7|k=5|curie\",calibration='scaling_factor',recal_ind=300)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_sub_parity(ax, df_sel, axis_name=\"topk\",model_class=\"topk\", lim=[-1,1], color='gray', GPR=False, Type_cali =False,rec_split=100,model='curie-001'):\n",
    "   \n",
    "    def process_data(df, unique_vals):\n",
    "        y, yhat, yprob = [], [], []\n",
    "        for prompt in unique_vals:\n",
    "            y.append(df[df['x'] == prompt]['y'].unique()[0])\n",
    "            yhat.append(df[df['x'] == prompt]['yhat'].values)\n",
    "            yprob.append(df[df['x'] == prompt]['yprobs'].values)\n",
    "        return y, yhat, yprob\n",
    "\n",
    "    def calculate_means_and_stds(yhat, yprob):\n",
    "        means = np.array([np.sum(yhi * ypi) if len(yhi) > 1 else ypi.mean() for yhi, ypi in zip(yhat, yprob)])\n",
    "        means = np.where(means == 0, 0.0001, means)\n",
    "        stds = np.array([np.sqrt(np.sum((yhi - ymi)**2 * ypi)) if len(yhi) > 1 else ypi.mean() for yhi, ypi, ymi in zip(yhat, yprob, means)])\n",
    "        return means, stds\n",
    "\n",
    "    unique_vals = df_sel['x'].unique()\n",
    "    y, yhat, yprob = process_data(df_sel, unique_vals[:rec_split])\n",
    "    y_rec, yhat_rec, yprob_rec = process_data(df_sel, unique_vals[rec_split:])\n",
    "\n",
    "    ymeans, ystds = calculate_means_and_stds(yhat, yprob)\n",
    "    ymeans_rec, ystds_rec = calculate_means_and_stds(yhat_rec, yprob_rec)\n",
    "    \n",
    "    if Type_cali == \"cali\":\n",
    "\n",
    "        if GPR:\n",
    "            yprobs = np.array([ypi.mean() for ypi in yprob])\n",
    "\n",
    "            yhats=np.array(np.concatenate(yhat))\n",
    "\n",
    "            ma = uct.miscalibration_area(yhats,yprobs, np.array(y), recal_model=None)\n",
    "            \n",
    "            x, y1 = uct.get_proportion_lists_vectorized(yhats,yprobs, np.array(y))\n",
    "            \n",
    "            ax.plot(x,x, linestyle= '--')\n",
    "            ax.plot(x, y1)\n",
    "            ax.fill_between(x, x, y1, color='teal', alpha=0.3)\n",
    "            \n",
    "            ax.set_title(' {} | {} | {}'.format(model,axis_name, model_class))\n",
    "           \n",
    "            ax.set_ylim(lim[0],lim[1])\n",
    "            ax.set_xlim(lim[0],lim[1])\n",
    "            ax.set_ylabel(\"Observed Proportion in Interval\")\n",
    "            \n",
    "            # ax.(lim[0] + 0.1*(max(yhat)-min(yhat)), lim[1] - 1*0.1*(max(yhat)-min(y)), f\"(\\u2193)Miscalibration area = {ma:.3f}\")\n",
    "\n",
    "            ax.annotate(f\"(\\u2193)Miscalibration area = {ma:.3f}\",\n",
    "                xy=(0.02, 0.98), xycoords='axes fraction',\n",
    "                horizontalalignment='left', verticalalignment='top')\n",
    "\n",
    "        else:\n",
    "            ma = uct.miscalibration_area(ymeans,ystds, np.array(y), recal_model=None)\n",
    "            \n",
    "            x, y1 = uct.get_proportion_lists_vectorized(ymeans,ystds, np.array(y))\n",
    "            \n",
    "            ax.plot(x,x, linestyle= '--')\n",
    "            ax.plot(x, y1)\n",
    "            ax.fill_between(x, x, y1, color='teal', alpha=0.3)\n",
    "            \n",
    "            ax.set_title(' {} | {} | {}'.format(model,axis_name, model_class))\n",
    "            # ax.set_xlabel(f\"measured {axis_name}\")\n",
    "            # ax.set_ylabel(\"Obsererved Proportion in Interval\")\n",
    "            ax.set_ylabel(\"Observed Proportion in Interval\")\n",
    "            ax.set_ylim(lim[0],lim[1])\n",
    "            ax.set_xlim(lim[0],lim[1])\n",
    "            \n",
    "            # ax.(lim[0] + 0.1*(max(yhat)-min(yhat)), lim[1] - 1*0.1*(max(yhat)-min(y)), f\"(\\u2193)Miscalibration area = {ma:.3f}\")\n",
    "\n",
    "            ax.annotate(f\"(\\u2193)Miscalibration area = {ma:.3f}\",\n",
    "                xy=(0.02, 0.98), xycoords='axes fraction',\n",
    "                horizontalalignment='left', verticalalignment='top')\n",
    "            \n",
    "\n",
    "    elif Type_cali == \"recali\":\n",
    "\n",
    "        if GPR:\n",
    "\n",
    "            yprobs = np.array([ypi.mean() for ypi in yprob])\n",
    "            yyprobs = np.array([ypi.mean() for ypi in yprob_rec])\n",
    "\n",
    "            yhats=np.array(np.concatenate(yhat))\n",
    "            yyhats=np.array(np.concatenate(yhat_rec))\n",
    "\n",
    "\n",
    "            exp_props,obs_props= uct.metrics_calibration.get_proportion_lists_vectorized(yyhats[:100], yyprobs[:100], np.array(y_rec[:100]))\n",
    "\n",
    "            \n",
    "            recal_model = uct.recalibration.iso_recal(exp_props, obs_props)\n",
    "\n",
    "            ma = uct.miscalibration_area(yhats, yprobs, np.array(y), recal_model=recal_model)\n",
    "            \n",
    "            x, y1 = uct.metrics_calibration.get_proportion_lists_vectorized(yhats, yprobs, np.array(y), recal_model=recal_model)\n",
    "            \n",
    "            ax.plot(x,x, linestyle= '--')\n",
    "            ax.plot(x, y1)\n",
    "            ax.fill_between(x, x, y1, color='teal', alpha=0.3)\n",
    "            \n",
    "            ax.set_title('Isotonic')\n",
    "            ax.set_ylim(lim[0],lim[1])\n",
    "            ax.set_xlim(lim[0],lim[1])\n",
    "            \n",
    "            # ax.(lim[0] + 0.1*(max(yhat)-min(yhat)), lim[1] - 1*0.1*(max(yhat)-min(y)), f\"(\\u2193)Miscalibration area = {ma:.3f}\")\n",
    "\n",
    "            ax.annotate(f\"(\\u2193)Miscalibration area = {ma:.3f}\",\n",
    "                xy=(0.02, 0.98), xycoords='axes fraction',\n",
    "                horizontalalignment='left', verticalalignment='top')\n",
    "\n",
    "        else:\n",
    "        \n",
    "            exp_props,obs_props= uct.metrics_calibration.get_proportion_lists_vectorized(ymeans_rec[:100], ystds_rec[:100], np.array(y_rec[:100]))\n",
    "\n",
    "\n",
    "            recal_model = uct.recalibration.iso_recal(exp_props, obs_props)\n",
    "\n",
    "            ma = uct.miscalibration_area(ymeans, ystds, np.array(y), recal_model=recal_model)\n",
    "            \n",
    "            x, y1 = uct.metrics_calibration.get_proportion_lists_vectorized(ymeans,ystds, np.array(y), recal_model=recal_model)\n",
    "            \n",
    "            ax.plot(x,x, linestyle= '--')\n",
    "            ax.plot(x, y1)\n",
    "            ax.fill_between(x, x, y1, color='teal', alpha=0.3)\n",
    "            \n",
    "            ax.set_title('Isotonic')\n",
    "            \n",
    "            ax.set_ylabel(\"Observed Proportion in Interval\")\n",
    "            ax.set_ylim(lim[0],lim[1])\n",
    "            ax.set_xlim(lim[0],lim[1])\n",
    "            \n",
    "            # ax.(lim[0] + 0.1*(max(yhat)-min(yhat)), lim[1] - 1*0.1*(max(yhat)-min(y)), f\"(\\u2193)Miscalibration area = {ma:.3f}\")\n",
    "\n",
    "            ax.annotate(f\"(\\u2193)Miscalibration area = {ma:.3f}\",\n",
    "                xy=(0.02, 0.98), xycoords='axes fraction',\n",
    "                horizontalalignment='left', verticalalignment='top')\n",
    "\n",
    "    elif Type_cali == \"recali_scale\":\n",
    "\n",
    "\n",
    "        if GPR:\n",
    "            \n",
    "            yhats=np.concatenate(yhat)\n",
    "            yyhats=np.concatenate(yhat_rec)\n",
    "\n",
    "            yprobs = np.array([ypi.mean() for ypi in yprob])\n",
    "            yyprobs = np.array([ypi.mean() for ypi in yprob_rec])\n",
    "\n",
    "            std_scaling = uct.recalibration.optimize_recalibration_ratio(yyhats[:100], yyprobs[:100], np.array(y_rec[:100]), criterion=\"miscal\")\n",
    "\n",
    "\n",
    "            ystds = yprobs * std_scaling\n",
    "            print(std_scaling,model)\n",
    "\n",
    "            ma = uct.miscalibration_area(yhats, ystds, np.array(y), recal_model=None)\n",
    "    \n",
    "            \n",
    "            x, y1 = uct.metrics_calibration.get_proportion_lists_vectorized(yhats, ystds, np.array(y), recal_model=None)\n",
    "            \n",
    "            ax.plot(x,x, linestyle= '--')\n",
    "            ax.plot(x, y1)\n",
    "            ax.fill_between(x, x, y1, color='teal', alpha=0.3)\n",
    "            \n",
    "            ax.set_title('Scaling')\n",
    "            ax.set_xlabel(\"Predicted Proportion in Interval\")\n",
    "            ax.set_ylabel(\"Observed Proportion in Interval\")\n",
    "            ax.set_ylim(lim[0],lim[1])\n",
    "            ax.set_xlim(lim[0],lim[1])\n",
    "            \n",
    "\n",
    "            ax.annotate(f\"(\\u2193)Miscalibration area = {ma:.3f}\",\n",
    "                xy=(0.02, 0.98), xycoords='axes fraction',\n",
    "                horizontalalignment='left', verticalalignment='top')\n",
    "\n",
    "        else:\n",
    "\n",
    "            std_scaling = uct.recalibration.optimize_recalibration_ratio(ymeans_rec[:100], ystds_rec[:100], np.array(y_rec[:100]),\n",
    "                                                                        criterion=\"miscal\")\n",
    "            print(std_scaling)\n",
    "            ystds = ystds * std_scaling\n",
    "\n",
    "\n",
    "            ma = uct.miscalibration_area(ymeans, ystds, np.array(y), recal_model=None)\n",
    "            \n",
    "            x, y1 = uct.metrics_calibration.get_proportion_lists_vectorized(ymeans, np.array(ystds), np.array(y), recal_model=None)\n",
    "            \n",
    "            ax.plot(x,x, linestyle= '--')\n",
    "            ax.plot(x, y1)\n",
    "            ax.fill_between(x, x, y1, color='teal', alpha=0.3)\n",
    "            \n",
    "            ax.set_title('Scaling')\n",
    "            ax.set_xlabel(\"Predicted Proportion in Interval\")\n",
    "            ax.set_ylabel(\"Observed Proportion in Interval\")\n",
    "            ax.set_ylim(lim[0],lim[1])\n",
    "            ax.set_xlim(lim[0],lim[1])\n",
    "            \n",
    "            # ax.(lim[0] + 0.1*(max(yhat)-min(yhat)), lim[1] - 1*0.1*(max(yhat)-min(y)), f\"(\\u2193)Miscalibration area = {ma:.3f}\")\n",
    "\n",
    "            ax.annotate(f\"(\\u2193)Miscalibration area = {ma:.3f}\",\n",
    "                xy=(0.02, 0.98), xycoords='axes fraction',\n",
    "                horizontalalignment='left', verticalalignment='top')\n",
    "\n",
    "    else:\n",
    "\n",
    "        ax.set_xlabel(f\"measured {axis_name}\")\n",
    "        ax.set_ylabel(f\"predicted {axis_name}\")\n",
    "        ax.set_ylim(lim[0], lim[1])\n",
    "        ax.set_xlim(lim[0], lim[1])\n",
    "\n",
    "        corr_val = corr(y, [yhi.mean() for yhi in yhat])\n",
    "        ax.text(lim[0] + 0.1 * (max(y) - min(y)), lim[1] - 1 * 0.1 * (max(y) - min(y)), f\"(\\u2191)correlation = {corr_val:.3f}\")\n",
    "        \n",
    "        if GPR:\n",
    "            ax.text(lim[0] + 0.1*(max(y)-min(y)), lim[1] - 2*0.1*(max(y)-min(y)), f\"(\\u2193)neg-ll = {log_likelihood(y, [yhi.mean() for yhi in yhat], yprobs, eps=1e-6):.3f}\")\n",
    "        else:\n",
    "            ax.text(lim[0] + 0.1*(max(y)-min(y)), lim[1] - 2*0.1*(max(y)-min(y)), f\"(\\u2193)neg-ll = {log_likelihood(y, [yhi.mean() for yhi in yhat], [yhi.std() if len(yhi)>1 else max(yprobs) for yhi in yhat], eps=1e-6):.3f}\")\n",
    "        ax.text(lim[0] + 0.1*(max(y)-min(y)), lim[1] - 3*0.1*(max(y)-min(y)), f\"(\\u2193)MAE = {mae(y, [yhi.mean() for yhi in yhat]):.3f}\")\n",
    "        \n",
    "        ax.plot(y,y)\n",
    "        ax.plot(lim,lim)\n",
    "        \n",
    "        if GPR:\n",
    "            ax.errorbar(y, \n",
    "                        [yhi.mean() for yhi in yhat], \n",
    "                        yerr=[abs(recal_bounds.lower),abs(recal_bounds.upper)],\n",
    "                        fmt='.', color='gray', alpha=0.3)\n",
    "        else:  \n",
    "            ax.errorbar(y, \n",
    "                        [yhi.mean() for yhi in yhat], \n",
    "                        yerr=[yhi.std() if len(yhi)>1 else max(yprobs) for yhi in yhat],\n",
    "                        fmt='.', color='gray', alpha=0.3)\n",
    "        ax.scatter(\n",
    "            y, [yhi.mean() for yhi in yhat], s=6, alpha=1, color=color\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import uncertainty_toolbox as uct\n",
    "\n",
    "#figsize=(6.4,4.8)\n",
    "fig, axs = plt.subplots(nrows=3, ncols=7, figsize=(30,12), constrained_layout=True)\n",
    "for ax in axs.flat:\n",
    "    ax.set_aspect(1)\n",
    "\n",
    "\n",
    "# plot axs[0,0]\n",
    "d00 = select_df(df, data=\"C2\", k=5, T=.7, model='text-curie-001', model_class='topk', N=1000)\n",
    "lim_c2 = (min(d00['y']), max(d00['y']))\n",
    "lim_c2 = (0, 1)\n",
    "text_anchor = sum(lim_c2)/len(lim_c2)\n",
    "create_sub_parity(axs[0,0], d00, axis_name='C2',model_class='topk', lim=lim_c2, color=f'C0',Type_cali=\"cali\",rec_split=100)\n",
    "# # plot axs[0,1]\n",
    "d01 = select_df(df, data=\"C2\", k=5, T=.7, model='text-curie-001', model_class='multi', N=1000)\n",
    "create_sub_parity(axs[0,1], d01, axis_name='C2',model_class='multi', lim=lim_c2, color=f'C1', Type_cali=\"cali\",rec_split=100)\n",
    "# # plot axs[0,2]\n",
    "d02 = select_df(df, data=\"C2\", k=5, T=0.7, model='text-davinci-003', model_class='topk', N=1000)\n",
    "create_sub_parity(axs[0,2], d02, axis_name='C2',model_class='topk', lim=lim_c2, color=f'C2', Type_cali=\"cali\", rec_split=100,model='text-davinci-003')\n",
    "\n",
    "\n",
    "\n",
    "# # plot axs[1,0]\n",
    "d10 = select_df(df, data=\"C2\", k=5, T=0.7, model='text-curie-001', model_class='topk', N=1000)\n",
    "lim_c2 = (min(d10['y']), max(d10['y']))\n",
    "lim_c2 = (0, 1)\n",
    "create_sub_parity(axs[1,0], d10, axis_name='C2 yield',model_class='topk', lim=lim_c2, color=f'C4', Type_cali=\"recali\",rec_split=100) # calibration plot\n",
    "# # # plot axs[1,1]\n",
    "d11 = select_df(df, data=\"C2\", k=5, T=.7, model='text-curie-001', model_class='multi', N=1000)\n",
    "lim = (min(d11['y']), max(d11['y']))\n",
    "create_sub_parity(axs[1,1], d11, axis_name='C2 yield',model_class='multi', lim=lim_c2, color=f'C5', Type_cali=\"recali\",rec_split=100)\n",
    "# # plot axs[1,2]\n",
    "d12 = select_df(df, data=\"C2\", k=5, T=0.7, model='text-davinci-003', model_class='topk', N=1000)\n",
    "lim = (min(d12['y']), max(d12['y']))\n",
    "create_sub_parity(axs[1,2], d12, axis_name='C2 yield',model_class='topk', lim=lim_c2, color=f'C6',Type_cali=\"recali\",rec_split=100)\n",
    "\n",
    "\n",
    "\n",
    "# # plot axs[2,0]\n",
    "d20 = select_df(df, data=\"C2\", k=5, T=0.7, model='text-curie-001', model_class='topk', N=1000)\n",
    "lim = (min(d20['y']), max(d20['y']))\n",
    "create_sub_parity(axs[2,0], d20, 'C2 yield',model_class='topk', lim=lim_c2, color=f'C6',Type_cali=\"recali_scale\",rec_split=100)\n",
    "\n",
    "# # plot axs[2,1]\n",
    "d21 = select_df(df, data=\"C2\", k=5, T=0.7, model='text-curie-001', model_class='multi', N=1000)\n",
    "lim = (min(d21['y']), max(d21['y']))\n",
    "create_sub_parity(axs[2,1], d21, 'C2 yield',model_class='multi', lim=lim_c2, color=f'C6',Type_cali=\"recali_scale\",GPR=False,rec_split=100)\n",
    "\n",
    "# # # plot axs[2,2]\n",
    "d22 = select_df(df, data=\"C2\", k=5, T=0.7, model='text-davinci-003', model_class='topk', N=1000)\n",
    "lim = (min(d22['y']), max(d22['y']))\n",
    "create_sub_parity(axs[2,2], d22, 'C2 yield', lim=lim_c2, color=f'C6',Type_cali=\"recali_scale\",rec_split=100)\n",
    "\n",
    "\n",
    "# # plot axs[0,3]\n",
    "d03 = select_df(df, data=\"C2\", k=5, T=0.7, model='gpt-4', model_class='topk', N=1000)\n",
    "lim_c2 = (min(d03['y']), max(d03['y']))\n",
    "lim_c2 = (0, 1)\n",
    "text_anchor = sum(lim_c2)/len(lim_c2)\n",
    "lim = (min(d03['y']), max(d03['y']))\n",
    "create_sub_parity(axs[0,3], d03, 'C2 yield',model='gpt-4', model_class='topk', lim=lim_c2, color=f'C6',Type_cali=\"cali\",rec_split=100)\n",
    "\n",
    "# # plot axs[1,3]\n",
    "d33 = select_df(df, data=\"C2\", k=5, T=0.7, model='gpt-4', model_class='topk', N=1000)\n",
    "lim = (min(d33['y']), max(d33['y']))\n",
    "create_sub_parity(axs[1,3], d33, 'C2 yield', lim=lim_c2, color=f'C6',Type_cali=\"recali\",rec_split=100)\n",
    "\n",
    "# # # plot axs[2,3]\n",
    "d33 = select_df(df, data=\"C2\", k=5, T=0.7, model='gpt-4', model_class='topk', N=1000)\n",
    "lim = (min(d33['y']), max(d33['y']))\n",
    "create_sub_parity(axs[2,3], d33, 'C2 yield', lim=lim_c2, color=f'C6',Type_cali=\"recali_scale\",rec_split=100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # plot axs[0,4]\n",
    "d04 = select_df(df, data=\"C2\", k=0, T=0, model='GPR', model_class='GPR_mat', N=1000)\n",
    "lim_c2 = (min(d04['y']), max(d04['y']))\n",
    "lim_c2 = (0, 1)\n",
    "text_anchor = sum(lim_c2)/len(lim_c2)\n",
    "lim = (min(d04['y']), max(d04['y']))\n",
    "create_sub_parity(axs[0,4], d04, 'C2 yield',model='GPR',GPR=True,model_class='GPR_mat', lim=lim_c2, color=f'C6',Type_cali=\"cali\",rec_split=100)\n",
    "\n",
    "# # plot axs[1,4]\n",
    "d14 = select_df(df, data=\"C2\", k=0, T=0, model='GPR', model_class='GPR_mat', N=1000)\n",
    "lim = (min(d14['y']), max(d14['y']))\n",
    "create_sub_parity(axs[1,4], d14, 'C2 yield', lim=lim_c2, color=f'C6',Type_cali=\"recali\",GPR=True,rec_split=100)\n",
    "\n",
    "# # # plot axs[2,4]\n",
    "d24 = select_df(df, data=\"C2\", k=0, T=0, model='GPR', model_class='GPR_mat', N=1000)\n",
    "lim = (min(d24['y']), max(d24['y']))\n",
    "create_sub_parity(axs[2,4], d24, 'C2 yield', lim=lim_c2, color=f'C6',Type_cali=\"recali_scale\",GPR=True,rec_split=100)\n",
    "\n",
    "\n",
    "\n",
    "# # plot axs[0,5]\n",
    "d05 = select_df(df, data=\"C2\", k=0, T=0, model='GPR', model_class='GPR_ada', N=1000)\n",
    "lim_c2 = (min(d05['y']), max(d05['y']))\n",
    "lim_c2 = (0, 1)\n",
    "text_anchor = sum(lim_c2)/len(lim_c2)\n",
    "lim = (min(d05['y']), max(d05['y']))\n",
    "create_sub_parity(axs[0,5], d05, 'C2 yield',model='GPR',GPR=True, model_class='GPR-ada', lim=lim_c2, color=f'C6',Type_cali=\"cali\",rec_split=100)\n",
    "\n",
    "# # plot axs[1,5]\n",
    "d35 = select_df(df, data=\"C2\", k=0, T=0, model='GPR', model_class='GPR_ada', N=1000)\n",
    "lim = (min(d35['y']), max(d35['y']))\n",
    "create_sub_parity(axs[1,5], d35, 'C2 yield', lim=lim_c2, color=f'C6',Type_cali=\"recali\",GPR=True,rec_split=100)\n",
    "\n",
    "# # # plot axs[2,5]\n",
    "d35 = select_df(df, data=\"C2\", k=0, T=0, model='GPR', model_class='GPR_ada', N=1000)\n",
    "lim = (min(d35['y']), max(d35['y']))\n",
    "create_sub_parity(axs[2,5], d35, 'C2 yield', lim=lim_c2, color=f'C6',GPR=True,Type_cali=\"recali_scale\",rec_split=100)\n",
    "\n",
    "\n",
    "\n",
    "# # plot axs[0,6]\n",
    "d06 = select_df(df, data=\"C2\", k=0, T=0, model='GPR', model_class='GPR_num', N=1000)\n",
    "lim_c2 = (min(d06['y']), max(d06['y']))\n",
    "lim_c2 = (0, 1)\n",
    "text_anchor = sum(lim_c2)/len(lim_c2)\n",
    "lim = (min(d06['y']), max(d06['y']))\n",
    "create_sub_parity(axs[0,6], d06, 'C2 yield',model='GPR',GPR=True,model_class='GPR_num', lim=lim_c2, color=f'C6',Type_cali=\"cali\",rec_split=100)\n",
    "\n",
    "# # plot axs[1,6]\n",
    "d16 = select_df(df, data=\"C2\", k=0, T=0, model='GPR', model_class='GPR_num', N=1000)\n",
    "lim = (min(d16['y']), max(d16['y']))\n",
    "create_sub_parity(axs[1,6], d16, 'C2 yield', lim=lim_c2, color=f'C6',Type_cali=\"recali\",GPR=True,rec_split=100)\n",
    "\n",
    "# # # plot axs[2,6]\n",
    "d26 = select_df(df, data=\"C2\", k=0, T=0, model='GPR', model_class='GPR_num', N=1000)\n",
    "lim = (min(d26['y']), max(d26['y']))\n",
    "create_sub_parity(axs[2,6], d26, 'C2 yield', lim=lim_c2, color=f'C6',Type_cali=\"recali_scale\",GPR=True,rec_split=100)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import uncertainty_toolbox as uct\n",
    "\n",
    "def combine(s, l):\n",
    "  '''Number of combinations of l elements with max = s'''\n",
    "  return (s**l - (s-1)**(l))\n",
    "\n",
    "def prob(s, l, n):\n",
    "  '''Probability of getting a sample with max([x0,x1,...,xl]) = s where xi={0,n}'''\n",
    "  return combine(s,l) * ((1/n)**l)\n",
    "\n",
    "def expected_value_p(l, n):\n",
    "  '''Expected value of max([x0,x1,...,xl]) where xi={0,n}'''\n",
    "  E = [s * prob(s, l, n) for s in range(1,100+1)]\n",
    "  return sum(E)\n",
    "\n",
    "def expected_value_q(l, n, data):\n",
    "  '''Expected value of max([x0,x1,...,xl]) where xi={0,n}'''\n",
    "  quants = [data.quantile(i/100) for i in range(100+1)]\n",
    "  # E = [(quants[s-1]) * prob(s, l, n) for s in range(1,100+1)]\n",
    "  E = [((quants[s-1]+quants[s])/2) * prob(s, l, n) for s in range(1,100+1)]\n",
    "  return sum(E)\n",
    "\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")\n",
    "\n",
    "# @retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def run_experiment(\n",
    "    asktell, pool, raw_data, indexes, x_name, y_name, N=1, initial_train=1, ask_K=1, aq=\"random\", start_index=0, calibrate=False,\n",
    "    lambda_multi=0.1, system_message=\"\", inv_system_message=\"\",transfer_train=1, transfer=False, trans_data=transfer_data, t_indexes=t_indexes\n",
    "):\n",
    "    if aq=='random_mean':\n",
    "       return [ (i, expected_value_q(i, 100, raw_data[y_name])) for i in range(1,N+initial_train) ]\n",
    "    \n",
    "    point=[]\n",
    "    py = 0 \n",
    "    mod_std = 0\n",
    "    counter = 0\n",
    "    for i in indexes[:initial_train]:\n",
    "        print(\"indexes check\",)\n",
    "        asktell.tell(raw_data[x_name].iloc[i], float(raw_data[y_name].iloc[i]))\n",
    "        if counter == 0:\n",
    "           i_best = float(raw_data[y_name].iloc[i])\n",
    "        else:\n",
    "           i_best = sorted(point, key=lambda i_points: i_points[-1])[-1][-3]\n",
    "           \n",
    "        point.append((raw_data[x_name].iloc[i],counter,i_best,float(raw_data[y_name].iloc[i]),float(raw_data[y_name].iloc[i]),mod_std))\n",
    "\n",
    "\n",
    "        print(\"check\",raw_data[x_name].iloc[i], float(raw_data[y_name].iloc[i]),i_best)\n",
    "        counter+=1\n",
    "        \n",
    "    print(\"you made it\")\n",
    "    if transfer:\n",
    "      for j in t_indexes[:transfer_train]:\n",
    "          asktell.tell(trans_data[x_name].iloc[j], float(trans_data[y_name].iloc[j]))\n",
    "          print(\"transfer running here and shouldn't\")\n",
    "        \n",
    "    if calibrate:\n",
    "        # y = [float(raw_data[y_name].iloc[i]) for i in indexes[:initial_train]]\n",
    "        # pred = asktell.predict(y)\n",
    "        # ymeans = np.array([yhi.mean() for yhi in pred])\n",
    "        # ystds = np.array([yhi.std() for yhi in pred])\n",
    "        # calibration_factor = uct.recalibration.optimize_recalibration_ratio (ymeans, ystds, np.array(y), criterion=\"miscal\")\n",
    "        calibration_factor = 5.0\n",
    "        asktell.set_calibration_factor(calibration_factor)\n",
    "\n",
    "    x = raw_data[x_name].tolist()\n",
    "\n",
    "    pool.reset()\n",
    "    xi = x[start_index]\n",
    "    x.remove(xi)\n",
    "    pool.choose(xi)\n",
    "    print(\"len of x:\",len(x),\"startindex:\",start_index,\"xi:\",xi)\n",
    "    yi = float(raw_data[raw_data[x_name] == xi][y_name].iloc[0])\n",
    "    asktell.tell(xi, yi) # Stuck here\n",
    "    point.append((xi,1+initial_train,i_best, yi,py,mod_std))\n",
    "    best = sorted(point, key=lambda points: points[-1])[-1][-3]\n",
    "\n",
    "\n",
    "    for i in range(1, N):\n",
    "        if i == N - 1 and aq != \"random\":\n",
    "            aq = \"greedy\"\n",
    "        px, _, py, mod_std = asktell.ask(pool,\n",
    "                                k=ask_K,\n",
    "                                aq_fxn=aq,\n",
    "                                _lambda=1.0,\n",
    "                                inv_filter=16,\n",
    "                                aug_random_filter=0,\n",
    "                                lambda_mult=lambda_multi,\n",
    "                                system_message=system_message,\n",
    "                                inv_system_message=inv_system_message,\n",
    "                                )\n",
    "        for j in range(ask_K):\n",
    "          xc = px[j]\n",
    "          x.remove(xc)\n",
    "          pool.choose(xc)\n",
    "          y = float(raw_data[raw_data[x_name] == xc][y_name].iloc[0])\n",
    "          asktell.tell(xc, y)\n",
    "          best = max(y, best)\n",
    "          print(\"here\",best)\n",
    "        point.append((xc, 1+initial_train+i*ask_K, best, y,py[0],mod_std[0]))\n",
    "        print(point)\n",
    "    return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://github.com/google/fonts/raw/main/ofl/ibmplexmono/IBMPlexMono-Regular.ttf\",\n",
    "    \"IBMPlexMono-Regular.ttf\",\n",
    ")\n",
    "fe = font_manager.FontEntry(fname=\"IBMPlexMono-Regular.ttf\", name=\"plexmono\")\n",
    "font_manager.fontManager.ttflist.append(fe)\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"axes.facecolor\": \"#f5f4e9\",\n",
    "        \"grid.color\": \"#AAAAAA\",\n",
    "        \"axes.edgecolor\": \"#333333\",\n",
    "        \"figure.facecolor\": \"#FFFFFF\",\n",
    "        \"axes.grid\": False,\n",
    "        \"axes.prop_cycle\": plt.cycler(\"color\", plt.cm.Dark2.colors),\n",
    "        \"font.family\": fe.name,\n",
    "        \"figure.figsize\": (3.5, 3.5 / 1.2),\n",
    "        \"ytick.left\": True,\n",
    "        \"xtick.bottom\": True,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df= pd.read_csv(\"out/dataset/data/C2_yield_meth_oxy_short_corrected.csv\")\n",
    "\n",
    "original_labels= df[\"completion\"].values\n",
    "\n",
    "kde = gaussian_kde(original_labels, bw_method=\"scott\")\n",
    "n_samples = len(df)\n",
    "randomized_samples = kde.resample(n_samples).flatten()\n",
    "randomized_samples = np.round(randomized_samples, 2)\n",
    "np.random.shuffle(randomized_samples)\n",
    "df['random_labels'] = randomized_samples \n",
    "df.to_csv(\"out/dataset/data/C2_yield_meth_oxy_short_corrected_wrandom_labels.csv\", index=False)\n",
    "\n",
    "kde_original = gaussian_kde(original_labels)\n",
    "kde_random = gaussian_kde(randomized_samples)\n",
    "\n",
    "x_min = min(original_labels.min(), randomized_samples.min())\n",
    "x_max = max(original_labels.max(), randomized_samples.max())\n",
    "x_vals = np.linspace(x_min, x_max, 1000)\n",
    "\n",
    "plt.figure(figsize=(10, 6),)\n",
    "plt.plot(x_vals, kde_original(x_vals), label='Original Labels KDE', linewidth=2)\n",
    "plt.plot(x_vals, kde_random(x_vals), label='Randomized Labels KDE', linewidth=2, linestyle='--')\n",
    "plt.title(\"KDE of Original vs. Randomized Labels\",fontsize=14)\n",
    "plt.xlabel(\"Label Value\",fontsize=14)\n",
    "plt.ylabel(\"Density\",fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"out/figs/ocm_kde_original_vs_randomized.png\", dpi=300)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
